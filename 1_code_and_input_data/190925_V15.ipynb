{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb63125a-0ada-4bdc-bd2c-d7de85bc0c36",
   "metadata": {},
   "source": [
    "# MFA-Modell for Timber Trusses in Eichkampkieyz\n",
    "\n",
    "\n",
    "* **Version:** 1.0\n",
    "* **Date:** 14.09.2025\n",
    "* **Authors:** [A. K., Johannes Scholz, Lukas Hoppe]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8085532",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56738efa-6be4-4a1c-a2ef-7ad73fac2ad4",
   "metadata": {},
   "source": [
    "# Section 0: Importing the packages & basic settings translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b416ef-6b40-4497-8eed-c7825c26494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console contrib dejavu events execute kernel kernelspec\n",
      "lab labextension labhub migrate nbconvert nbextensions_configurator notebook\n",
      "qtconsole run script server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "### Load packages ###\n",
    "# Add this at the beginning of your notebook\n",
    "!jupyter nbextension list\n",
    "\n",
    "# Load general libraries\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import lognorm\n",
    "import xlsxwriter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator,\n",
    "                               FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "from ipywidgets import SelectMultiple\n",
    "import networkx as nx\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "\n",
    "\n",
    "# Load ODYM package\n",
    "# Add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'framework', 'ODYM-master_20241127', 'odym', 'modules')) \n",
    "\n",
    "# Import the ODYM class file\n",
    "import ODYM_Classes as msc \n",
    "# Import the ODYM function file\n",
    "import ODYM_Functions as msf\n",
    "# Import the dynamic stock model library\n",
    "import dynamic_stock_model as dsm \n",
    "\n",
    "\n",
    "# Load bioDYM_addon\n",
    "# Add ODYM module directory to system path, absolute\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'framework', 'bioDYM_add-on', 'modules')) \n",
    "\n",
    "# Import classes for first order model process\n",
    "import bioDYM_classes as bicl\n",
    "# Import plotting functions\n",
    "import bioDYM_plotting as bipl\n",
    "# Import export functions\n",
    "import bioDYM_export as bix\n",
    "\n",
    "\n",
    "\n",
    "# Enables plotting directly in the notebook (in most cases this is already enabled)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105c22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36db6e27-01ed-490a-8af7-5c46da93a228",
   "metadata": {},
   "source": [
    "# Section 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7959486e-b38a-4d14-8606-e101ee8d1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Section 1: Model Configuration\n",
    "# All user-defined settings for a scenario run go here.\n",
    "# ====================================================================\n",
    "\n",
    "# --- File Paths ---\n",
    "EXCEL_FILE_PATH = '250731_V11.xlsx'\n",
    "\n",
    "# --- Model Scope ---\n",
    "START_YEAR = 1920\n",
    "END_YEAR = 2045\n",
    "ELEMENTS = ['material', 'WC', 'DM', 'CC'] # Elements to be tracked\n",
    "\n",
    "# In Section 1: Model Configuration\n",
    "\n",
    "# --- Model Calculation Switches ---\n",
    "# Set to True to enable the calculation, False to disable.\n",
    "# This allows for simpler test runs without DSM or FOMP.\n",
    "RUN_DSM_CALCULATION = True\n",
    "RUN_FOMP_CALCULATION = False # Set to False to disable FOMP calculations\n",
    "\n",
    "# --- Dynamic Stock Model (DSM) Parameters ---\n",
    "# This dictionary holds the parameters for ALL dynamic stocks in the model.\n",
    "# The key (e.g., 3) is the integer process_id where the stock is located.\n",
    "# This structure allows for multiple DSMs; just add another process_id as a key.\n",
    "# In Section 1: Model Configuration\n",
    "DSM_PARAMS = {\n",
    "    0: { # Parameters for Stock in process 0: Biosphere #\n",
    "        'inflow_split': [1], # Split of inflow into the stock\n",
    "        'lifetimes': {\n",
    "            'Type': 'Normal', # Type of distribution for residence time\n",
    "            'Mean': [20], # Residence time in process\n",
    "            'StdDev': [4] # Standard deviation for the residence time\n",
    "        },\n",
    "        # Name for inflow categories in the legend of the plot\n",
    "        'category_names': ['Average Exchange'] \n",
    "    },\n",
    "\n",
    "    2: { # Parameters for Stock in process 2: Processing #\n",
    "        'inflow_split': [1], \n",
    "        'lifetimes': {\n",
    "            'Type': 'Normal', \n",
    "            'Mean': [6],\n",
    "            'StdDev': [2]\n",
    "        },\n",
    "        'category_names': ['Air Drying'] \n",
    "    },\n",
    "\n",
    "    3: { # Parameters for Stock in process 3: Use #\n",
    "        'inflow_split': [1], \n",
    "        'lifetimes': {\n",
    "            'Type': 'Normal',\n",
    "            'Mean': [80],\n",
    "            'StdDev': [16] \n",
    "        },\n",
    "    'category_names': ['Average Lifetime'] \n",
    "    },\n",
    "\n",
    "\n",
    "    7: { # Parameters for Stock in process 7: Atmosphere #\n",
    "        'inflow_split': [1], \n",
    "        'lifetimes': {\n",
    "            'Type': 'Normal',\n",
    "            'Mean': [70], \n",
    "            'StdDev': [2]\n",
    "        },\n",
    "     'category_names': ['Photosynthesis']  \n",
    "    },\n",
    "\n",
    "    8: { # Parameters for Stock in process 8: Anthroposphere #\n",
    "        'inflow_split': [1],\n",
    "        'lifetimes': {\n",
    "            'Type': 'Normal',\n",
    "            'Mean': [], \n",
    "            'StdDev': []\n",
    "        },\n",
    "    'category_names': [] \n",
    "    }\n",
    "}\n",
    "# Example for a second dynamic stock in another process (e.g., process 25):\n",
    "# 25: {\n",
    "#     'lifetimes': {\n",
    "#         'Type': 'Lognormal',\n",
    "#         'Mean': [50],\n",
    "#         'StdDev': [15]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# --- First-Order Model Process (FOMP) Parameters ---\n",
    "# This dictionary holds parameters for ALL FOMP calculations.\n",
    "# The key (e.g., 17) is the integer process_id where the decay occurs.\n",
    "# In Section 1: Model Configuration\n",
    "\n",
    "# FOMP_PARAMS = {\n",
    "#     5: { # Parameter fÃ¼r die Mineralisierung im Prozess 17 (Lithosphere_Stock)\n",
    "#         'outflow_id': 'F_05_07', # NEU: Der exakte Name des Abflusses, der berechnet werden soll\n",
    "#         'f': 0.5, \n",
    "#         'k1': 0.5, \n",
    "#         'k2': 0.5\n",
    "#     }\n",
    "# }\n",
    "\n",
    "    \n",
    "    # Example for a second FOMP in another process (e.g., process 16):\n",
    "    # 16: {\n",
    "    #     'f': 0.1,\n",
    "    #     'k1': 0.05,\n",
    "    #     'k2': 0.001\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4f6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Validation for DSM Lifetimes\n",
    "# This function checks and corrects DSM lifetime parameters to ensure realistic values.\n",
    "def validate_dsm_lifetimes(dsm_params):\n",
    "    \"\"\"Enhanced validation for DSM lifetimes\n",
    "    Ensures lifetimes and standard deviations are within realistic bounds.\n",
    "    \"\"\"\n",
    "    for process_id, params in dsm_params.items():\n",
    "        lifetimes = params['lifetimes']['Mean']\n",
    "        std_devs = params['lifetimes']['StdDev']\n",
    "        \n",
    "        for i, (lt, std) in enumerate(zip(lifetimes, std_devs)):\n",
    "            # Check minimum lifetime\n",
    "            if lt < 2.0:  # Minimum 2 years for processing\n",
    "                print(f\"âš ï¸ WARNING: Process {process_id} lifetime {lt} years too short\")\n",
    "                print(f\"   Minimum recommended: 2 years for processing stability\")\n",
    "                params['lifetimes']['Mean'][i] = 2.0\n",
    "                print(f\"   Auto-corrected to {params['lifetimes']['Mean'][i]} years\")\n",
    "            \n",
    "            # Check std dev vs mean ratio\n",
    "            if std > lt * 0.8:  # StdDev shouldn't exceed 80% of mean\n",
    "                print(f\"âš ï¸ WARNING: Process {process_id} StdDev {std} too large vs Mean {lt}\")\n",
    "                params['lifetimes']['StdDev'][i] = lt * 0.5  # Set to 50% of mean\n",
    "                print(f\"   Auto-corrected StdDev to {params['lifetimes']['StdDev'][i]} years\")\n",
    "                \n",
    "    return dsm_params\n",
    "\n",
    "\n",
    "# Apply enhanced validation\n",
    "DSM_PARAMS = validate_dsm_lifetimes(DSM_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bca2dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'inflow_split': [1], 'lifetimes': {'Type': 'Normal', 'Mean': [20], 'StdDev': [4]}, 'category_names': ['Average Exchange']}, 2: {'inflow_split': [1], 'lifetimes': {'Type': 'Normal', 'Mean': [6], 'StdDev': [2]}, 'category_names': ['Air Drying']}, 3: {'inflow_split': [1], 'lifetimes': {'Type': 'Normal', 'Mean': [80], 'StdDev': [16]}, 'category_names': ['Average Lifetime']}, 7: {'inflow_split': [1], 'lifetimes': {'Type': 'Normal', 'Mean': [70], 'StdDev': [2]}, 'category_names': ['Photosynthesis']}, 8: {'inflow_split': [1], 'lifetimes': {'Type': 'Normal', 'Mean': [], 'StdDev': []}, 'category_names': []}}\n"
     ]
    }
   ],
   "source": [
    "print(DSM_PARAMS)\n",
    "#print(FOMP_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc42ab-027c-4385-8b92-a00ca8ba063c",
   "metadata": {},
   "source": [
    "# Section 2: Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7186852-b1ff-4ca9-b244-78aec61745e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Section 2: Function Definitions\n",
    "# ====================================================================\n",
    "\n",
    "# --- Helper Function 2.1: Define Model Scope & Classifications ---\n",
    "\n",
    "\n",
    "def define_model_scope(start_year, end_year, elements):\n",
    "    \"\"\"\n",
    "    Defines the temporal and elemental scope of the MFA model. \n",
    "    Creates the ModelClassification dictionary and IndexTable DataFrame,\n",
    "    which are core ODYM objects used for calculations\n",
    "\n",
    "    Args:\n",
    "        start_year (int): The first year of the analysis.\n",
    "        end_year (int): The last year of the analysis.\n",
    "        elements (list): A list of strings for the elements to be tracked.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the ModelClassification dictionary \n",
    "               and the IndexTable DataFrame.\n",
    "    \"\"\"\n",
    "    ModelClassification = {} # Initialize an empty dictionary to hold model classifications\n",
    "    MyYears = list(np.arange(start_year, end_year + 1)) # Generata a list of years (MyYears) from start_year to end_year (inclusive)\n",
    "\n",
    "    \n",
    "    # Define Time and Element Classifications for the ODYM framework\n",
    "    # Creates a dictionary called ModelClassification that stores ODYM Classification objects for 'Time' and 'Element'.\n",
    "    ModelClassification['Time'] = msc.Classification(Name='Time', Dimension='Time', ID=1, Items=MyYears)\n",
    "    ModelClassification['Element'] = msc.Classification(Name='Elements', Dimension='Element', ID=2, Items=elements)\n",
    "\n",
    "    # Create the IndexTable (Pandas DataFrame), which ODYM uses for calculations\n",
    "    IndexTable = pd.DataFrame({\n",
    "        'Aspect': ['Time', 'Element'],\n",
    "        'Description': ['Model aspect \"time\"', 'Model aspect \"Element\"'],\n",
    "        'Dimension': ['Time', 'Element'],\n",
    "        'Classification': [ModelClassification[Aspect] for Aspect in ['Time', 'Element']],\n",
    "        'IndexLetter': ['t', 'e']\n",
    "    })\n",
    "    IndexTable.set_index('Aspect', inplace=True)\n",
    "    \n",
    "    print(\"--> Model scope and classifications defined.\")\n",
    "    return ModelClassification, IndexTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493df12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing define_model_scope Function ===\n",
      "\n",
      "Test 1: Basic functionality\n",
      "--> Model scope and classifications defined.\n",
      "âœ… Test 1 passed: Basic functionality works correctly\n",
      "   - Years: 1920 to 2045 (126 years)\n",
      "   - Elements: ['material', 'WC', 'DM', 'CC']\n",
      "   - IndexTable shape: (2, 4)\n",
      "\n",
      "Test 2: Edge case - single year\n",
      "--> Model scope and classifications defined.\n",
      "âœ… Test 2 passed: Single year case works correctly\n",
      "\n",
      "Test 3: Different element configuration\n",
      "--> Model scope and classifications defined.\n",
      "âœ… Test 3 passed: Different element set works correctly\n",
      "\n",
      "Test 4: Detailed object inspection\n",
      "--> Model scope and classifications defined.\n",
      "ðŸ“Š ModelClassification structure:\n",
      "   Time: Classification\n",
      "      - Name: Time\n",
      "      - Dimension: Time\n",
      "      - ID: 1\n",
      "      - Items count: 126\n",
      "      - First/Last: 1920/2045\n",
      "   Element: Classification\n",
      "      - Name: Elements\n",
      "      - Dimension: Element\n",
      "      - ID: 2\n",
      "      - Items count: 4\n",
      "      - Items: ['material', 'WC', 'DM', 'CC']\n",
      "\n",
      "ðŸ“Š IndexTable structure:\n",
      "                    Description Dimension  \\\n",
      "Aspect                                      \n",
      "Time        Model aspect \"time\"      Time   \n",
      "Element  Model aspect \"Element\"   Element   \n",
      "\n",
      "                                            Classification IndexLetter  \n",
      "Aspect                                                                  \n",
      "Time     <ODYM_Classes.Classification object at 0x00000...           t  \n",
      "Element  <ODYM_Classes.Classification object at 0x00000...           e  \n",
      "   Index: ['Time', 'Element']\n",
      "   Columns: ['Description', 'Dimension', 'Classification', 'IndexLetter']\n",
      "âœ… Test 4 passed: Detailed inspection completed\n",
      "\n",
      "ðŸŽ‰ All tests passed! The define_model_scope function is working correctly.\n",
      "\n",
      "==================================================\n",
      "READY TO USE: define_model_scope function is validated!\n",
      "You can now use it in your MFA workflow.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Test Function for define_model_scope ---\n",
    "def test_define_model_scope():\n",
    "    \"\"\"\n",
    "    Test function to verify that define_model_scope works correctly.\n",
    "    Tests various scenarios and validates the output structure.\n",
    "    \"\"\"\n",
    "    print(\"=== Testing define_model_scope Function ===\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Basic functionality with your project parameters\n",
    "        print(\"Test 1: Basic functionality\")\n",
    "        start_year = 1920\n",
    "        end_year = 2045\n",
    "        elements = ['material', 'WC', 'DM', 'CC']\n",
    "        \n",
    "        model_classification, index_table = define_model_scope(start_year, end_year, elements)\n",
    "        \n",
    "        # Validate results\n",
    "        assert isinstance(model_classification, dict), \"ModelClassification should be a dictionary\"\n",
    "        assert 'Time' in model_classification, \"Time classification missing\"\n",
    "        assert 'Element' in model_classification, \"Element classification missing\"\n",
    "        \n",
    "        # Check time classification\n",
    "        time_items = model_classification['Time'].Items\n",
    "        assert len(time_items) == (end_year - start_year + 1), f\"Expected {end_year - start_year + 1} years, got {len(time_items)}\"\n",
    "        assert time_items[0] == start_year, f\"First year should be {start_year}, got {time_items[0]}\"\n",
    "        assert time_items[-1] == end_year, f\"Last year should be {end_year}, got {time_items[-1]}\"\n",
    "        \n",
    "        # Check element classification\n",
    "        element_items = model_classification['Element'].Items\n",
    "        assert element_items == elements, f\"Elements don't match. Expected {elements}, got {element_items}\"\n",
    "        \n",
    "        # Check IndexTable structure\n",
    "        assert isinstance(index_table, pd.DataFrame), \"IndexTable should be a DataFrame\"\n",
    "        assert list(index_table.index) == ['Time', 'Element'], \"IndexTable index should be ['Time', 'Element']\"\n",
    "        \n",
    "        print(\"âœ… Test 1 passed: Basic functionality works correctly\")\n",
    "        print(f\"   - Years: {start_year} to {end_year} ({len(time_items)} years)\")\n",
    "        print(f\"   - Elements: {elements}\")\n",
    "        print(f\"   - IndexTable shape: {index_table.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test 1 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test 2: Edge case - single year\n",
    "        print(\"\\nTest 2: Edge case - single year\")\n",
    "        model_classification_2, index_table_2 = define_model_scope(2023, 2023, ['carbon'])\n",
    "        \n",
    "        time_items_2 = model_classification_2['Time'].Items\n",
    "        assert len(time_items_2) == 1, f\"Expected 1 year, got {len(time_items_2)}\"\n",
    "        assert time_items_2[0] == 2023, f\"Expected 2023, got {time_items_2[0]}\"\n",
    "        \n",
    "        print(\"âœ… Test 2 passed: Single year case works correctly\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test 2 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test 3: Different element set\n",
    "        print(\"\\nTest 3: Different element configuration\")\n",
    "        model_classification_3, index_table_3 = define_model_scope(2000, 2010, ['mass', 'carbon', 'nitrogen'])\n",
    "        \n",
    "        element_items_3 = model_classification_3['Element'].Items\n",
    "        expected_elements = ['mass', 'carbon', 'nitrogen']\n",
    "        assert element_items_3 == expected_elements, f\"Expected {expected_elements}, got {element_items_3}\"\n",
    "        \n",
    "        print(\"âœ… Test 3 passed: Different element set works correctly\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test 3 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 4: Display detailed information about the objects created\n",
    "    print(\"\\nTest 4: Detailed object inspection\")\n",
    "    try:\n",
    "        model_classification, index_table = define_model_scope(1920, 2045, ['material', 'WC', 'DM', 'CC'])\n",
    "        \n",
    "        print(\"ðŸ“Š ModelClassification structure:\")\n",
    "        for key, classification in model_classification.items():\n",
    "            print(f\"   {key}: {classification.__class__.__name__}\")\n",
    "            print(f\"      - Name: {classification.Name}\")\n",
    "            print(f\"      - Dimension: {classification.Dimension}\")\n",
    "            print(f\"      - ID: {classification.ID}\")\n",
    "            print(f\"      - Items count: {len(classification.Items)}\")\n",
    "            if key == 'Time':\n",
    "                print(f\"      - First/Last: {classification.Items[0]}/{classification.Items[-1]}\")\n",
    "            else:\n",
    "                print(f\"      - Items: {classification.Items}\")\n",
    "        \n",
    "        print(\"\\nðŸ“Š IndexTable structure:\")\n",
    "        print(index_table)\n",
    "        print(f\"   Index: {list(index_table.index)}\")\n",
    "        print(f\"   Columns: {list(index_table.columns)}\")\n",
    "        \n",
    "        print(\"âœ… Test 4 passed: Detailed inspection completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test 4 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ All tests passed! The define_model_scope function is working correctly.\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# === Main execution block ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the test function\n",
    "    test_result = test_define_model_scope()\n",
    "    \n",
    "    if test_result:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"READY TO USE: define_model_scope function is validated!\")\n",
    "        print(\"You can now use it in your MFA workflow.\")\n",
    "        print(\"=\"*50)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ISSUES FOUND: Please review the function implementation.\")\n",
    "        print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf87136-469d-4cc8-b602-c92d43a2d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function 2.2: Initialize the main MFA System object ---\n",
    "\n",
    "def initialize_mfa_system(model_classification, index_table):\n",
    "    \"\"\"\n",
    "    Initializes the main MFAsystem object based on the defined scope.\n",
    "\n",
    "    Args:\n",
    "        model_classification (dict): The ModelClassification dictionary from define_model_scope.\n",
    "        index_table (pd.DataFrame): The IndexTable DataFrame from define_model_scope.\n",
    "\n",
    "    Returns:\n",
    "        odym.MFAsystem (MFAsystem object): An empty but structured MFAsystem object.\n",
    "    \"\"\"\n",
    "    # Extract scope details from the input objects\n",
    "    start_time = model_classification['Time'].Items[0]\n",
    "    end_time = model_classification['Time'].Items[-1]\n",
    "    element_items = model_classification['Element'].Items\n",
    "    \n",
    "    # Create the main system object using the ODYM class\n",
    "    MFA_System = msc.MFAsystem(\n",
    "        Name='TimberTruss_MFA', \n",
    "        Geogr_Scope='Eichkamp_Kiez', \n",
    "        Unit='Mg', \n",
    "        ProcessList=[], \n",
    "        FlowDict={}, \n",
    "        StockDict={},\n",
    "        ParameterDict={}, \n",
    "        Time_Start=start_time, \n",
    "        Time_End=end_time, \n",
    "        IndexTable=index_table, \n",
    "        Elements=element_items\n",
    "    )\n",
    "    \n",
    "    print(\"--> MFA system object initialized.\")\n",
    "    return MFA_System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "924b5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function 2.3: Load data and define processes and stocks (Updated with Fixed Tracking)\n",
    "\n",
    "def load_and_define_processes(mfa_system, EXCEL_FILE_PATH):\n",
    "    \"\"\"\n",
    "    Loads all data from the Excel file, treating 'N.A.' as a missing value,\n",
    "    and populates the ProcessList and StockDict in the MFA system.\n",
    "    Prints how many processes, stocks, transfer coefficients, and dynamic transfer coefficients were created.\n",
    "\n",
    "    Args: \n",
    "        mfa_system (msc.MFAsystem): The initialized MFA system object from initialize_mfa_system.\n",
    "        EXCEL_FILE_PATH (str): Path to the Excel file containing process definitions.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated MFA system object and the input data as a DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "    # Load Excel file\n",
    "    input_data = pd.read_excel(\n",
    "        EXCEL_FILE_PATH,\n",
    "        sheet_name=None,\n",
    "        header=0,\n",
    "        engine='openpyxl',\n",
    "        na_values=['N.A.', 'NA', 'n/a']\n",
    "    )\n",
    "    print(f\"--> Excel file '{EXCEL_FILE_PATH}' loaded successfully.\")\n",
    "\n",
    "    process_definitions = input_data.get('2_1_Definition_Processes')\n",
    "    if process_definitions is None:\n",
    "        raise ValueError(\"Sheet '2_1_Definition_Processes' not found in Excel file.\")\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    created_processes = []\n",
    "    created_stocks = []\n",
    "    tc_count = 0\n",
    "    dynamic_tc_count = 0\n",
    "    \n",
    "    # Track different types of processes\n",
    "    tc_processes = []\n",
    "    dynamic_tc_processes = []\n",
    "    stock_processes = []\n",
    "\n",
    "    print(\"\\n=== PROCESSING PROCESS DEFINITIONS ===\")\n",
    "    \n",
    "    for index, row in process_definitions.iterrows():\n",
    "        if pd.notna(row['Name(EN)']): # Check if the process name is not empty\n",
    "            process_id = int(row['ID']) # Convert ID to integer\n",
    "            process_name = row['Name(EN)'] # Process name \n",
    "            \n",
    "            # Parse process characteristics \n",
    "            has_tc = str(row.get('TC?', '')).strip().lower() in ['yes', 'y', 'true', '1'] # Check if TC is defined\n",
    "            has_dynamic_tc = str(row.get('Dyn_TC?', '')).strip().lower() in ['yes', 'y', 'true', '1'] # Check if dynamic TC is defined\n",
    "            has_stock = str(row.get('Stock?', '')).strip().lower() in ['yes', 'y', 'true', '1'] # Check if stock is defined\n",
    "            \n",
    "            print(f\"  Processing: {process_name} (ID: {process_id})\")\n",
    "            print(f\"    TC: {has_tc}, Dynamic TC: {has_dynamic_tc}, Stock: {has_stock}\")\n",
    "\n",
    "            # Add process to system\n",
    "            extensions = [] \n",
    "            if has_tc: \n",
    "                extensions.append('TC')\n",
    "            if has_dynamic_tc:\n",
    "                extensions.append('DynTC')\n",
    "            if has_stock:\n",
    "                extensions.append('Stock')\n",
    "            \n",
    "            extension_str = ','.join(extensions) if extensions else 'None' \n",
    "            # Create the process object and append it to the system\n",
    "            mfa_system.ProcessList.append(\n",
    "                msc.Process(Name=process_name, ID=process_id, Extensions=extension_str)\n",
    "            )\n",
    "            created_processes.append(process_name)\n",
    "\n",
    "            # Track process types\n",
    "            if has_tc:\n",
    "                tc_processes.append(process_name)\n",
    "                tc_count += 1\n",
    "                \n",
    "            if has_dynamic_tc:\n",
    "                dynamic_tc_processes.append(process_name)\n",
    "                dynamic_tc_count += 1\n",
    "                \n",
    "            if has_stock:\n",
    "                stock_processes.append(process_name)\n",
    "\n",
    "            # Add stocks if specified\n",
    "            if has_stock:\n",
    "                ds_name = f\"dS_{process_id}\" # Dynamic stock name\n",
    "                s_name = f\"S_{process_id}\" # Static stock name\n",
    "                \n",
    "                mfa_system.StockDict[ds_name] = msc.Stock(\n",
    "                    Name=ds_name, P_Res=process_id, Type=1, Indices='t,e', Values=None\n",
    "                )\n",
    "                mfa_system.StockDict[s_name] = msc.Stock(\n",
    "                    Name=s_name, P_Res=process_id, Type=0, Indices='t,e', Values=None\n",
    "                )\n",
    "                \n",
    "                created_stocks.extend([ds_name, s_name])\n",
    "                print(f\"    âœ… Created stocks: {ds_name}, {s_name}\")\n",
    "\n",
    "    # Initialize stock values\n",
    "    print(\"\\n--> Initializing stock values...\")\n",
    "    mfa_system.Initialize_StockValues() \n",
    "\n",
    "    # Enhanced summary output\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PROCESS LOADING SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"ðŸ“Š PROCESSES:\")\n",
    "    print(f\"  Total processes created: {len(created_processes)}\")\n",
    "    print(f\"  Process names: {created_processes}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ TRANSFER COEFFICIENTS:\")\n",
    "    print(f\"  Static TC processes: {tc_count}\")\n",
    "    if tc_processes:\n",
    "        print(f\"  TC process names: {tc_processes}\")\n",
    "    \n",
    "    print(f\"  Dynamic TC processes: {dynamic_tc_count}\")\n",
    "    if dynamic_tc_processes:\n",
    "        print(f\"  Dynamic TC process names: {dynamic_tc_processes}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“¦ STOCKS:\")\n",
    "    print(f\"  Total stocks created: {len(created_stocks)}\")\n",
    "    if stock_processes:\n",
    "        print(f\"  Stock process names: {stock_processes}\")\n",
    "        print(f\"  Stock names: {created_stocks}\")\n",
    "    \n",
    "    if created_stocks:\n",
    "        try:\n",
    "            example_stock = mfa_system.StockDict[created_stocks[0]]\n",
    "            if hasattr(example_stock, 'Values') and example_stock.Values is not None:\n",
    "                print(f\"  Example stock array shape: {example_stock.Values.shape}\")\n",
    "            else:\n",
    "                print(\"  Stock arrays initialized but not yet populated\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not determine stock array shape: {e}\")\n",
    "    else:\n",
    "        print(\"  No stocks were created.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PROCESS LOADING COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Validation checks\n",
    "    print(f\"\\nðŸ” VALIDATION CHECKS:\")\n",
    "    print(f\"  âœ… Processes in system: {len(mfa_system.ProcessList)}\")\n",
    "    print(f\"  âœ… Stocks in system: {len(mfa_system.StockDict)}\")\n",
    "    \n",
    "    # Check for potential issues\n",
    "    if tc_count == 0 and dynamic_tc_count == 0:\n",
    "        print(\"  âš ï¸  WARNING: No transfer coefficients defined\")\n",
    "    \n",
    "    if len(created_stocks) == 0:\n",
    "        print(\"  âš ï¸  WARNING: No stocks defined\")\n",
    "    \n",
    "    if len(created_processes) == 0:\n",
    "        print(\"  âŒ ERROR: No processes were created!\")\n",
    "        \n",
    "    print()\n",
    "    return mfa_system, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e910d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Excel data loaded successfully. Preview:\n",
      "      -  ID  Process_ID      Name(EN)     Output_Flow  TC? DynTC?  Flow_ID  \\\n",
      "0  True   1           7    Atmosphere         Atm_Bio  Yes     No  F_07_00   \n",
      "1  True   2           0     Biosphere            Wood  Yes     No  F_00_01   \n",
      "2  True   3           5   Degredation         Deg_Bio  Yes     No  F_05_00   \n",
      "3  True   4           5   Degredation  Deg_Atm_Carbon  Yes     No  F_05_07   \n",
      "4  True   5           6  Incineration  Inc_Carbon_Atm  Yes     No  F_06_07   \n",
      "\n",
      "      TC_ID  Year  ...  Flow_ID_O_6 TC_ID_O_6_Year  TC_ID_O_6 TC O_6_[%]  \\\n",
      "0  TC_07_00  1920  ...          NaN        F_07_00        NaN        NaN   \n",
      "1  TC_00_01  1920  ...          NaN        F_00_01        NaN        NaN   \n",
      "2  TC_05_00  1920  ...          NaN        F_05_00        NaN        NaN   \n",
      "3  TC_05_07  1920  ...          NaN        F_05_07        NaN        NaN   \n",
      "4  TC_06_07  1920  ...          NaN        F_06_07        NaN        NaN   \n",
      "\n",
      "   Sum_TC_O  Titel Year publication  Author  Type of the Study URL  \n",
      "0         1    NaN              NaN     NaN                NaN NaN  \n",
      "1         1    NaN              NaN     NaN                NaN NaN  \n",
      "2         1    NaN              NaN     NaN                NaN NaN  \n",
      "3         1    NaN              NaN     NaN                NaN NaN  \n",
      "4         1    NaN              NaN     NaN                NaN NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "--> Generating dynamic TC time series via interpolation...\n",
      "Generated 15 dynamic TC parameter(s).\n",
      "\n",
      "TC_ID: TC_07_00\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "TC_ID: TC_00_01\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "TC_ID: TC_05_00\n",
      "[0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "\n",
      "TC_ID: TC_05_07\n",
      "[0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95]\n",
      "\n",
      "TC_ID: TC_06_07\n",
      "[0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "\n",
      "TC_ID: TC_06_08\n",
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "\n",
      "TC_ID: TC_02_03\n",
      "[0.5   0.502 0.504 0.506 0.508 0.51  0.512 0.514 0.516 0.518 0.52  0.522\n",
      " 0.524 0.526 0.528 0.53  0.532 0.534 0.536 0.538 0.54  0.542 0.544 0.546\n",
      " 0.548 0.55  0.552 0.554 0.556 0.558 0.56  0.562 0.564 0.566 0.568 0.57\n",
      " 0.572 0.574 0.576 0.578 0.58  0.582 0.584 0.586 0.588 0.59  0.592 0.594\n",
      " 0.596 0.598 0.6   0.604 0.608 0.612 0.616 0.62  0.624 0.628 0.632 0.636\n",
      " 0.64  0.644 0.648 0.652 0.656 0.66  0.664 0.668 0.672 0.676 0.68  0.684\n",
      " 0.688 0.692 0.696 0.7   0.701 0.702 0.703 0.704 0.705 0.706 0.707 0.708\n",
      " 0.709 0.71  0.711 0.712 0.713 0.714 0.715 0.716 0.717 0.718 0.719 0.72\n",
      " 0.721 0.722 0.723 0.724 0.725 0.726 0.727 0.728 0.729 0.73  0.731 0.732\n",
      " 0.733 0.734 0.735 0.736 0.737 0.738 0.739 0.74  0.741 0.742 0.743 0.744\n",
      " 0.745 0.746 0.747 0.748 0.749 0.75 ]\n",
      "\n",
      "TC_ID: TC_02_08\n",
      "[0.5   0.498 0.496 0.494 0.492 0.49  0.488 0.486 0.484 0.482 0.48  0.478\n",
      " 0.476 0.474 0.472 0.47  0.468 0.466 0.464 0.462 0.46  0.458 0.456 0.454\n",
      " 0.452 0.45  0.448 0.446 0.444 0.442 0.44  0.438 0.436 0.434 0.432 0.43\n",
      " 0.428 0.426 0.424 0.422 0.42  0.418 0.416 0.414 0.412 0.41  0.408 0.406\n",
      " 0.404 0.402 0.4   0.396 0.392 0.388 0.384 0.38  0.376 0.372 0.368 0.364\n",
      " 0.36  0.356 0.352 0.348 0.344 0.34  0.336 0.332 0.328 0.324 0.32  0.316\n",
      " 0.312 0.308 0.304 0.3   0.299 0.298 0.297 0.296 0.295 0.294 0.293 0.292\n",
      " 0.291 0.29  0.289 0.288 0.287 0.286 0.285 0.284 0.283 0.282 0.281 0.28\n",
      " 0.279 0.278 0.277 0.276 0.275 0.274 0.273 0.272 0.271 0.27  0.269 0.268\n",
      " 0.267 0.266 0.265 0.264 0.263 0.262 0.261 0.26  0.259 0.258 0.257 0.256\n",
      " 0.255 0.254 0.253 0.252 0.251 0.25 ]\n",
      "\n",
      "TC_ID: TC_01_00\n",
      "[0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3]\n",
      "\n",
      "TC_ID: TC_01_02\n",
      "[0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7]\n",
      "\n",
      "TC_ID: TC_04_03\n",
      "[0.05    0.04968 0.04936 0.04904 0.04872 0.0484  0.04808 0.04776 0.04744\n",
      " 0.04712 0.0468  0.04648 0.04616 0.04584 0.04552 0.0452  0.04488 0.04456\n",
      " 0.04424 0.04392 0.0436  0.04328 0.04296 0.04264 0.04232 0.042   0.04168\n",
      " 0.04136 0.04104 0.04072 0.0404  0.04008 0.03976 0.03944 0.03912 0.0388\n",
      " 0.03848 0.03816 0.03784 0.03752 0.0372  0.03688 0.03656 0.03624 0.03592\n",
      " 0.0356  0.03528 0.03496 0.03464 0.03432 0.034   0.03368 0.03336 0.03304\n",
      " 0.03272 0.0324  0.03208 0.03176 0.03144 0.03112 0.0308  0.03048 0.03016\n",
      " 0.02984 0.02952 0.0292  0.02888 0.02856 0.02824 0.02792 0.0276  0.02728\n",
      " 0.02696 0.02664 0.02632 0.026   0.02568 0.02536 0.02504 0.02472 0.0244\n",
      " 0.02408 0.02376 0.02344 0.02312 0.0228  0.02248 0.02216 0.02184 0.02152\n",
      " 0.0212  0.02088 0.02056 0.02024 0.01992 0.0196  0.01928 0.01896 0.01864\n",
      " 0.01832 0.018   0.01768 0.01736 0.01704 0.01672 0.0164  0.01608 0.01576\n",
      " 0.01544 0.01512 0.0148  0.01448 0.01416 0.01384 0.01352 0.0132  0.01288\n",
      " 0.01256 0.01224 0.01192 0.0116  0.01128 0.01096 0.01064 0.01032 0.01   ]\n",
      "\n",
      "TC_ID: TC_04_08\n",
      "[0.95    0.95032 0.95064 0.95096 0.95128 0.9516  0.95192 0.95224 0.95256\n",
      " 0.95288 0.9532  0.95352 0.95384 0.95416 0.95448 0.9548  0.95512 0.95544\n",
      " 0.95576 0.95608 0.9564  0.95672 0.95704 0.95736 0.95768 0.958   0.95832\n",
      " 0.95864 0.95896 0.95928 0.9596  0.95992 0.96024 0.96056 0.96088 0.9612\n",
      " 0.96152 0.96184 0.96216 0.96248 0.9628  0.96312 0.96344 0.96376 0.96408\n",
      " 0.9644  0.96472 0.96504 0.96536 0.96568 0.966   0.96632 0.96664 0.96696\n",
      " 0.96728 0.9676  0.96792 0.96824 0.96856 0.96888 0.9692  0.96952 0.96984\n",
      " 0.97016 0.97048 0.9708  0.97112 0.97144 0.97176 0.97208 0.9724  0.97272\n",
      " 0.97304 0.97336 0.97368 0.974   0.97432 0.97464 0.97496 0.97528 0.9756\n",
      " 0.97592 0.97624 0.97656 0.97688 0.9772  0.97752 0.97784 0.97816 0.97848\n",
      " 0.9788  0.97912 0.97944 0.97976 0.98008 0.9804  0.98072 0.98104 0.98136\n",
      " 0.98168 0.982   0.98232 0.98264 0.98296 0.98328 0.9836  0.98392 0.98424\n",
      " 0.98456 0.98488 0.9852  0.98552 0.98584 0.98616 0.98648 0.9868  0.98712\n",
      " 0.98744 0.98776 0.98808 0.9884  0.98872 0.98904 0.98936 0.98968 0.99   ]\n",
      "\n",
      "TC_ID: TC_03_04\n",
      "[0.05       0.0504     0.0508     0.0512     0.0516     0.052\n",
      " 0.0524     0.0528     0.0532     0.0536     0.054      0.0544\n",
      " 0.0548     0.0552     0.0556     0.056      0.0564     0.0568\n",
      " 0.0572     0.0576     0.058      0.0584     0.0588     0.0592\n",
      " 0.0596     0.06       0.0608     0.0616     0.0624     0.0632\n",
      " 0.064      0.0648     0.0656     0.0664     0.0672     0.068\n",
      " 0.0688     0.0696     0.0704     0.0712     0.072      0.0728\n",
      " 0.0736     0.0744     0.0752     0.076      0.0768     0.0776\n",
      " 0.0784     0.0792     0.08       0.08066667 0.08133333 0.082\n",
      " 0.08266667 0.08333333 0.084      0.08466667 0.08533333 0.086\n",
      " 0.08666667 0.08733333 0.088      0.08866667 0.08933333 0.09\n",
      " 0.09066667 0.09133333 0.092      0.09266667 0.09333333 0.094\n",
      " 0.09466667 0.09533333 0.096      0.09666667 0.09733333 0.098\n",
      " 0.09866667 0.09933333 0.1        0.10222222 0.10444444 0.10666667\n",
      " 0.10888889 0.11111111 0.11333333 0.11555556 0.11777778 0.12\n",
      " 0.12222222 0.12444444 0.12666667 0.12888889 0.13111111 0.13333333\n",
      " 0.13555556 0.13777778 0.14       0.14222222 0.14444444 0.14666667\n",
      " 0.14888889 0.15111111 0.15333333 0.15555556 0.15777778 0.16\n",
      " 0.16222222 0.16444444 0.16666667 0.16888889 0.17111111 0.17333333\n",
      " 0.17555556 0.17777778 0.18       0.18222222 0.18444444 0.18666667\n",
      " 0.18888889 0.19111111 0.19333333 0.19555556 0.19777778 0.2       ]\n",
      "\n",
      "TC_ID: TC_03_05\n",
      "[0.25       0.2476     0.2452     0.2428     0.2404     0.238\n",
      " 0.2356     0.2332     0.2308     0.2284     0.226      0.2236\n",
      " 0.2212     0.2188     0.2164     0.214      0.2116     0.2092\n",
      " 0.2068     0.2044     0.202      0.1996     0.1972     0.1948\n",
      " 0.1924     0.19       0.1872     0.1844     0.1816     0.1788\n",
      " 0.176      0.1732     0.1704     0.1676     0.1648     0.162\n",
      " 0.1592     0.1564     0.1536     0.1508     0.148      0.1452\n",
      " 0.1424     0.1396     0.1368     0.134      0.1312     0.1284\n",
      " 0.1256     0.1228     0.12       0.11766667 0.11533333 0.113\n",
      " 0.11066667 0.10833333 0.106      0.10366667 0.10133333 0.099\n",
      " 0.09666667 0.09433333 0.092      0.08966667 0.08733333 0.085\n",
      " 0.08266667 0.08033333 0.078      0.07566667 0.07333333 0.071\n",
      " 0.06866667 0.06633333 0.064      0.06166667 0.05933333 0.057\n",
      " 0.05466667 0.05233333 0.05       0.04933333 0.04866667 0.048\n",
      " 0.04733333 0.04666667 0.046      0.04533333 0.04466667 0.044\n",
      " 0.04333333 0.04266667 0.042      0.04133333 0.04066667 0.04\n",
      " 0.03933333 0.03866667 0.038      0.03733333 0.03666667 0.036\n",
      " 0.03533333 0.03466667 0.034      0.03333333 0.03266667 0.032\n",
      " 0.03133333 0.03066667 0.03       0.02933333 0.02866667 0.028\n",
      " 0.02733333 0.02666667 0.026      0.02533333 0.02466667 0.024\n",
      " 0.02333333 0.02266667 0.022      0.02133333 0.02066667 0.02      ]\n",
      "\n",
      "TC_ID: TC_03_06\n",
      "[0.7        0.702      0.704      0.706      0.708      0.71\n",
      " 0.712      0.714      0.716      0.718      0.72       0.722\n",
      " 0.724      0.726      0.728      0.73       0.732      0.734\n",
      " 0.736      0.738      0.74       0.742      0.744      0.746\n",
      " 0.748      0.75       0.752      0.754      0.756      0.758\n",
      " 0.76       0.762      0.764      0.766      0.768      0.77\n",
      " 0.772      0.774      0.776      0.778      0.78       0.782\n",
      " 0.784      0.786      0.788      0.79       0.792      0.794\n",
      " 0.796      0.798      0.8        0.80166667 0.80333333 0.805\n",
      " 0.80666667 0.80833333 0.81       0.81166667 0.81333333 0.815\n",
      " 0.81666667 0.81833333 0.82       0.82166667 0.82333333 0.825\n",
      " 0.82666667 0.82833333 0.83       0.83166667 0.83333333 0.835\n",
      " 0.83666667 0.83833333 0.84       0.84166667 0.84333333 0.845\n",
      " 0.84666667 0.84833333 0.85       0.84844444 0.84688889 0.84533333\n",
      " 0.84377778 0.84222222 0.84066667 0.83911111 0.83755556 0.836\n",
      " 0.83444444 0.83288889 0.83133333 0.82977778 0.82822222 0.82666667\n",
      " 0.82511111 0.82355556 0.822      0.82044444 0.81888889 0.81733333\n",
      " 0.81577778 0.81422222 0.81266667 0.81111111 0.80955556 0.808\n",
      " 0.80644444 0.80488889 0.80333333 0.80177778 0.80022222 0.79866667\n",
      " 0.79711111 0.79555556 0.794      0.79244444 0.79088889 0.78933333\n",
      " 0.78777778 0.78622222 0.78466667 0.78311111 0.78155556 0.78      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nasty\\anaconda3\\envs\\bioDYM_anaconda_environment\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Helper Function 2.4: Create dynamic TC time series from long table with interpolation\n",
    "\n",
    "def create_dynamic_tc_parameters(dynamic_tc_data, time_vector):\n",
    "    \"\"\"\n",
    "    Generates time series for TCs by reading a long data table and interpolating\n",
    "    between the defined data points for each year in the model scope.\n",
    "\n",
    "    Args:\n",
    "        dynamic_tc_data (pd.DataFrame): DataFrame loaded from the dynamic TCs sheet.\n",
    "        time_vector (list): The list of years for the analysis.\n",
    "\n",
    "    Returns:\n",
    "        dynamic_tc_dict (dict): A dictionary of TC names and their complete time series arrays.\n",
    "    \"\"\"\n",
    "    print(\"--> Generating dynamic TC time series via interpolation...\")\n",
    "    dynamic_tc_dict = {}\n",
    "    \n",
    "    if 'TC_ID' not in dynamic_tc_data.columns:\n",
    "        print(\"Warning: 'TC_ID' column not found in dynamic TCs sheet. Skipping.\")\n",
    "        return {}\n",
    "        \n",
    "    unique_tc_ids = dynamic_tc_data['TC_ID'].dropna().unique() # Ensure unique TC_IDs and drop NaN values\n",
    "    \n",
    "    # Check if there are any unique TC_IDs\n",
    "    for tc_id in unique_tc_ids:\n",
    "        tc_points = dynamic_tc_data[dynamic_tc_data['TC_ID'] == tc_id] \n",
    "\n",
    "        # Ensure there are 'Year' and 'Value' columns\n",
    "        if not {'Year', 'Value'}.issubset(tc_points.columns):\n",
    "            print(f\"Skipping TC_ID {tc_id} due to missing columns.\")\n",
    "            continue\n",
    "\n",
    "        ts = pd.Series(tc_points['Value'].values, index=tc_points['Year']) # Create a time series with 'Year' as index\n",
    "        ts_full = ts.reindex(time_vector) # Reindex to the full time vector\n",
    "        ts_interpolated = ts_full.interpolate(method='linear', limit_direction='both') # Interpolate missing values with a linear method\n",
    "        dynamic_tc_dict[tc_id] = ts_interpolated.to_numpy() # Convert to numpy array for consistency\n",
    "\n",
    "    print(f\"Generated {len(dynamic_tc_dict)} dynamic TC parameter(s).\")\n",
    "    return dynamic_tc_dict\n",
    "\n",
    "\n",
    "# === Main Execution Block ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Define model years\n",
    "    time_vector = list(range(1920, 2046)) # From 1920 to 2045 inclusive\n",
    "\n",
    "    # Excel file details\n",
    "    sheet_name = \"2_5_dynamic_tcs\"\n",
    "\n",
    "    try:\n",
    "        # Load the Excel sheet into a DataFrame\n",
    "        dynamic_tc_data = pd.read_excel(EXCEL_FILE_PATH, sheet_name=sheet_name, engine='openpyxl')\n",
    "        print(\"âœ… Excel data loaded successfully. Preview:\")\n",
    "        print(dynamic_tc_data.head())\n",
    "\n",
    "        # Run the function\n",
    "        result = create_dynamic_tc_parameters(dynamic_tc_data, time_vector)\n",
    "\n",
    "        # Print each result\n",
    "        for tc_id, series in result.items():\n",
    "            print(f\"\\nTC_ID: {tc_id}\")\n",
    "            print(series)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file or processing data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02ac273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function 2.5: Define flows and all model parameters \n",
    "\n",
    "def define_flows_and_parameters(mfa_system, all_excel_data, dsm_params_config):\n",
    "    \"\"\"\n",
    "    Defines all flows and parameters, with ONLY F_00_01 getting data from Excel.\n",
    "    This function sets up the flow structure, adds numerical data to flows,\n",
    "    defines all parameters, and calculates elemental compositions for primary input flows.\n",
    "\n",
    "    Args:\n",
    "        mfa_system (msc.MFAsystem): The initialized MFA system object from initialize_mfa_system from load_and_define_processes\n",
    "        all_excel_data (dict): Dictionary containing all loaded Excel data from load_and_define_processes.\n",
    "        dsm_params_config (dict): Configuration dictionary for DSM parameters.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated MFA system object and the input data as a DataFrame       \n",
    "    \"\"\"\n",
    "    # --- Step 1: Define flow structure ---\n",
    "    flow_definitions = all_excel_data['1_1_Definition_Flows']\n",
    "    for index, row in flow_definitions.iterrows():\n",
    "        if pd.notna(row['Name(EN)']):\n",
    "            import re\n",
    "            \n",
    "            # mapping of origin and destination\n",
    "            origin_id_str = str(row['Process_ID_O'])      # O = Origin = P_Start\n",
    "            destination_id_str = str(row['Process_ID_I'])  # I = Input = P_End\n",
    "            \n",
    "            origin_match = re.match(r'(\\d+)', origin_id_str) # Match the origin ID\n",
    "            destination_match = re.match(r'(\\d+)', destination_id_str) # Match the destination ID\n",
    "            \n",
    "            if origin_match and destination_match: # Ensure both matches are successful\n",
    "                origin_id = int(origin_match.group(1)) # Origin becomes P_Start\n",
    "                destination_id = int(destination_match.group(1)) # Destination becomes P_End\n",
    "\n",
    "                # #Ensure both IDs are valid integers before creating the flow object\n",
    "                # Ensure correct P_Start and P_End assignment\n",
    "\n",
    "                mfa_system.FlowDict[row['Flow_ID']] = msc.Flow(\n",
    "                    Name=row['Flow_ID'], \n",
    "                    P_Start=origin_id,      # Origin becomes P_Start\n",
    "                    P_End=destination_id,   # Destination becomes P_End\n",
    "                    Indices='t,e', \n",
    "                    Values=None\n",
    "                )\n",
    "    \n",
    "    mfa_system.Initialize_FlowValues()\n",
    "    print(\"--> Defined flows.\")\n",
    "    \n",
    "\n",
    "    # --- Step 2: Add numerical data to flows ---\n",
    "    flow_data = all_excel_data['1_2_Data_Flows']\n",
    "    for flow_id, flow_obj in mfa_system.FlowDict.items():\n",
    "        if flow_id in flow_data['Flow_ID'].values:\n",
    "            flow_time_series = flow_data[flow_data['Flow_ID'] == flow_id]\n",
    "            if len(flow_time_series) == len(mfa_system.IndexTable.Classification['Time'].Items):\n",
    "                flow_obj.Values[:, 0] = np.array(flow_time_series['Flow_Py']).ravel()\n",
    "    \n",
    "    print(\"--> Added numerical data to input flows.\")\n",
    "\n",
    "    # --- Step 3: Define all Parameters ---\n",
    "    parameter_id_counter = 1\n",
    "    \n",
    "    # Dynamic TCs - properly call the function\n",
    "    dynamic_tc_sheet = all_excel_data.get('2_5_dynamic_tcs')\n",
    "    if dynamic_tc_sheet is not None and not dynamic_tc_sheet.empty:\n",
    "        print(\"--> Processing dynamic TCs...\")\n",
    "        time_items = mfa_system.IndexTable.Classification['Time'].Items\n",
    "        \n",
    "        # Call the function properly\n",
    "        dynamic_tcs = create_dynamic_tc_parameters(dynamic_tc_sheet, time_items)\n",
    "        \n",
    "        # Add them to the system\n",
    "        for name, values in dynamic_tcs.items():\n",
    "            mfa_system.ParameterDict[name] = msc.Parameter(\n",
    "                Name=name, \n",
    "                ID=parameter_id_counter, \n",
    "                Values=values, \n",
    "                Unit='1'\n",
    "            )\n",
    "            parameter_id_counter += 1\n",
    "            print(f\"    -> Added dynamic TC: {name}\")\n",
    "        \n",
    "        print(f\"--> Created {len(dynamic_tcs)} dynamic TC parameters\")\n",
    "    else:\n",
    "        print(\"--> No dynamic TC data found or sheet is empty\")\n",
    "        \n",
    "    # Elemental Contents\n",
    "    content_definitions = all_excel_data['1_1_Definition_Flows']\n",
    "    for index, row in content_definitions.iterrows():\n",
    "        if pd.notna(row['Flow_ID']) and row['Flow_ID'] in mfa_system.FlowDict:\n",
    "            for element in ['WC', 'DM', 'CC']:\n",
    "                if element in row and pd.notna(row[element]):\n",
    "                    mfa_system.ParameterDict[f\"{element}_{row['Flow_ID']}\"] = msc.Parameter(\n",
    "                        Name=f\"{element}_{row['Flow_ID']}\", ID=parameter_id_counter, Values=row[element], Unit='1'\n",
    "                    )\n",
    "                    parameter_id_counter += 1\n",
    "    \n",
    "    # DSM Parameters \n",
    "    for process_id, params in dsm_params_config.items(): # Loop through each process ID in the DSM parameters configuration\n",
    "        for param_name, value in params['lifetimes'].items(): # Loop through each parameter name and value\n",
    "            mfa_system.ParameterDict[f\"dsm_{process_id}_{param_name}\"] = msc.Parameter(\n",
    "                Name=f\"dsm_{process_id}_{param_name}\", ID=parameter_id_counter, P_Res=process_id, Values=value, Unit='yr'\n",
    "            ) # Create a new parameter object\n",
    "            parameter_id_counter += 1\n",
    "            \n",
    "    print(f\"--> Defined {len(mfa_system.ParameterDict)} parameters.\")\n",
    "\n",
    "    # --- Step 4: Calculate elemental composition for primary input flows ---\n",
    "    print(\"--> Calculating elemental composition for primary input flows...\")\n",
    "    for flow in mfa_system.FlowDict.values():\n",
    "        # Check if the material flow for this flow is already filled\n",
    "        if np.any(flow.Values[:, 0] != 0):\n",
    "            # Loop through WC, DM, CC and calculate their values\n",
    "            for i_elem, element_name in enumerate(mfa_system.Elements[1:], 1):\n",
    "                param_name = f\"{element_name}_{flow.Name}\"\n",
    "                if param_name in mfa_system.ParameterDict:\n",
    "                    content_value = mfa_system.ParameterDict[param_name].Values\n",
    "                    flow.Values[:, i_elem] = flow.Values[:, 0] * content_value\n",
    "    \n",
    "    # --- Final Consistency Check ---\n",
    "    mfa_system.Consistency_Check()\n",
    "    print(\"--> System setup is complete and ready for calculations!\")\n",
    "    \n",
    "    for flow_name, flow_obj in mfa_system.FlowDict.items():\n",
    "        print(f\"{flow_name}: {flow_obj.Values}\")\n",
    "\n",
    "    \n",
    "    return mfa_system, all_excel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a25259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Model scope and classifications defined.\n",
      "--> MFA system object initialized.\n",
      "--> Excel file '250731_V11.xlsx' loaded successfully.\n",
      "\n",
      "=== PROCESSING PROCESS DEFINITIONS ===\n",
      "  Processing: Biosphere (ID: 0)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_0, S_0\n",
      "  Processing: Raw Material Extraction (ID: 1)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Processing (ID: 2)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_2, S_2\n",
      "  Processing: Use (ID: 3)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_3, S_3\n",
      "  Processing: Refurbishment (ID: 4)\n",
      "    TC: True, Dynamic TC: True, Stock: False\n",
      "  Processing: Degredation (ID: 5)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Incineration (ID: 6)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Atmosphere (ID: 7)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_7, S_7\n",
      "  Processing: Anthroposphere (ID: 8)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_8, S_8\n",
      "\n",
      "--> Initializing stock values...\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING SUMMARY\n",
      "==================================================\n",
      "ðŸ“Š PROCESSES:\n",
      "  Total processes created: 9\n",
      "  Process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "\n",
      "ðŸ“ˆ TRANSFER COEFFICIENTS:\n",
      "  Static TC processes: 9\n",
      "  TC process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "  Dynamic TC processes: 3\n",
      "  Dynamic TC process names: ['Processing', 'Use', 'Refurbishment']\n",
      "\n",
      "ðŸ“¦ STOCKS:\n",
      "  Total stocks created: 10\n",
      "  Stock process names: ['Biosphere', 'Processing', 'Use', 'Atmosphere', 'Anthroposphere']\n",
      "  Stock names: ['dS_0', 'S_0', 'dS_2', 'S_2', 'dS_3', 'S_3', 'dS_7', 'S_7', 'dS_8', 'S_8']\n",
      "  Example stock array shape: (126, 4)\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING COMPLETE\n",
      "==================================================\n",
      "\n",
      "ðŸ” VALIDATION CHECKS:\n",
      "  âœ… Processes in system: 9\n",
      "  âœ… Stocks in system: 10\n",
      "\n",
      "--> Defined flows.\n",
      "--> Added numerical data to input flows.\n",
      "--> Processing dynamic TCs...\n",
      "--> Generating dynamic TC time series via interpolation...\n",
      "Generated 15 dynamic TC parameter(s).\n",
      "    -> Added dynamic TC: TC_07_00\n",
      "    -> Added dynamic TC: TC_00_01\n",
      "    -> Added dynamic TC: TC_05_00\n",
      "    -> Added dynamic TC: TC_05_07\n",
      "    -> Added dynamic TC: TC_06_07\n",
      "    -> Added dynamic TC: TC_06_08\n",
      "    -> Added dynamic TC: TC_02_03\n",
      "    -> Added dynamic TC: TC_02_08\n",
      "    -> Added dynamic TC: TC_01_00\n",
      "    -> Added dynamic TC: TC_01_02\n",
      "    -> Added dynamic TC: TC_04_03\n",
      "    -> Added dynamic TC: TC_04_08\n",
      "    -> Added dynamic TC: TC_03_04\n",
      "    -> Added dynamic TC: TC_03_05\n",
      "    -> Added dynamic TC: TC_03_06\n",
      "--> Created 15 dynamic TC parameters\n",
      "--> Defined 75 parameters.\n",
      "--> Calculating elemental composition for primary input flows...\n",
      "--> System setup is complete and ready for calculations!\n",
      "F_00_01: [[302.6   60.52 242.08 151.3 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [186.4   37.28 149.12  93.2 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [147.8   29.56 118.24  73.9 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [199.2   39.84 159.36  99.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [205.6   41.12 164.48 102.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]]\n",
      "F_01_02: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_01_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_04: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_05: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_06: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_07_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "=== DYNAMIC TC VERIFICATION ===\n",
      "Total TC parameters found: 15\n",
      "âœ… Dynamic TC: TC_07_00 (array length: 126)\n",
      "âœ… Dynamic TC: TC_00_01 (array length: 126)\n",
      "âœ… Dynamic TC: TC_05_00 (array length: 126)\n",
      "âœ… Dynamic TC: TC_05_07 (array length: 126)\n",
      "âœ… Dynamic TC: TC_06_07 (array length: 126)\n",
      "âœ… Dynamic TC: TC_06_08 (array length: 126)\n",
      "âœ… Dynamic TC: TC_02_03 (array length: 126)\n",
      "âœ… Dynamic TC: TC_02_08 (array length: 126)\n",
      "âœ… Dynamic TC: TC_01_00 (array length: 126)\n",
      "âœ… Dynamic TC: TC_01_02 (array length: 126)\n",
      "âœ… Dynamic TC: TC_04_03 (array length: 126)\n",
      "âœ… Dynamic TC: TC_04_08 (array length: 126)\n",
      "âœ… Dynamic TC: TC_03_04 (array length: 126)\n",
      "âœ… Dynamic TC: TC_03_05 (array length: 126)\n",
      "âœ… Dynamic TC: TC_03_06 (array length: 126)\n"
     ]
    }
   ],
   "source": [
    "# === Main Execution Block ===\n",
    "#1. Modellbereich und Klassifikationen definieren\n",
    "model_classification, index_table = define_model_scope(START_YEAR, END_YEAR, ELEMENTS)\n",
    "# 2. Leeres System initialisieren\n",
    "mfa_system = initialize_mfa_system(model_classification, index_table)\n",
    "# 3. Prozesse und Lager aus Excel laden\n",
    "mfa_system, input_data = load_and_define_processes(mfa_system, EXCEL_FILE_PATH)\n",
    "\n",
    "\n",
    "mfa_system_configured, _ = define_flows_and_parameters(mfa_system, input_data, DSM_PARAMS)\n",
    "\n",
    "# Check dynamic TCs\n",
    "print(\"=== DYNAMIC TC VERIFICATION ===\")\n",
    "dynamic_tc_params = {name: param for name, param in mfa_system_configured.ParameterDict.items() if name.startswith('TC_')}\n",
    "print(f\"Total TC parameters found: {len(dynamic_tc_params)}\")\n",
    "\n",
    "for tc_name, tc_param in dynamic_tc_params.items():\n",
    "    if hasattr(tc_param.Values, '__len__') and len(tc_param.Values) > 1:\n",
    "        print(f\"âœ… Dynamic TC: {tc_name} (array length: {len(tc_param.Values)})\")\n",
    "    else:\n",
    "        print(f\"ðŸ“Š Static TC: {tc_name} (value: {tc_param.Values})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b61574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TC PIPELINE DIAGNOSIS ===\n",
      "1. Dynamic TC sheet exists: True\n",
      "   Sheet shape: (37, 65)\n",
      "   Sheet empty: False\n",
      "   Columns: ['-', 'ID', 'Process_ID', 'Name(EN)', 'Output_Flow', 'TC?', 'DynTC?', 'Flow_ID', 'TC_ID', 'Year', 'Value', 'Stock?', 'Column1', 'Input_Flow_I_1', 'Flow_ID_I_1', 'Flow_TC_I_1_[%]', 'Input_Flow_I_2', 'Flow_ID_I_3', 'Flow_TC_I_2_[%]', 'Input_Flow_I_3', 'Flow ID I_3', 'Flow_TC_I_3_[%]', 'Input_Flow_I_4', 'Flow ID I_4', 'Flow_TC_I_4_[%]', 'Input_Flow_I_5', 'Flow ID I_5', 'Flow_TC_I_5_[%]', 'Sum_TC_I', 'Output_Flow_O_1', 'Flow_ID_O_1', 'TC_ID_O_1_Year', 'TC_ID_O_1', 'TC_O_1_[%]', 'Output_Flow_O_2', 'Flow_ID_O_2', 'TC_ID_O_2_Year', 'TC_ID_O_2', 'TC_O_2_[%]', 'Output_Flow_O_3', 'Flow_ID_O_3', 'TC_ID_O_3_Year', 'TC_ID_O_3', 'TC_O_3_[%]', 'Output_Flow_O_4', 'Flow_ID_O_4', 'TC_ID_O_4_Year', 'TC_ID_O_4', 'TC_O_4_[%]', 'Output_Flow_O_5', 'Flow_ID_O_5', 'TC_ID_O_5_Year', 'TC_ID_O_5', 'TC O_5_[%]', 'Output_Flow_O_6', 'Flow_ID_O_6', 'TC_ID_O_6_Year', 'TC_ID_O_6', 'TC O_6_[%]', 'Sum_TC_O', 'Titel', 'Year publication', 'Author', 'Type of the Study', 'URL']\n",
      "   First few rows:\n",
      "      -  ID  Process_ID      Name(EN)     Output_Flow  TC? DynTC?  Flow_ID  \\\n",
      "0  True   1           7    Atmosphere         Atm_Bio  Yes     No  F_07_00   \n",
      "1  True   2           0     Biosphere            Wood  Yes     No  F_00_01   \n",
      "2  True   3           5   Degredation         Deg_Bio  Yes     No  F_05_00   \n",
      "3  True   4           5   Degredation  Deg_Atm_Carbon  Yes     No  F_05_07   \n",
      "4  True   5           6  Incineration  Inc_Carbon_Atm  Yes     No  F_06_07   \n",
      "\n",
      "      TC_ID  Year  ...  Flow_ID_O_6 TC_ID_O_6_Year  TC_ID_O_6  TC O_6_[%]  \\\n",
      "0  TC_07_00  1920  ...          NaN        F_07_00        NaN         NaN   \n",
      "1  TC_00_01  1920  ...          NaN        F_00_01        NaN         NaN   \n",
      "2  TC_05_00  1920  ...          NaN        F_05_00        NaN         NaN   \n",
      "3  TC_05_07  1920  ...          NaN        F_05_07        NaN         NaN   \n",
      "4  TC_06_07  1920  ...          NaN        F_06_07        NaN         NaN   \n",
      "\n",
      "   Sum_TC_O  Titel  Year publication  Author  Type of the Study  URL  \n",
      "0         1    NaN               NaN     NaN                NaN  NaN  \n",
      "1         1    NaN               NaN     NaN                NaN  NaN  \n",
      "2         1    NaN               NaN     NaN                NaN  NaN  \n",
      "3         1    NaN               NaN     NaN                NaN  NaN  \n",
      "4         1    NaN               NaN     NaN                NaN  NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "2. All available Excel sheets: ['1_1_Definition_Flows', '1_2_Data_Flows', '2_1_Definition_Processes', '2_3_Process_TCs', '2_5_dynamic_tcs']\n",
      "\n",
      "3. Total parameters in system: 75\n",
      "   All parameter names:\n",
      "   - TC_07_00: <class 'numpy.ndarray'> = [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "   - TC_00_01: <class 'numpy.ndarray'> = [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "   - TC_05_00: <class 'numpy.ndarray'> = [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "   - TC_05_07: <class 'numpy.ndarray'> = [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95]\n",
      "   - TC_06_07: <class 'numpy.ndarray'> = [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99\n",
      " 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "   - TC_06_08: <class 'numpy.ndarray'> = [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "   - TC_02_03: <class 'numpy.ndarray'> = [0.5   0.502 0.504 0.506 0.508 0.51  0.512 0.514 0.516 0.518 0.52  0.522\n",
      " 0.524 0.526 0.528 0.53  0.532 0.534 0.536 0.538 0.54  0.542 0.544 0.546\n",
      " 0.548 0.55  0.552 0.554 0.556 0.558 0.56  0.562 0.564 0.566 0.568 0.57\n",
      " 0.572 0.574 0.576 0.578 0.58  0.582 0.584 0.586 0.588 0.59  0.592 0.594\n",
      " 0.596 0.598 0.6   0.604 0.608 0.612 0.616 0.62  0.624 0.628 0.632 0.636\n",
      " 0.64  0.644 0.648 0.652 0.656 0.66  0.664 0.668 0.672 0.676 0.68  0.684\n",
      " 0.688 0.692 0.696 0.7   0.701 0.702 0.703 0.704 0.705 0.706 0.707 0.708\n",
      " 0.709 0.71  0.711 0.712 0.713 0.714 0.715 0.716 0.717 0.718 0.719 0.72\n",
      " 0.721 0.722 0.723 0.724 0.725 0.726 0.727 0.728 0.729 0.73  0.731 0.732\n",
      " 0.733 0.734 0.735 0.736 0.737 0.738 0.739 0.74  0.741 0.742 0.743 0.744\n",
      " 0.745 0.746 0.747 0.748 0.749 0.75 ]\n",
      "   - TC_02_08: <class 'numpy.ndarray'> = [0.5   0.498 0.496 0.494 0.492 0.49  0.488 0.486 0.484 0.482 0.48  0.478\n",
      " 0.476 0.474 0.472 0.47  0.468 0.466 0.464 0.462 0.46  0.458 0.456 0.454\n",
      " 0.452 0.45  0.448 0.446 0.444 0.442 0.44  0.438 0.436 0.434 0.432 0.43\n",
      " 0.428 0.426 0.424 0.422 0.42  0.418 0.416 0.414 0.412 0.41  0.408 0.406\n",
      " 0.404 0.402 0.4   0.396 0.392 0.388 0.384 0.38  0.376 0.372 0.368 0.364\n",
      " 0.36  0.356 0.352 0.348 0.344 0.34  0.336 0.332 0.328 0.324 0.32  0.316\n",
      " 0.312 0.308 0.304 0.3   0.299 0.298 0.297 0.296 0.295 0.294 0.293 0.292\n",
      " 0.291 0.29  0.289 0.288 0.287 0.286 0.285 0.284 0.283 0.282 0.281 0.28\n",
      " 0.279 0.278 0.277 0.276 0.275 0.274 0.273 0.272 0.271 0.27  0.269 0.268\n",
      " 0.267 0.266 0.265 0.264 0.263 0.262 0.261 0.26  0.259 0.258 0.257 0.256\n",
      " 0.255 0.254 0.253 0.252 0.251 0.25 ]\n",
      "   - TC_01_00: <class 'numpy.ndarray'> = [0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      " 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3]\n",
      "   - TC_01_02: <class 'numpy.ndarray'> = [0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7\n",
      " 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7]\n",
      "   - TC_04_03: <class 'numpy.ndarray'> = [0.05    0.04968 0.04936 0.04904 0.04872 0.0484  0.04808 0.04776 0.04744\n",
      " 0.04712 0.0468  0.04648 0.04616 0.04584 0.04552 0.0452  0.04488 0.04456\n",
      " 0.04424 0.04392 0.0436  0.04328 0.04296 0.04264 0.04232 0.042   0.04168\n",
      " 0.04136 0.04104 0.04072 0.0404  0.04008 0.03976 0.03944 0.03912 0.0388\n",
      " 0.03848 0.03816 0.03784 0.03752 0.0372  0.03688 0.03656 0.03624 0.03592\n",
      " 0.0356  0.03528 0.03496 0.03464 0.03432 0.034   0.03368 0.03336 0.03304\n",
      " 0.03272 0.0324  0.03208 0.03176 0.03144 0.03112 0.0308  0.03048 0.03016\n",
      " 0.02984 0.02952 0.0292  0.02888 0.02856 0.02824 0.02792 0.0276  0.02728\n",
      " 0.02696 0.02664 0.02632 0.026   0.02568 0.02536 0.02504 0.02472 0.0244\n",
      " 0.02408 0.02376 0.02344 0.02312 0.0228  0.02248 0.02216 0.02184 0.02152\n",
      " 0.0212  0.02088 0.02056 0.02024 0.01992 0.0196  0.01928 0.01896 0.01864\n",
      " 0.01832 0.018   0.01768 0.01736 0.01704 0.01672 0.0164  0.01608 0.01576\n",
      " 0.01544 0.01512 0.0148  0.01448 0.01416 0.01384 0.01352 0.0132  0.01288\n",
      " 0.01256 0.01224 0.01192 0.0116  0.01128 0.01096 0.01064 0.01032 0.01   ]\n",
      "   - TC_04_08: <class 'numpy.ndarray'> = [0.95    0.95032 0.95064 0.95096 0.95128 0.9516  0.95192 0.95224 0.95256\n",
      " 0.95288 0.9532  0.95352 0.95384 0.95416 0.95448 0.9548  0.95512 0.95544\n",
      " 0.95576 0.95608 0.9564  0.95672 0.95704 0.95736 0.95768 0.958   0.95832\n",
      " 0.95864 0.95896 0.95928 0.9596  0.95992 0.96024 0.96056 0.96088 0.9612\n",
      " 0.96152 0.96184 0.96216 0.96248 0.9628  0.96312 0.96344 0.96376 0.96408\n",
      " 0.9644  0.96472 0.96504 0.96536 0.96568 0.966   0.96632 0.96664 0.96696\n",
      " 0.96728 0.9676  0.96792 0.96824 0.96856 0.96888 0.9692  0.96952 0.96984\n",
      " 0.97016 0.97048 0.9708  0.97112 0.97144 0.97176 0.97208 0.9724  0.97272\n",
      " 0.97304 0.97336 0.97368 0.974   0.97432 0.97464 0.97496 0.97528 0.9756\n",
      " 0.97592 0.97624 0.97656 0.97688 0.9772  0.97752 0.97784 0.97816 0.97848\n",
      " 0.9788  0.97912 0.97944 0.97976 0.98008 0.9804  0.98072 0.98104 0.98136\n",
      " 0.98168 0.982   0.98232 0.98264 0.98296 0.98328 0.9836  0.98392 0.98424\n",
      " 0.98456 0.98488 0.9852  0.98552 0.98584 0.98616 0.98648 0.9868  0.98712\n",
      " 0.98744 0.98776 0.98808 0.9884  0.98872 0.98904 0.98936 0.98968 0.99   ]\n",
      "   - TC_03_04: <class 'numpy.ndarray'> = [0.05       0.0504     0.0508     0.0512     0.0516     0.052\n",
      " 0.0524     0.0528     0.0532     0.0536     0.054      0.0544\n",
      " 0.0548     0.0552     0.0556     0.056      0.0564     0.0568\n",
      " 0.0572     0.0576     0.058      0.0584     0.0588     0.0592\n",
      " 0.0596     0.06       0.0608     0.0616     0.0624     0.0632\n",
      " 0.064      0.0648     0.0656     0.0664     0.0672     0.068\n",
      " 0.0688     0.0696     0.0704     0.0712     0.072      0.0728\n",
      " 0.0736     0.0744     0.0752     0.076      0.0768     0.0776\n",
      " 0.0784     0.0792     0.08       0.08066667 0.08133333 0.082\n",
      " 0.08266667 0.08333333 0.084      0.08466667 0.08533333 0.086\n",
      " 0.08666667 0.08733333 0.088      0.08866667 0.08933333 0.09\n",
      " 0.09066667 0.09133333 0.092      0.09266667 0.09333333 0.094\n",
      " 0.09466667 0.09533333 0.096      0.09666667 0.09733333 0.098\n",
      " 0.09866667 0.09933333 0.1        0.10222222 0.10444444 0.10666667\n",
      " 0.10888889 0.11111111 0.11333333 0.11555556 0.11777778 0.12\n",
      " 0.12222222 0.12444444 0.12666667 0.12888889 0.13111111 0.13333333\n",
      " 0.13555556 0.13777778 0.14       0.14222222 0.14444444 0.14666667\n",
      " 0.14888889 0.15111111 0.15333333 0.15555556 0.15777778 0.16\n",
      " 0.16222222 0.16444444 0.16666667 0.16888889 0.17111111 0.17333333\n",
      " 0.17555556 0.17777778 0.18       0.18222222 0.18444444 0.18666667\n",
      " 0.18888889 0.19111111 0.19333333 0.19555556 0.19777778 0.2       ]\n",
      "   - TC_03_05: <class 'numpy.ndarray'> = [0.25       0.2476     0.2452     0.2428     0.2404     0.238\n",
      " 0.2356     0.2332     0.2308     0.2284     0.226      0.2236\n",
      " 0.2212     0.2188     0.2164     0.214      0.2116     0.2092\n",
      " 0.2068     0.2044     0.202      0.1996     0.1972     0.1948\n",
      " 0.1924     0.19       0.1872     0.1844     0.1816     0.1788\n",
      " 0.176      0.1732     0.1704     0.1676     0.1648     0.162\n",
      " 0.1592     0.1564     0.1536     0.1508     0.148      0.1452\n",
      " 0.1424     0.1396     0.1368     0.134      0.1312     0.1284\n",
      " 0.1256     0.1228     0.12       0.11766667 0.11533333 0.113\n",
      " 0.11066667 0.10833333 0.106      0.10366667 0.10133333 0.099\n",
      " 0.09666667 0.09433333 0.092      0.08966667 0.08733333 0.085\n",
      " 0.08266667 0.08033333 0.078      0.07566667 0.07333333 0.071\n",
      " 0.06866667 0.06633333 0.064      0.06166667 0.05933333 0.057\n",
      " 0.05466667 0.05233333 0.05       0.04933333 0.04866667 0.048\n",
      " 0.04733333 0.04666667 0.046      0.04533333 0.04466667 0.044\n",
      " 0.04333333 0.04266667 0.042      0.04133333 0.04066667 0.04\n",
      " 0.03933333 0.03866667 0.038      0.03733333 0.03666667 0.036\n",
      " 0.03533333 0.03466667 0.034      0.03333333 0.03266667 0.032\n",
      " 0.03133333 0.03066667 0.03       0.02933333 0.02866667 0.028\n",
      " 0.02733333 0.02666667 0.026      0.02533333 0.02466667 0.024\n",
      " 0.02333333 0.02266667 0.022      0.02133333 0.02066667 0.02      ]\n",
      "   - TC_03_06: <class 'numpy.ndarray'> = [0.7        0.702      0.704      0.706      0.708      0.71\n",
      " 0.712      0.714      0.716      0.718      0.72       0.722\n",
      " 0.724      0.726      0.728      0.73       0.732      0.734\n",
      " 0.736      0.738      0.74       0.742      0.744      0.746\n",
      " 0.748      0.75       0.752      0.754      0.756      0.758\n",
      " 0.76       0.762      0.764      0.766      0.768      0.77\n",
      " 0.772      0.774      0.776      0.778      0.78       0.782\n",
      " 0.784      0.786      0.788      0.79       0.792      0.794\n",
      " 0.796      0.798      0.8        0.80166667 0.80333333 0.805\n",
      " 0.80666667 0.80833333 0.81       0.81166667 0.81333333 0.815\n",
      " 0.81666667 0.81833333 0.82       0.82166667 0.82333333 0.825\n",
      " 0.82666667 0.82833333 0.83       0.83166667 0.83333333 0.835\n",
      " 0.83666667 0.83833333 0.84       0.84166667 0.84333333 0.845\n",
      " 0.84666667 0.84833333 0.85       0.84844444 0.84688889 0.84533333\n",
      " 0.84377778 0.84222222 0.84066667 0.83911111 0.83755556 0.836\n",
      " 0.83444444 0.83288889 0.83133333 0.82977778 0.82822222 0.82666667\n",
      " 0.82511111 0.82355556 0.822      0.82044444 0.81888889 0.81733333\n",
      " 0.81577778 0.81422222 0.81266667 0.81111111 0.80955556 0.808\n",
      " 0.80644444 0.80488889 0.80333333 0.80177778 0.80022222 0.79866667\n",
      " 0.79711111 0.79555556 0.794      0.79244444 0.79088889 0.78933333\n",
      " 0.78777778 0.78622222 0.78466667 0.78311111 0.78155556 0.78      ]\n",
      "   - WC_F_00_01: <class 'float'> = 0.2\n",
      "   - DM_F_00_01: <class 'float'> = 0.8\n",
      "   - CC_F_00_01: <class 'float'> = 0.5\n",
      "   - WC_F_01_02: <class 'float'> = 0.2\n",
      "   - DM_F_01_02: <class 'float'> = 0.8\n",
      "   - CC_F_01_02: <class 'float'> = 0.5\n",
      "   - WC_F_01_00: <class 'float'> = 0.2\n",
      "   - DM_F_01_00: <class 'float'> = 0.8\n",
      "   - CC_F_01_00: <class 'float'> = 0.5\n",
      "   - WC_F_02_03: <class 'float'> = 0.2\n",
      "   - DM_F_02_03: <class 'float'> = 0.8\n",
      "   - CC_F_02_03: <class 'float'> = 0.5\n",
      "   - WC_F_03_04: <class 'float'> = 0.2\n",
      "   - DM_F_03_04: <class 'float'> = 0.8\n",
      "   - CC_F_03_04: <class 'float'> = 0.5\n",
      "   - WC_F_04_03: <class 'float'> = 0.2\n",
      "   - DM_F_04_03: <class 'float'> = 0.8\n",
      "   - CC_F_04_03: <class 'float'> = 0.5\n",
      "   - WC_F_03_05: <class 'float'> = 0.2\n",
      "   - DM_F_03_05: <class 'float'> = 0.8\n",
      "   - CC_F_03_05: <class 'float'> = 0.5\n",
      "   - WC_F_03_06: <class 'float'> = 0.2\n",
      "   - DM_F_03_06: <class 'float'> = 0.8\n",
      "   - CC_F_03_06: <class 'float'> = 0.5\n",
      "   - WC_F_05_07: <class 'float'> = 0.2\n",
      "   - DM_F_05_07: <class 'float'> = 0.8\n",
      "   - CC_F_05_07: <class 'float'> = 0.5\n",
      "   - WC_F_05_00: <class 'float'> = 0.2\n",
      "   - DM_F_05_00: <class 'float'> = 0.8\n",
      "   - CC_F_05_00: <class 'float'> = 0.5\n",
      "   - WC_F_06_07: <class 'float'> = 0.2\n",
      "   - DM_F_06_07: <class 'float'> = 0.8\n",
      "   - CC_F_06_07: <class 'float'> = 0.5\n",
      "   - WC_F_06_08: <class 'float'> = 0.2\n",
      "   - DM_F_06_08: <class 'float'> = 0.8\n",
      "   - CC_F_06_08: <class 'float'> = 0.5\n",
      "   - WC_F_02_08: <class 'float'> = 0.2\n",
      "   - DM_F_02_08: <class 'float'> = 0.8\n",
      "   - CC_F_02_08: <class 'float'> = 0.5\n",
      "   - WC_F_04_08: <class 'float'> = 0.2\n",
      "   - DM_F_04_08: <class 'float'> = 0.8\n",
      "   - CC_F_04_08: <class 'float'> = 0.5\n",
      "   - WC_F_07_00: <class 'float'> = 0.2\n",
      "   - DM_F_07_00: <class 'float'> = 0.8\n",
      "   - CC_F_07_00: <class 'float'> = 0.5\n",
      "   - dsm_0_Type: <class 'str'> = Normal\n",
      "   - dsm_0_Mean: <class 'list'> = [20]\n",
      "   - dsm_0_StdDev: <class 'list'> = [4]\n",
      "   - dsm_2_Type: <class 'str'> = Normal\n",
      "   - dsm_2_Mean: <class 'list'> = [6]\n",
      "   - dsm_2_StdDev: <class 'list'> = [2]\n",
      "   - dsm_3_Type: <class 'str'> = Normal\n",
      "   - dsm_3_Mean: <class 'list'> = [80]\n",
      "   - dsm_3_StdDev: <class 'list'> = [16]\n",
      "   - dsm_7_Type: <class 'str'> = Normal\n",
      "   - dsm_7_Mean: <class 'list'> = [70]\n",
      "   - dsm_7_StdDev: <class 'list'> = [2]\n",
      "   - dsm_8_Type: <class 'str'> = Normal\n",
      "   - dsm_8_Mean: <class 'list'> = []\n",
      "   - dsm_8_StdDev: <class 'list'> = []\n",
      "\n",
      "4. Testing create_dynamic_tc_parameters directly...\n",
      "   Time items: 126\n",
      "--> Generating dynamic TC time series via interpolation...\n",
      "Generated 15 dynamic TC parameter(s).\n",
      "   Function returned: 15 TCs\n",
      "   - TC_07_00: 126 values\n",
      "   - TC_00_01: 126 values\n",
      "   - TC_05_00: 126 values\n",
      "   - TC_05_07: 126 values\n",
      "   - TC_06_07: 126 values\n",
      "   - TC_06_08: 126 values\n",
      "   - TC_02_03: 126 values\n",
      "   - TC_02_08: 126 values\n",
      "   - TC_01_00: 126 values\n",
      "   - TC_01_02: 126 values\n",
      "   - TC_04_03: 126 values\n",
      "   - TC_04_08: 126 values\n",
      "   - TC_03_04: 126 values\n",
      "   - TC_03_05: 126 values\n",
      "   - TC_03_06: 126 values\n"
     ]
    }
   ],
   "source": [
    "# Test Function: COMPREHENSIVE TC DIAGNOSIS ===\n",
    "\n",
    "print(\"=== TC PIPELINE DIAGNOSIS ===\")\n",
    "\n",
    "# Step 1: Check if dynamic_tc_sheet exists and has data\n",
    "dynamic_tc_sheet = input_data.get('2_5_dynamic_tcs')\n",
    "print(f\"1. Dynamic TC sheet exists: {dynamic_tc_sheet is not None}\")\n",
    "if dynamic_tc_sheet is not None:\n",
    "    print(f\"   Sheet shape: {dynamic_tc_sheet.shape}\")\n",
    "    print(f\"   Sheet empty: {dynamic_tc_sheet.empty}\")\n",
    "    print(f\"   Columns: {list(dynamic_tc_sheet.columns)}\")\n",
    "    print(f\"   First few rows:\")\n",
    "    print(dynamic_tc_sheet.head())\n",
    "\n",
    "# Step 2: Check if the dynamic TC section is being reached\n",
    "print(f\"\\n2. All available Excel sheets: {list(input_data.keys())}\")\n",
    "\n",
    "# Step 3: Check ALL parameters in the system\n",
    "print(f\"\\n3. Total parameters in system: {len(mfa_system.ParameterDict)}\")\n",
    "print(\"   All parameter names:\")\n",
    "for name in mfa_system.ParameterDict.keys():\n",
    "    param = mfa_system.ParameterDict[name]\n",
    "    print(f\"   - {name}: {type(param.Values)} = {param.Values}\")\n",
    "\n",
    "# Step 4: Test the function directly\n",
    "print(f\"\\n4. Testing create_dynamic_tc_parameters directly...\")\n",
    "if dynamic_tc_sheet is not None and not dynamic_tc_sheet.empty:\n",
    "    time_items = mfa_system.IndexTable.Classification['Time'].Items\n",
    "    print(f\"   Time items: {len(time_items)}\")\n",
    "    try:\n",
    "        test_result = create_dynamic_tc_parameters(dynamic_tc_sheet, time_items)\n",
    "        print(f\"   Function returned: {len(test_result)} TCs\")\n",
    "        for name, values in test_result.items():\n",
    "            print(f\"   - {name}: {len(values) if hasattr(values, '__len__') else 1} values\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87971cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1_2_DATA_FLOWS CONTENT CHECK ===\n",
      "Available Flow_IDs: ['F_00_01']\n",
      "Number of data rows per flow:\n",
      "  F_00_01: 126 rows\n",
      "\n",
      "Expected number of years: 126\n",
      "\n",
      "F_00_01 data preview:\n",
      "  Rows: 126\n",
      "  Sample values: [302.6, 173.6, 186.4, 173.6, 115.8]\n",
      "  Value range: 0.0 to 302.6\n"
     ]
    }
   ],
   "source": [
    "# Test function: FLOW DATA VERIFICATION === \n",
    "# Check what's actually in 1_2_Data_Flows sheet\n",
    "\n",
    "flow_data = input_data['1_2_Data_Flows']\n",
    "print(\"=== 1_2_DATA_FLOWS CONTENT CHECK ===\")\n",
    "print(f\"Available Flow_IDs: {list(flow_data['Flow_ID'].unique())}\")\n",
    "print(f\"Number of data rows per flow:\")\n",
    "for flow_id in flow_data['Flow_ID'].unique():\n",
    "    count = len(flow_data[flow_data['Flow_ID'] == flow_id])\n",
    "    print(f\"  {flow_id}: {count} rows\")\n",
    "\n",
    "print(f\"\\nExpected number of years: {len(mfa_system.IndexTable.Classification['Time'].Items)}\")\n",
    "\n",
    "# Check if F_00_01 has the right amount of data\n",
    "f_00_01_data = flow_data[flow_data['Flow_ID'] == 'F_00_01']\n",
    "print(f\"\\nF_00_01 data preview:\")\n",
    "print(f\"  Rows: {len(f_00_01_data)}\")\n",
    "if not f_00_01_data.empty:\n",
    "    print(f\"  Sample values: {f_00_01_data['Flow_Py'].head().tolist()}\")\n",
    "    print(f\"  Value range: {f_00_01_data['Flow_Py'].min()} to {f_00_01_data['Flow_Py'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7309bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel elemental content values:\n",
      "F_00_01: CC=0.5, DM=0.8, WC=0.2\n",
      "F_01_02: CC=0.5, DM=0.8, WC=0.2\n",
      "F_01_00: CC=0.5, DM=0.8, WC=0.2\n",
      "F_02_03: CC=0.5, DM=0.8, WC=0.2\n",
      "F_03_04: CC=0.5, DM=0.8, WC=0.2\n",
      "F_04_03: CC=0.5, DM=0.8, WC=0.2\n",
      "F_03_05: CC=0.5, DM=0.8, WC=0.2\n",
      "F_03_06: CC=0.5, DM=0.8, WC=0.2\n",
      "F_05_07: CC=0.5, DM=0.8, WC=0.2\n",
      "F_05_00: CC=0.5, DM=0.8, WC=0.2\n",
      "F_06_07: CC=0.5, DM=0.8, WC=0.2\n",
      "F_06_08: CC=0.5, DM=0.8, WC=0.2\n",
      "F_02_08: CC=0.5, DM=0.8, WC=0.2\n",
      "F_04_08: CC=0.5, DM=0.8, WC=0.2\n",
      "F_07_00: CC=0.5, DM=0.8, WC=0.2\n"
     ]
    }
   ],
   "source": [
    "# Test function: Check Excel elemental content values\n",
    "\n",
    "flow_defs = input_data['1_1_Definition_Flows']\n",
    "print(\"Excel elemental content values:\")\n",
    "for index, row in flow_defs.iterrows():\n",
    "    if pd.notna(row.get('Flow_ID')):\n",
    "        flow_id = row['Flow_ID']\n",
    "        cc = row.get('CC', 'N/A')\n",
    "        dm = row.get('DM', 'N/A') \n",
    "        wc = row.get('WC', 'N/A')\n",
    "        print(f\"{flow_id}: CC={cc}, DM={dm}, WC={wc}\")\n",
    "        \n",
    "        if cc == 1.0:\n",
    "            print(f\"  âŒ PROBLEM: CC=1.0 should be ~0.5!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function 2.6: Calculate dynamic stocks with automatic elemental content reading.\n",
    "\n",
    "\"\"\" \n",
    "This function calculates dynamic stocks for the MFA system using the DSM model. It automatically reads elemental contents from Excel parameters,\n",
    "ensuring that the elemental composition is correctly applied to the outflow values. \n",
    "The function handles missing parameters by using default values and provides detailed results for each process. \n",
    "\n",
    "Args: \n",
    "    mfa_system (msc.MFASystem): The MFA system object containing processes, flows, and parameters.\n",
    "    dsm_params_config (dict): Configuration dictionary for DSM parameters, including lifetimes, inflow splits, and category names.  \n",
    "\n",
    "Returns:\n",
    "    tuple: A tuple containing the modified MFA system and a dictionary with detailed results for each process.\n",
    "    mfa_system (msc.MFASystem): The modified MFA system with updated flow values.\n",
    "    dsm_details_results (dict): A dictionary containing detailed results for each process, including category\n",
    "\"\"\"\n",
    "\n",
    "def calculate_dynamic_stock(mfa_system, dsm_params_config):\n",
    "    \"\"\"\n",
    "    Enhanced DSM calculation with automatic elemental content reading from Excel\n",
    "    \"\"\"\n",
    "    print(\"--> Calculating dynamic stocks with automatic elemental content...\")\n",
    "    time_vector = np.array(mfa_system.IndexTable.Classification['Time'].Items)\n",
    "    dsm_details_results = {} \n",
    "\n",
    "    # âœ… AUTO-READ ELEMENTAL CONTENTS FROM EXCEL\n",
    "    def get_elemental_content_from_excel(flow_name, element):\n",
    "        \"\"\"Helper function to read elemental content from Excel parameters\"\"\"\n",
    "        param_name = f\"{element}_{flow_name}\"\n",
    "        if param_name in mfa_system.ParameterDict:\n",
    "            return float(mfa_system.ParameterDict[param_name].Values)\n",
    "        else:\n",
    "            # Default values if not found in Excel\n",
    "            defaults = {'CC': 0.5, 'DM': 0.9, 'WC': 0.1}\n",
    "            print(f\"âš ï¸ Warning: {param_name} not found, using default {element}={defaults[element]}\")\n",
    "            return defaults[element]\n",
    "\n",
    "    for process_id, params in dsm_params_config.items():\n",
    "        if not any(p.ID == process_id for p in mfa_system.ProcessList):\n",
    "            print(f\"Warning: Process {process_id} from DSM_PARAMS not found in model. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"    ... running DSM for process {process_id}\")\n",
    "        dsm_details_results[process_id] = {'category_names': [], 'stock_by_category': []}\n",
    "\n",
    "        # Get inflow and outflow flow objects\n",
    "        inflow_flow = next((f for f in mfa_system.FlowDict.values() if f.P_End == process_id), None)\n",
    "        outflow_flow = next((f for f in mfa_system.FlowDict.values() if f.P_Start == process_id), None)\n",
    "        \n",
    "        if not inflow_flow or not outflow_flow:\n",
    "            print(f\"Warning: Missing inflow or outflow for process {process_id}\")\n",
    "            continue\n",
    "\n",
    "        inflow_values = inflow_flow.Values # Materil flow over time\n",
    "        if inflow_values.ndim == 1:\n",
    "            inflow_values = inflow_values.reshape(-1, 1)\n",
    "\n",
    "        # âœ… AUTO-READ ELEMENTAL CONTENTS FOR THIS FLOW\n",
    "        inflow_cc_content = get_elemental_content_from_excel(inflow_flow.Name, 'CC')\n",
    "        inflow_dm_content = get_elemental_content_from_excel(inflow_flow.Name, 'DM') \n",
    "        inflow_wc_content = get_elemental_content_from_excel(inflow_flow.Name, 'WC')\n",
    "        \n",
    "        print(f\"      Auto-read elemental contents for {inflow_flow.Name}:\")\n",
    "        print(f\"        CC: {inflow_cc_content:.1%}\")\n",
    "        print(f\"        DM: {inflow_dm_content:.1%}\")\n",
    "        print(f\"        WC: {inflow_wc_content:.1%}\")\n",
    "\n",
    "        # DSM parameters\n",
    "        lt_params = params.get('lifetimes', {}) # Ensure lt_params is a dict\n",
    "        inflow_split = params.get('inflow_split', [1.0]) # Default to [1.0] if not provided\n",
    "        category_names = params.get('category_names', []) # Default to empty list if not provided\n",
    "        mean_lifetimes = lt_params.get('Mean', []) # Default to empty list if not provided\n",
    "        std_devs = lt_params.get('StdDev', []) # Default to empty list if not provided\n",
    "\n",
    "        category_labels = [f\"{name} ({lt} yrs)\" for name, lt in zip(category_names, mean_lifetimes)] # Create category labels with lifetimes\n",
    "        dsm_details_results[process_id]['category_names'] = category_labels\n",
    "\n",
    "        # Initialize arrays\n",
    "        outflow_total_material = np.zeros(len(time_vector))\n",
    "        stock_total_material = np.zeros(len(time_vector))\n",
    "        stock_by_category_list = []\n",
    "\n",
    "        # DSM calculation for each category\n",
    "        for i in range(len(inflow_split)): \n",
    "            inflow_category = inflow_values[:, 0] * inflow_split[i]\n",
    "\n",
    "            if np.sum(inflow_category) > 0: #\n",
    "                dsm_model = dsm.DynamicStockModel(\n",
    "                    t=time_vector, # Years 1920-2045\n",
    "                    i=inflow_category, # Annual inflow\n",
    "                    lt={'Type': lt_params.get('Type'),  # Lifetime type\n",
    "                        'Mean': [mean_lifetimes[i]],  # Mean lifetime for this category\n",
    "                        'StdDev': [std_devs[i]]} #  Standard deviation for this category\n",
    "                )\n",
    "                s_c = dsm_model.compute_s_c_inflow_driven() # Calculate stock by cohort (s_c)\n",
    "                o_c = dsm_model.compute_o_c_from_s_c() # Calculate outflow by cohort (o_c) \n",
    "\n",
    "                if o_c is not None: # Aggregate across all cohorts\n",
    "                    outflow_total_material += o_c.sum(axis=1)\n",
    "                    stock_category_ts = s_c.sum(axis=1)\n",
    "                    stock_total_material += stock_category_ts\n",
    "                    stock_by_category_list.append(stock_category_ts)\n",
    "                else:\n",
    "                    stock_by_category_list.append(np.zeros(len(time_vector)))\n",
    "            else:\n",
    "                stock_by_category_list.append(np.zeros(len(time_vector)))\n",
    "\n",
    "        dsm_details_results[process_id]['stock_by_category'] = stock_by_category_list\n",
    "\n",
    "        # âœ… FIXED: Assign outflow with FIXED elemental composition\n",
    "        outflow_flow.Values[:, 0] = outflow_total_material\n",
    "        \n",
    "        # Calculate elemental flows using FIXED composition from Excel\n",
    "        element_contents = {\n",
    "            'CC': inflow_cc_content,\n",
    "            'DM': inflow_dm_content, \n",
    "            'WC': inflow_wc_content\n",
    "        }\n",
    "        \n",
    "        for idx_elem, element in enumerate(mfa_system.Elements[1:], 1):\n",
    "            if element in element_contents:\n",
    "                # Use fixed elemental content\n",
    "                content_value = element_contents[element]\n",
    "                outflow_flow.Values[:, idx_elem] = outflow_total_material * content_value\n",
    "                print(f\"        {element} outflow calculated with fixed content {content_value:.1%}\")\n",
    "            else:\n",
    "                print(f\"        âš ï¸ Unknown element {element}, setting to zero\")\n",
    "                outflow_flow.Values[:, idx_elem] = 0\n",
    "\n",
    "        # Calculate stock changes and absolute stocks with fixed composition\n",
    "        dS_values = inflow_values - outflow_flow.Values\n",
    "        mfa_system.StockDict[f'dS_{process_id}'].Values = dS_values\n",
    "\n",
    "        # âœ… FIXED: Calculate stocks with fixed elemental composition\n",
    "        mfa_system.StockDict[f'S_{process_id}'].Values[:, 0] = stock_total_material\n",
    "        \n",
    "        for idx_elem, element in enumerate(mfa_system.Elements[1:], 1):\n",
    "            if element in element_contents:\n",
    "                content_value = element_contents[element]\n",
    "                stock_total_element = stock_total_material * content_value\n",
    "                # Prevent negative stocks\n",
    "                stock_total_element = np.maximum(stock_total_element, 0)\n",
    "                mfa_system.StockDict[f'S_{process_id}'].Values[:, idx_elem] = stock_total_element\n",
    "            else:\n",
    "                mfa_system.StockDict[f'S_{process_id}'].Values[:, idx_elem] = 0\n",
    "\n",
    "        print(f\"      âœ… DSM completed for Process {process_id}\")\n",
    "\n",
    "    print(\"--> Dynamic stock calculation finished.\")\n",
    "    return mfa_system, dsm_details_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a813b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing calculate_dynamic_stock ===\n",
      "--> Model scope and classifications defined.\n",
      "--> MFA system object initialized.\n",
      "--> Excel file '250731_V11.xlsx' loaded successfully.\n",
      "\n",
      "=== PROCESSING PROCESS DEFINITIONS ===\n",
      "  Processing: Biosphere (ID: 0)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_0, S_0\n",
      "  Processing: Raw Material Extraction (ID: 1)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Processing (ID: 2)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_2, S_2\n",
      "  Processing: Use (ID: 3)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_3, S_3\n",
      "  Processing: Refurbishment (ID: 4)\n",
      "    TC: True, Dynamic TC: True, Stock: False\n",
      "  Processing: Degredation (ID: 5)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Incineration (ID: 6)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Atmosphere (ID: 7)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_7, S_7\n",
      "  Processing: Anthroposphere (ID: 8)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_8, S_8\n",
      "\n",
      "--> Initializing stock values...\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING SUMMARY\n",
      "==================================================\n",
      "ðŸ“Š PROCESSES:\n",
      "  Total processes created: 9\n",
      "  Process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "\n",
      "ðŸ“ˆ TRANSFER COEFFICIENTS:\n",
      "  Static TC processes: 9\n",
      "  TC process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "  Dynamic TC processes: 3\n",
      "  Dynamic TC process names: ['Processing', 'Use', 'Refurbishment']\n",
      "\n",
      "ðŸ“¦ STOCKS:\n",
      "  Total stocks created: 10\n",
      "  Stock process names: ['Biosphere', 'Processing', 'Use', 'Atmosphere', 'Anthroposphere']\n",
      "  Stock names: ['dS_0', 'S_0', 'dS_2', 'S_2', 'dS_3', 'S_3', 'dS_7', 'S_7', 'dS_8', 'S_8']\n",
      "  Example stock array shape: (126, 4)\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING COMPLETE\n",
      "==================================================\n",
      "\n",
      "ðŸ” VALIDATION CHECKS:\n",
      "  âœ… Processes in system: 9\n",
      "  âœ… Stocks in system: 10\n",
      "\n",
      "--> Defined flows.\n",
      "--> Added numerical data to input flows.\n",
      "--> Processing dynamic TCs...\n",
      "--> Generating dynamic TC time series via interpolation...\n",
      "Generated 15 dynamic TC parameter(s).\n",
      "    -> Added dynamic TC: TC_07_00\n",
      "    -> Added dynamic TC: TC_00_01\n",
      "    -> Added dynamic TC: TC_05_00\n",
      "    -> Added dynamic TC: TC_05_07\n",
      "    -> Added dynamic TC: TC_06_07\n",
      "    -> Added dynamic TC: TC_06_08\n",
      "    -> Added dynamic TC: TC_02_03\n",
      "    -> Added dynamic TC: TC_02_08\n",
      "    -> Added dynamic TC: TC_01_00\n",
      "    -> Added dynamic TC: TC_01_02\n",
      "    -> Added dynamic TC: TC_04_03\n",
      "    -> Added dynamic TC: TC_04_08\n",
      "    -> Added dynamic TC: TC_03_04\n",
      "    -> Added dynamic TC: TC_03_05\n",
      "    -> Added dynamic TC: TC_03_06\n",
      "--> Created 15 dynamic TC parameters\n",
      "--> Defined 75 parameters.\n",
      "--> Calculating elemental composition for primary input flows...\n",
      "--> System setup is complete and ready for calculations!\n",
      "F_00_01: [[302.6   60.52 242.08 151.3 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [186.4   37.28 149.12  93.2 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [147.8   29.56 118.24  73.9 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [199.2   39.84 159.36  99.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [205.6   41.12 164.48 102.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]]\n",
      "F_01_02: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_01_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_04: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_05: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_06: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_07_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 0\n",
      "      Auto-read elemental contents for F_01_00:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 0\n",
      "    ... running DSM for process 2\n",
      "      Auto-read elemental contents for F_01_02:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 2\n",
      "    ... running DSM for process 3\n",
      "      Auto-read elemental contents for F_02_03:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 3\n",
      "    ... running DSM for process 7\n",
      "      Auto-read elemental contents for F_05_07:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 7\n",
      "    ... running DSM for process 8\n",
      "Warning: Missing inflow or outflow for process 8\n",
      "--> Dynamic stock calculation finished.\n",
      "\n",
      "=== STOCK RESULTS ===\n",
      "Stock dS_0:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock S_0:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock dS_2:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock S_2:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock dS_3:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock S_3:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock dS_7:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock S_7:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock dS_8:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "Stock S_8:\n",
      "   - Shape: (126, 4)\n",
      "   - Min: 0.00\n",
      "   - Max: 0.00\n",
      "   - Final year total: 0.00\n",
      "\n",
      "=== DSM DETAILS ===\n",
      "Process 0:\n",
      "   - Categories: ['Average Exchange (20 yrs)']\n",
      "   - Stock categories: 1\n",
      "Process 2:\n",
      "   - Categories: ['Air Drying (6 yrs)']\n",
      "   - Stock categories: 1\n",
      "Process 3:\n",
      "   - Categories: ['Average Lifetime (80 yrs)']\n",
      "   - Stock categories: 1\n",
      "Process 7:\n",
      "   - Categories: ['Photosynthesis (70 yrs)']\n",
      "   - Stock categories: 1\n",
      "Process 8:\n",
      "   - Categories: []\n",
      "   - Stock categories: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Test Function for calculate_dynamic_stock \n",
    "\n",
    "def test_calculate_dynamic_stock():\n",
    "    \"\"\"\n",
    "    Simple test function for calculate_dynamic_stock.\n",
    "    \"\"\"\n",
    "    print(\"=== Testing calculate_dynamic_stock ===\")\n",
    "    \n",
    "    try:\n",
    "        # Setup test environment\n",
    "        model_classification, index_table = define_model_scope(START_YEAR, END_YEAR, ELEMENTS)\n",
    "        test_mfa_system = initialize_mfa_system(model_classification, index_table)\n",
    "        test_mfa_system, excel_data = load_and_define_processes(test_mfa_system, EXCEL_FILE_PATH)\n",
    "        test_mfa_system, _ = define_flows_and_parameters(test_mfa_system, excel_data, DSM_PARAMS)\n",
    "        \n",
    "        # Test the function\n",
    "        updated_system, dsm_details = calculate_dynamic_stock(test_mfa_system, DSM_PARAMS)\n",
    "        \n",
    "        # # Show results\n",
    "        # print(f\"âœ… Function executed successfully!\")\n",
    "        # print(f\"   - DSM processes calculated: {len(dsm_details)}\")\n",
    "        \n",
    "        # Show stock information\n",
    "        print(\"\\n=== STOCK RESULTS ===\")\n",
    "        for stock_name, stock_obj in updated_system.StockDict.items():\n",
    "            if stock_obj.Values is not None:\n",
    "                print(f\"Stock {stock_name}:\")\n",
    "                print(f\"   - Shape: {stock_obj.Values.shape}\")\n",
    "                print(f\"   - Min: {stock_obj.Values.min():.2f}\")\n",
    "                print(f\"   - Max: {stock_obj.Values.max():.2f}\")\n",
    "                print(f\"   - Final year total: {stock_obj.Values[-1, :].sum():.2f}\")\n",
    "        \n",
    "        # Show DSM details\n",
    "        print(\"\\n=== DSM DETAILS ===\")\n",
    "        for process_id, details in dsm_details.items():\n",
    "            print(f\"Process {process_id}:\")\n",
    "            print(f\"   - Categories: {details['category_names']}\")\n",
    "            print(f\"   - Stock categories: {len(details['stock_by_category'])}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# === EXECUTE THE TEST ===\n",
    "test_calculate_dynamic_stock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c72cf1fa-ab08-409e-883c-34b79627d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function 2.7: Calculate final stock changes and balances\n",
    "\n",
    "def calculate_final_balances(mfa_system):\n",
    "    \"\"\"\n",
    "    Calculates the stock changes (dS) and absolute stocks (S) for all processes.\n",
    "    Skip DSM processes to avoid overwriting their calculated stocks.\n",
    "\n",
    "    Args:\n",
    "        mfa_system (msc.MFASystem): The MFA system object containing processes, flows, and stocks.  \n",
    "\n",
    "    Returns:\n",
    "        mfa_system (msc.MFASystem): The modified MFA system with updated stock values\n",
    "    \"\"\"\n",
    "    print(\"--> Calculating final stock balances...\")\n",
    "    \n",
    "    # âœ… CRITICAL FIX: Skip both primary inputs AND DSM processes\n",
    "    PRIMARY_INPUT_PROCESSES = [0]  # Process 0 is Biosphere\n",
    "    DSM_PROCESSES = list(DSM_PARAMS.keys()) if 'DSM_PARAMS' in globals() else []\n",
    "    SKIP_PROCESSES = PRIMARY_INPUT_PROCESSES + DSM_PROCESSES\n",
    "    \n",
    "    for process in mfa_system.ProcessList:\n",
    "        # âœ… SKIP both primary inputs and DSM processes\n",
    "        if process.ID in SKIP_PROCESSES:\n",
    "            process_type = \"primary input\" if process.ID in PRIMARY_INPUT_PROCESSES else \"DSM\"\n",
    "            print(f\"  -> Skipping balance calculation for {process_type} process {process.ID} ({process.Name})\")\n",
    "            continue\n",
    "            \n",
    "        # Check if a stock is associated with this process\n",
    "        if f\"S_{process.ID}\" in mfa_system.StockDict:\n",
    "            \n",
    "            # Find all input and output flows for this process\n",
    "            input_flows = [f.Values for f in mfa_system.FlowDict.values() if f.P_End == process.ID]\n",
    "            output_flows = [f.Values for f in mfa_system.FlowDict.values() if f.P_Start == process.ID]\n",
    "            \n",
    "            sum_input_flows = sum(input_flows) if input_flows else 0\n",
    "            sum_output_flows = sum(output_flows) if output_flows else 0\n",
    "            \n",
    "            # Calculate stock change (dS) and absolute stock (S)\n",
    "            dS_values = sum_input_flows - sum_output_flows\n",
    "            mfa_system.StockDict[f\"dS_{process.ID}\"].Values = dS_values\n",
    "            mfa_system.StockDict[f\"S_{process.ID}\"].Values = dS_values.cumsum(axis=0)\n",
    "            \n",
    "            print(f\"  -> Calculated balance for Process {process.ID} ({process.Name})\")\n",
    "            \n",
    "    print(\"--> Stock balance calculation finished.\")\n",
    "    return mfa_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504f5e7d-285c-4391-bead-42bbd8bc3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function 2.8: Plot Mass Balance Error per Process  ---\n",
    "\n",
    "def plot_mass_balance_error(mfa_system_results):\n",
    "    \"\"\"\n",
    "    Creates an interactive bar chart showing the mass balance error for each process.\n",
    "    Error = Inflows - Outflows - dS. An error of 0 means perfect balance.\n",
    "\n",
    "    Args:\n",
    "        mfa_system_results (msc.MFASystem): The MFA system object after calculations, containing processes, flows, and stocks.\n",
    "    \n",
    "    Returns:\n",
    "        None: Displays an interactive plot.\n",
    "    \"\"\"\n",
    "\n",
    "    process_names = [p.Name for p in mfa_system_results.ProcessList]\n",
    "    time_items = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    element_items = mfa_system_results.Elements\n",
    "    \n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    def update_plot(year, element):\n",
    "        year_index = time_items.index(year)\n",
    "        element_index = element_items.index(element)\n",
    "        \n",
    "        errors = []\n",
    "        for p in mfa_system_results.ProcessList:\n",
    "            in_val = sum(f.Values[year_index, element_index] for f in mfa_system_results.FlowDict.values() if f.P_End == p.ID)\n",
    "            out_val = sum(f.Values[year_index, element_index] for f in mfa_system_results.FlowDict.values() if f.P_Start == p.ID)\n",
    "            ds_val = mfa_system_results.StockDict.get(f'dS_{p.ID}', None)\n",
    "            ds_sum = ds_val.Values[year_index, element_index] if ds_val is not None else 0\n",
    "            \n",
    "            error = in_val - out_val - ds_sum\n",
    "            errors.append(error)\n",
    "        \n",
    "        # Color bars based on error direction\n",
    "        colors = ['#d62728' if e > 1e-9 else '#2ca02c' if e < -1e-9 else '#7f7f7f' for e in errors] # Red for positive, Green for negative, Grey for zero\n",
    "\n",
    "        with fig.batch_update():\n",
    "            fig.data = [] # Clear previous data\n",
    "            fig.add_trace(go.Bar(x=process_names, y=errors, marker_color=colors))\n",
    "            fig.update_layout(\n",
    "                title=f\"Mass Balance Error Check for {element.upper()} in {year}\",\n",
    "                yaxis_title=\"Error in Mg (positive = mass created)\",\n",
    "                shapes=[dict(type='line', y0=0, y1=0, x0=-0.5, x1=len(process_names)-0.5, line=dict(color='black', width=2))] # Zero line\n",
    "            )\n",
    "\n",
    "    # Create widgets\n",
    "    year_slider = IntSlider(min=time_items[0], max=time_items[-1], step=1, value=time_items[0], description='Year')\n",
    "    element_dropdown = Dropdown(options=element_items, value=element_items[0], description='Element:')\n",
    "    \n",
    "    interact(update_plot, year=year_slider, element=element_dropdown)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56684a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Solver Function with Dynamic TC Handling ---\n",
    "\n",
    "def run_mfa_calculation(mfa_system_configured):\n",
    "    \"\"\"\n",
    "    Enhanced MFA solver that properly handles dynamic TCs for DSM outputs\n",
    "\n",
    "    Args:\n",
    "        mfa_system_configured (msc.MFASystem): The configured MFA system object with processes, flows, and parameters.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified MFA system and a dictionary with detailed DSM results.\n",
    "        mfa_system (msc.MFASystem): The modified MFA system with updated flow values.\n",
    "        dsm_details (dict): A dictionary containing detailed results for each DSM process.  \n",
    "    \"\"\"\n",
    "    import copy\n",
    "    import numpy as np\n",
    "\n",
    "    mfa_system = copy.deepcopy(mfa_system_configured)\n",
    "    dsm_details = {}\n",
    "\n",
    "    # Get primary flows and DSM processes\n",
    "    PRIMARY_INPUT_FLOWS = [f.Name for f in mfa_system.FlowDict.values() if f.P_Start == 0]\n",
    "    dsm_processes = set(DSM_PARAMS.keys()) if 'DSM_PARAMS' in globals() else set()\n",
    "    dsm_processes_run = {pid: False for pid in dsm_processes}\n",
    "\n",
    "    # Backup primary flows\n",
    "    original_primary_data = {}\n",
    "    for flow_name in PRIMARY_INPUT_FLOWS:\n",
    "        if flow_name in mfa_system.FlowDict and mfa_system.FlowDict[flow_name].Values is not None:\n",
    "            original_primary_data[flow_name] = mfa_system.FlowDict[flow_name].Values.copy()\n",
    "\n",
    "    print(\"ðŸš€ STARTING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT\")\n",
    "    print(f\"Primary flows: {PRIMARY_INPUT_FLOWS}\")\n",
    "    print(f\"DSM processes: {dsm_processes}\")\n",
    "\n",
    "    for iteration in range(50):\n",
    "        print(f\"\\n--- Iteration {iteration+1} ---\")\n",
    "        something_changed = False\n",
    "        flows_calculated_this_iteration = []\n",
    "\n",
    "        # Always restore primary flows\n",
    "        for flow_name in PRIMARY_INPUT_FLOWS:\n",
    "            if flow_name in mfa_system.FlowDict and flow_name in original_primary_data:\n",
    "                mfa_system.FlowDict[flow_name].Values = original_primary_data[flow_name].copy()\n",
    "\n",
    "        # 1. TC-based flow calculation\n",
    "        all_flows = list(mfa_system.FlowDict.values())\n",
    "        all_flows.sort(key=lambda f: f.P_Start)\n",
    "        \n",
    "        for flow in all_flows:\n",
    "            if flow.Name in PRIMARY_INPUT_FLOWS:\n",
    "                continue  # Skip primary inputs\n",
    "                \n",
    "            # Only calculate if flow is currently zero\n",
    "            if flow.Values is not None and np.all(flow.Values == 0):\n",
    "                flow_parts = flow.Name.split('_')\n",
    "                if len(flow_parts) >= 3:\n",
    "                    param_name = f\"TC_{flow_parts[1]}_{flow_parts[2]}\"\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if param_name in mfa_system.ParameterDict:\n",
    "                    # âœ… KEY FIX: Handle flows FROM DSM processes\n",
    "                    if flow.P_Start in dsm_processes:\n",
    "                        # For DSM outputs, we need the DSM total output as input\n",
    "                        dsm_output_flows = [f for f in mfa_system.FlowDict.values() \n",
    "                                          if f.P_Start == flow.P_Start and np.any(f.Values != 0)]\n",
    "                        \n",
    "                        if dsm_output_flows:\n",
    "                            # Use the DSM-calculated output as input for TC calculation\n",
    "                            dsm_total_output = sum(f.Values[:, 0] for f in dsm_output_flows)\n",
    "                            \n",
    "                            print(f\"  âœ… Calculating DSM output {flow.Name} using {param_name}\")\n",
    "                            \n",
    "                            # Get TC value (handle dynamic TCs)\n",
    "                            tc_param = mfa_system.ParameterDict[param_name]\n",
    "                            if hasattr(tc_param.Values, '__len__') and len(tc_param.Values) > 1:\n",
    "                                tc_value = tc_param.Values  # Dynamic TC\n",
    "                            else:\n",
    "                                tc_value = tc_param.Values  # Static TC\n",
    "\n",
    "                            # Calculate flow\n",
    "                            flow.Values[:, 0] = dsm_total_output * tc_value\n",
    "                            something_changed = True\n",
    "                            flows_calculated_this_iteration.append(flow.Name)\n",
    "\n",
    "                            # Calculate elemental flows\n",
    "                            for idx_elem, element in enumerate(mfa_system.Elements[1:], 1):\n",
    "                                content_param = f\"{element}_{flow.Name}\"\n",
    "                                if content_param in mfa_system.ParameterDict:\n",
    "                                    content_value = mfa_system.ParameterDict[content_param].Values\n",
    "                                    flow.Values[:, idx_elem] = flow.Values[:, 0] * content_value\n",
    "\n",
    "                            print(f\"      Input flows ready: DSM output from Process {flow.P_Start}\")\n",
    "                            print(f\"      max={flow.Values.max():.2f}, sum={flow.Values.sum():.2f}\")\n",
    "                    else:\n",
    "                        # Regular TC calculation for non-DSM flows\n",
    "                        input_flows = [f for f in mfa_system.FlowDict.values() if f.P_End == flow.P_Start]\n",
    "                        ready_input_flows = [f for f in input_flows if f.Values is not None and np.any(f.Values != 0)]\n",
    "                        \n",
    "                        if ready_input_flows:\n",
    "                            print(f\"  âœ… Calculating {flow.Name} using {param_name}\")\n",
    "                            print(f\"      Input flows ready: {[f.Name for f in ready_input_flows]}\")\n",
    "                            \n",
    "                            sum_input_flows = np.sum([f.Values[:, 0] for f in ready_input_flows], axis=0)\n",
    "                            \n",
    "                            tc_param = mfa_system.ParameterDict[param_name]\n",
    "                            if hasattr(tc_param.Values, '__len__') and len(tc_param.Values) > 1:\n",
    "                                tc_value = tc_param.Values\n",
    "                            else:\n",
    "                                tc_value = tc_param.Values\n",
    "\n",
    "                            flow.Values[:, 0] = sum_input_flows * tc_value\n",
    "                            something_changed = True\n",
    "                            flows_calculated_this_iteration.append(flow.Name)\n",
    "\n",
    "                            for idx_elem, element in enumerate(mfa_system.Elements[1:], 1):\n",
    "                                content_param = f\"{element}_{flow.Name}\"\n",
    "                                if content_param in mfa_system.ParameterDict:\n",
    "                                    content_value = mfa_system.ParameterDict[content_param].Values\n",
    "                                    flow.Values[:, idx_elem] = flow.Values[:, 0] * content_value\n",
    "\n",
    "                            print(f\"      max={flow.Values.max():.2f}, sum={flow.Values.sum():.2f}\")\n",
    "                        else:\n",
    "                            missing_inputs = [f.Name for f in input_flows if f.Values is None or np.all(f.Values == 0)]\n",
    "                            if missing_inputs:\n",
    "                                print(f\"  â³ {flow.Name} waiting for inputs: {missing_inputs}\")\n",
    "\n",
    "        print(f\"  Calculated flows this iteration: {flows_calculated_this_iteration}\")\n",
    "\n",
    "        # 2. DSM calculation\n",
    "        if globals().get('RUN_DSM_CALCULATION', False):\n",
    "            for pid in dsm_processes:\n",
    "                if not dsm_processes_run[pid]:\n",
    "                    inflows = [f for f in mfa_system.FlowDict.values() if f.P_End == pid]\n",
    "                    ready_inflows = [f for f in inflows if f.Values is not None and np.any(f.Values != 0)]\n",
    "                    \n",
    "                    if ready_inflows:\n",
    "                        print(f\"--> ðŸ¤– Running DSM for Process {pid}...\")\n",
    "                        try:\n",
    "                            mfa_system, dsm_details_single = calculate_dynamic_stock(mfa_system, {pid: DSM_PARAMS[pid]})\n",
    "                            dsm_details.update(dsm_details_single)\n",
    "                            dsm_processes_run[pid] = True\n",
    "                            something_changed = True\n",
    "                            \n",
    "                            # Verify DSM outputs\n",
    "                            outflows = [f for f in mfa_system.FlowDict.values() if f.P_Start == pid]\n",
    "                            for outflow in outflows:\n",
    "                                if outflow.Values is not None and np.any(outflow.Values != 0):\n",
    "                                    print(f\"      âœ… DSM Output {outflow.Name}: max={outflow.Values.max():.2f}\")\n",
    "                                    \n",
    "                        except Exception as e:\n",
    "                            print(f\"âŒ Error running DSM for {pid}: {e}\")\n",
    "\n",
    "        # Always restore primary flows at the end\n",
    "        for flow_name in PRIMARY_INPUT_FLOWS:\n",
    "            if flow_name in mfa_system.FlowDict and flow_name in original_primary_data:\n",
    "                mfa_system.FlowDict[flow_name].Values = original_primary_data[flow_name].copy()\n",
    "\n",
    "        # Check convergence\n",
    "        if not something_changed:\n",
    "            print(f\"--- âœ… System converged at iteration {iteration+1} ---\")\n",
    "            break\n",
    "        elif iteration == 49:\n",
    "            print(\"--- âš ï¸ Reached maximum iterations ---\")\n",
    "\n",
    "    # Final summary\n",
    "    print(\"\\n--- FINAL FLOW STATUS ---\")\n",
    "    flows_with_data = []\n",
    "    flows_without_data = []\n",
    "    \n",
    "    for flow_name, flow_obj in mfa_system.FlowDict.items():\n",
    "        if np.any(flow_obj.Values != 0):\n",
    "            flows_with_data.append(flow_name)\n",
    "        else:\n",
    "            flows_without_data.append(flow_name)\n",
    "    \n",
    "    print(f\"âœ… Flows WITH data ({len(flows_with_data)}): {flows_with_data}\")\n",
    "    print(f\"âŒ Flows WITHOUT data ({len(flows_without_data)}): {flows_without_data}\")\n",
    "    \n",
    "    # Final balance calculation\n",
    "    print(\"\\n--- Finalizing stock balances ---\")\n",
    "    mfa_system = calculate_final_balances(mfa_system)\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ MFA calculation finished after {iteration+1} iterations.\")\n",
    "    return mfa_system, dsm_details\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "401ce74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT ===\n",
      "ðŸš€ STARTING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT\n",
      "Primary flows: ['F_00_01']\n",
      "DSM processes: {0, 2, 3, 7, 8}\n",
      "\n",
      "--- Iteration 1 ---\n",
      "  âœ… Calculating F_01_02 using TC_01_02\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=211.82, sum=11949.35\n",
      "  âœ… Calculating F_01_00 using TC_01_00\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=90.78, sum=5121.15\n",
      "  â³ F_04_03 waiting for inputs: ['F_03_04']\n",
      "  â³ F_04_08 waiting for inputs: ['F_03_04']\n",
      "  â³ F_05_07 waiting for inputs: ['F_03_05']\n",
      "  â³ F_05_00 waiting for inputs: ['F_03_05']\n",
      "  â³ F_06_07 waiting for inputs: ['F_03_06']\n",
      "  â³ F_06_08 waiting for inputs: ['F_03_06']\n",
      "  Calculated flows this iteration: ['F_01_02', 'F_01_00']\n",
      "--> ðŸ¤– Running DSM for Process 0...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 0\n",
      "      Auto-read elemental contents for F_01_00:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 0\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_00_01: max=36.62\n",
      "--> ðŸ¤– Running DSM for Process 2...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 2\n",
      "      Auto-read elemental contents for F_01_02:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 2\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_02_03: max=112.35\n",
      "--> ðŸ¤– Running DSM for Process 3...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 3\n",
      "      Auto-read elemental contents for F_02_03:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 3\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_03_04: max=44.25\n",
      "\n",
      "--- Iteration 2 ---\n",
      "  âœ… Calculating DSM output F_02_08 using TC_02_08\n",
      "      Input flows ready: DSM output from Process 2\n",
      "      max=54.15, sum=4537.64\n",
      "  âœ… Calculating DSM output F_03_05 using TC_03_05\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=1.68, sum=215.41\n",
      "  âœ… Calculating DSM output F_03_06 using TC_03_06\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=37.29, sum=4598.64\n",
      "  âœ… Calculating F_04_03 using TC_04_03\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=0.82, sum=99.45\n",
      "  âœ… Calculating F_04_08 using TC_04_08\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=43.51, sum=5318.86\n",
      "  âœ… Calculating F_05_07 using TC_05_07\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=1.60, sum=204.64\n",
      "  âœ… Calculating F_05_00 using TC_05_00\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=0.08, sum=10.77\n",
      "  âœ… Calculating F_06_07 using TC_06_07\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=36.91, sum=4552.65\n",
      "  âœ… Calculating F_06_08 using TC_06_08\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=0.37, sum=45.99\n",
      "  Calculated flows this iteration: ['F_02_08', 'F_03_05', 'F_03_06', 'F_04_03', 'F_04_08', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08']\n",
      "--> ðŸ¤– Running DSM for Process 7...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 7\n",
      "      Auto-read elemental contents for F_05_07:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 7\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_07_00: max=0.26\n",
      "--> ðŸ¤– Running DSM for Process 8...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 8\n",
      "Warning: Missing inflow or outflow for process 8\n",
      "--> Dynamic stock calculation finished.\n",
      "\n",
      "--- Iteration 3 ---\n",
      "  Calculated flows this iteration: []\n",
      "--- âœ… System converged at iteration 3 ---\n",
      "\n",
      "--- FINAL FLOW STATUS ---\n",
      "âœ… Flows WITH data (15): ['F_00_01', 'F_01_02', 'F_01_00', 'F_02_03', 'F_03_04', 'F_04_03', 'F_03_05', 'F_03_06', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08', 'F_02_08', 'F_04_08', 'F_07_00']\n",
      "âŒ Flows WITHOUT data (0): []\n",
      "\n",
      "--- Finalizing stock balances ---\n",
      "--> Calculating final stock balances...\n",
      "  -> Skipping balance calculation for primary input process 0 (Biosphere)\n",
      "  -> Skipping balance calculation for DSM process 2 (Processing)\n",
      "  -> Skipping balance calculation for DSM process 3 (Use)\n",
      "  -> Skipping balance calculation for DSM process 7 (Atmosphere)\n",
      "  -> Skipping balance calculation for DSM process 8 (Anthroposphere)\n",
      "--> Stock balance calculation finished.\n",
      "\n",
      "ðŸŽ‰ MFA calculation finished after 3 iterations.\n",
      "\n",
      "=== AFTER MFA CALCULATION ===\n",
      "âœ… F_00_01: max=302.60, sum=17070.50\n",
      "âœ… F_01_02: max=211.82, sum=11949.35\n",
      "âœ… F_01_00: max=90.78, sum=5121.15\n",
      "âœ… F_02_03: max=112.35, sum=11804.44\n",
      "âœ… F_03_04: max=44.25, sum=5418.31\n",
      "âœ… F_04_03: max=0.82, sum=99.45\n",
      "âœ… F_03_05: max=1.68, sum=215.41\n",
      "âœ… F_03_06: max=37.29, sum=4598.64\n",
      "âœ… F_05_07: max=1.60, sum=204.64\n",
      "âœ… F_05_00: max=0.08, sum=10.77\n",
      "âœ… F_06_07: max=36.91, sum=4552.65\n",
      "âœ… F_06_08: max=0.37, sum=45.99\n",
      "âœ… F_02_08: max=54.15, sum=4537.64\n",
      "âœ… F_04_08: max=43.51, sum=5318.86\n",
      "âœ… F_07_00: max=0.26, sum=5.04\n",
      "\n",
      "ðŸ“Š Summary: 15 flows have calculated values\n"
     ]
    }
   ],
   "source": [
    "# Run the MFA calculation\n",
    "print(\"=== RUNNING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT ===\")\n",
    "mfa_system_with_results, dsm_details = run_mfa_calculation(mfa_system_configured)\n",
    "\n",
    "# Check which flows now have calculated values\n",
    "print(\"\\n=== AFTER MFA CALCULATION ===\")\n",
    "non_zero_flows = 0\n",
    "for flow_name, flow_obj in mfa_system_with_results.FlowDict.items():\n",
    "    max_val = flow_obj.Values.max()\n",
    "    if max_val > 0:\n",
    "        non_zero_flows += 1\n",
    "        print(f\"âœ… {flow_name}: max={max_val:.2f}, sum={flow_obj.Values.sum():.2f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary: {non_zero_flows} flows have calculated values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecb17ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FLOW CALCULATION DEBUG ===\n",
      "âœ… Flows WITH data (15):\n",
      "  F_00_01\n",
      "  F_01_02\n",
      "  F_01_00\n",
      "  F_02_03\n",
      "  F_03_04\n",
      "  F_04_03\n",
      "  F_03_05\n",
      "  F_03_06\n",
      "  F_05_07\n",
      "  F_05_00\n",
      "  F_06_07\n",
      "  F_06_08\n",
      "  F_02_08\n",
      "  F_04_08\n",
      "  F_07_00\n",
      "\n",
      "âŒ Flows WITHOUT data (0):\n",
      "\n",
      "=== TRANSFER COEFFICIENT CHECK ===\n",
      "Available TC parameters (15):\n",
      "  TC_00_01\n",
      "  TC_01_00\n",
      "  TC_01_02\n",
      "  TC_02_03\n",
      "  TC_02_08\n",
      "  TC_03_04\n",
      "  TC_03_05\n",
      "  TC_03_06\n",
      "  TC_04_03\n",
      "  TC_04_08\n",
      "  TC_05_00\n",
      "  TC_05_07\n",
      "  TC_06_07\n",
      "  TC_06_08\n",
      "  TC_07_00\n",
      "\n",
      "=== MISSING TC ANALYSIS ===\n",
      "\n",
      "=== DSM PROCESS CHECK ===\n",
      "DSM_PARAMS processes: [0, 2, 3, 7, 8]\n",
      "RUN_DSM_CALCULATION: True\n",
      "Process 0:\n",
      "  Inflows: ['F_01_00', 'F_05_00', 'F_07_00']\n",
      "  Outflows: ['F_00_01']\n",
      "    F_01_00 has data: True\n",
      "    F_05_00 has data: True\n",
      "    F_07_00 has data: True\n",
      "Process 2:\n",
      "  Inflows: ['F_01_02']\n",
      "  Outflows: ['F_02_03', 'F_02_08']\n",
      "    F_01_02 has data: True\n",
      "Process 3:\n",
      "  Inflows: ['F_02_03', 'F_04_03']\n",
      "  Outflows: ['F_03_04', 'F_03_05', 'F_03_06']\n",
      "    F_02_03 has data: True\n",
      "    F_04_03 has data: True\n",
      "Process 7:\n",
      "  Inflows: ['F_05_07', 'F_06_07']\n",
      "  Outflows: ['F_07_00']\n",
      "    F_05_07 has data: True\n",
      "    F_06_07 has data: True\n",
      "Process 8:\n",
      "  Inflows: ['F_06_08', 'F_02_08', 'F_04_08']\n",
      "  Outflows: []\n",
      "    F_06_08 has data: True\n",
      "    F_02_08 has data: True\n",
      "    F_04_08 has data: True\n"
     ]
    }
   ],
   "source": [
    "# Debug flow calculation process\n",
    "\n",
    "print(\"=== FLOW CALCULATION DEBUG ===\")\n",
    "\n",
    "# Check which flows have data vs. which are empty\n",
    "flows_with_data = []\n",
    "flows_without_data = []\n",
    "\n",
    "for flow_name, flow_obj in mfa_system_with_results.FlowDict.items():\n",
    "    if np.any(flow_obj.Values != 0):\n",
    "        flows_with_data.append(flow_name)\n",
    "    else:\n",
    "        flows_without_data.append(flow_name)\n",
    "\n",
    "print(f\"âœ… Flows WITH data ({len(flows_with_data)}):\")\n",
    "for flow in flows_with_data:\n",
    "    print(f\"  {flow}\")\n",
    "\n",
    "print(f\"\\nâŒ Flows WITHOUT data ({len(flows_without_data)}):\")\n",
    "for flow in flows_without_data:\n",
    "    print(f\"  {flow}\")\n",
    "\n",
    "# Check which TC parameters exist\n",
    "print(f\"\\n=== TRANSFER COEFFICIENT CHECK ===\")\n",
    "tc_params = {name: param for name, param in mfa_system_with_results.ParameterDict.items() if name.startswith('TC_')}\n",
    "print(f\"Available TC parameters ({len(tc_params)}):\")\n",
    "for tc_name in sorted(tc_params.keys()):\n",
    "    print(f\"  {tc_name}\")\n",
    "\n",
    "# For each missing flow, check if its TC exists\n",
    "print(f\"\\n=== MISSING TC ANALYSIS ===\")\n",
    "for flow_name in flows_without_data:\n",
    "    expected_tc = f\"TC_{'_'.join(flow_name.split('_')[1:3])}\"\n",
    "    if expected_tc in tc_params:\n",
    "        print(f\"âœ… {flow_name} -> {expected_tc} EXISTS\")\n",
    "    else:\n",
    "        print(f\"âŒ {flow_name} -> {expected_tc} MISSING\")\n",
    "\n",
    "# Check DSM configuration\n",
    "print(f\"\\n=== DSM PROCESS CHECK ===\")\n",
    "print(f\"DSM_PARAMS processes: {list(DSM_PARAMS.keys())}\")\n",
    "print(f\"RUN_DSM_CALCULATION: {globals().get('RUN_DSM_CALCULATION', 'NOT SET')}\")\n",
    "\n",
    "for process_id in DSM_PARAMS.keys():\n",
    "    inflows = [f.Name for f in mfa_system_with_results.FlowDict.values() if f.P_End == process_id]\n",
    "    outflows = [f.Name for f in mfa_system_with_results.FlowDict.values() if f.P_Start == process_id]\n",
    "    print(f\"Process {process_id}:\")\n",
    "    print(f\"  Inflows: {inflows}\")\n",
    "    print(f\"  Outflows: {outflows}\")\n",
    "    \n",
    "    # Check if inflows have data\n",
    "    for inflow_name in inflows:\n",
    "        inflow_obj = mfa_system_with_results.FlowDict[inflow_name]\n",
    "        has_data = np.any(inflow_obj.Values != 0)\n",
    "        print(f\"    {inflow_name} has data: {has_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79815327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ STARTING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT\n",
      "Primary flows: ['F_00_01']\n",
      "DSM processes: {0, 2, 3, 7, 8}\n",
      "\n",
      "--- Iteration 1 ---\n",
      "  âœ… Calculating F_01_02 using TC_01_02\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=211.82, sum=11949.35\n",
      "  âœ… Calculating F_01_00 using TC_01_00\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=90.78, sum=5121.15\n",
      "  â³ F_04_03 waiting for inputs: ['F_03_04']\n",
      "  â³ F_04_08 waiting for inputs: ['F_03_04']\n",
      "  â³ F_05_07 waiting for inputs: ['F_03_05']\n",
      "  â³ F_05_00 waiting for inputs: ['F_03_05']\n",
      "  â³ F_06_07 waiting for inputs: ['F_03_06']\n",
      "  â³ F_06_08 waiting for inputs: ['F_03_06']\n",
      "  Calculated flows this iteration: ['F_01_02', 'F_01_00']\n",
      "--> ðŸ¤– Running DSM for Process 0...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 0\n",
      "      Auto-read elemental contents for F_01_00:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 0\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_00_01: max=36.62\n",
      "--> ðŸ¤– Running DSM for Process 2...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 2\n",
      "      Auto-read elemental contents for F_01_02:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 2\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_02_03: max=112.35\n",
      "--> ðŸ¤– Running DSM for Process 3...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 3\n",
      "      Auto-read elemental contents for F_02_03:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 3\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_03_04: max=44.25\n",
      "\n",
      "--- Iteration 2 ---\n",
      "  âœ… Calculating DSM output F_02_08 using TC_02_08\n",
      "      Input flows ready: DSM output from Process 2\n",
      "      max=54.15, sum=4537.64\n",
      "  âœ… Calculating DSM output F_03_05 using TC_03_05\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=1.68, sum=215.41\n",
      "  âœ… Calculating DSM output F_03_06 using TC_03_06\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=37.29, sum=4598.64\n",
      "  âœ… Calculating F_04_03 using TC_04_03\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=0.82, sum=99.45\n",
      "  âœ… Calculating F_04_08 using TC_04_08\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=43.51, sum=5318.86\n",
      "  âœ… Calculating F_05_07 using TC_05_07\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=1.60, sum=204.64\n",
      "  âœ… Calculating F_05_00 using TC_05_00\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=0.08, sum=10.77\n",
      "  âœ… Calculating F_06_07 using TC_06_07\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=36.91, sum=4552.65\n",
      "  âœ… Calculating F_06_08 using TC_06_08\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=0.37, sum=45.99\n",
      "  Calculated flows this iteration: ['F_02_08', 'F_03_05', 'F_03_06', 'F_04_03', 'F_04_08', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08']\n",
      "--> ðŸ¤– Running DSM for Process 7...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 7\n",
      "      Auto-read elemental contents for F_05_07:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 7\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_07_00: max=0.26\n",
      "--> ðŸ¤– Running DSM for Process 8...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 8\n",
      "Warning: Missing inflow or outflow for process 8\n",
      "--> Dynamic stock calculation finished.\n",
      "\n",
      "--- Iteration 3 ---\n",
      "  Calculated flows this iteration: []\n",
      "--- âœ… System converged at iteration 3 ---\n",
      "\n",
      "--- FINAL FLOW STATUS ---\n",
      "âœ… Flows WITH data (15): ['F_00_01', 'F_01_02', 'F_01_00', 'F_02_03', 'F_03_04', 'F_04_03', 'F_03_05', 'F_03_06', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08', 'F_02_08', 'F_04_08', 'F_07_00']\n",
      "âŒ Flows WITHOUT data (0): []\n",
      "\n",
      "--- Finalizing stock balances ---\n",
      "--> Calculating final stock balances...\n",
      "  -> Skipping balance calculation for primary input process 0 (Biosphere)\n",
      "  -> Skipping balance calculation for DSM process 2 (Processing)\n",
      "  -> Skipping balance calculation for DSM process 3 (Use)\n",
      "  -> Skipping balance calculation for DSM process 7 (Atmosphere)\n",
      "  -> Skipping balance calculation for DSM process 8 (Anthroposphere)\n",
      "--> Stock balance calculation finished.\n",
      "\n",
      "ðŸŽ‰ MFA calculation finished after 3 iterations.\n",
      "\n",
      "=== UPDATED FLOW SUMMARY ===\n",
      "âœ… F_00_01: max=302.60, sum=17070.50\n",
      "âœ… F_01_02: max=211.82, sum=11949.35\n",
      "âœ… F_01_00: max=90.78, sum=5121.15\n",
      "âœ… F_02_03: max=112.35, sum=11804.44\n",
      "âœ… F_03_04: max=44.25, sum=5418.31\n",
      "âœ… F_04_03: max=0.82, sum=99.45\n",
      "âœ… F_03_05: max=1.68, sum=215.41\n",
      "âœ… F_03_06: max=37.29, sum=4598.64\n",
      "âœ… F_05_07: max=1.60, sum=204.64\n",
      "âœ… F_05_00: max=0.08, sum=10.77\n",
      "âœ… F_06_07: max=36.91, sum=4552.65\n",
      "âœ… F_06_08: max=0.37, sum=45.99\n",
      "âœ… F_02_08: max=54.15, sum=4537.64\n",
      "âœ… F_04_08: max=43.51, sum=5318.86\n",
      "âœ… F_07_00: max=0.26, sum=5.04\n"
     ]
    }
   ],
   "source": [
    "# Re-run the MFA calculation with the enhanced solver\n",
    "mfa_system_with_results, dsm_details = run_mfa_calculation(mfa_system_configured)\n",
    "\n",
    "# Check results\n",
    "print(\"\\n=== UPDATED FLOW SUMMARY ===\")\n",
    "for flow_name, flow_obj in mfa_system_with_results.FlowDict.items():\n",
    "    max_val = flow_obj.Values.max()\n",
    "    sum_val = flow_obj.Values.sum()\n",
    "    has_data = \"âœ…\" if max_val > 0 else \"âŒ\"\n",
    "    print(f\"{has_data} {flow_name}: max={max_val:.2f}, sum={sum_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca404a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MASS BALANCE ANALYSIS ===\n",
      "Mass balance errors (should be close to zero):\n",
      "[5.20289941e+03 1.24111832e-12 4.53763524e+03 4.71460312e+03\n",
      " 2.69248516e-13 1.29515405e-14 2.68546983e-13 4.55265177e+03\n",
      " 9.90248600e+03]\n",
      "Process 0 (Biosphere): SKIPPED (system boundary)\n",
      "Process 2 (Processing): Max error = 54.153680 Mg\n",
      "Process 3 (Use): Max error = 38.083195 Mg\n",
      "Process 7 (Atmosphere): Max error = 36.913888 Mg\n",
      "Process 8 (Anthroposphere): Max error = 54.153785 Mg\n"
     ]
    }
   ],
   "source": [
    "# Check mass balance errors where process 0 is being excluded\n",
    "print(\"=== MASS BALANCE ANALYSIS ===\")\n",
    "balance = mfa_system_with_results.MassBalance()\n",
    "print(\"Mass balance errors (should be close to zero):\")\n",
    "print(np.abs(balance).sum(axis=0).sum(axis=1))\n",
    "\n",
    "# Check individual process balances - EXCLUDING PROCESS 0\n",
    "for process in mfa_system_with_results.ProcessList:\n",
    "    pid = process.ID\n",
    "    \n",
    "    # SKIP Process 0 (Biosphere) - it's a system boundary, not a mass-conserving process\n",
    "    if pid == 0:\n",
    "        print(f\"Process {pid} ({process.Name}): SKIPPED (system boundary)\")\n",
    "        continue\n",
    "    \n",
    "    inflows = sum(f.Values for f in mfa_system_with_results.FlowDict.values() if f.P_End == pid)\n",
    "    outflows = sum(f.Values for f in mfa_system_with_results.FlowDict.values() if f.P_Start == pid)\n",
    "    \n",
    "    if f\"S_{pid}\" in mfa_system_with_results.StockDict:\n",
    "        stock_change = mfa_system_with_results.StockDict[f\"dS_{pid}\"].Values\n",
    "        balance_error = inflows - outflows - stock_change\n",
    "        max_error = np.abs(balance_error).max()\n",
    "        print(f\"Process {pid} ({process.Name}): Max error = {max_error:.6f} Mg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "563eeb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DSM LIFETIME ANALYSIS ===\n",
      "\n",
      "Process 0:\n",
      "  Average Exchange: 20 years\n",
      "\n",
      "Process 2:\n",
      "  Air Drying: 6 years\n",
      "\n",
      "Process 3:\n",
      "  Average Lifetime: 80 years\n",
      "    âœ… Realistic lifespan for timber construction\n",
      "\n",
      "Process 7:\n",
      "  Photosynthesis: 70 years\n",
      "\n",
      "Process 8:\n"
     ]
    }
   ],
   "source": [
    "# Analyze DSM lifetimes for realism\n",
    "print(\"\\n=== DSM LIFETIME ANALYSIS ===\")\n",
    "for process_id, params in DSM_PARAMS.items():\n",
    "    lifetimes = params['lifetimes']['Mean']\n",
    "    categories = params['category_names']\n",
    "    \n",
    "    print(f\"\\nProcess {process_id}:\")\n",
    "    for i, (category, lifetime) in enumerate(zip(categories, lifetimes)):\n",
    "        print(f\"  {category}: {lifetime} years\")\n",
    "        \n",
    "        # Reality check for timber products\n",
    "        if process_id == 3:  # Use phase\n",
    "            if lifetime < 10:\n",
    "                print(f\"    âš ï¸ WARNING: {lifetime} years seems short for timber products\")\n",
    "            elif lifetime > 100:\n",
    "                print(f\"    âš ï¸ WARNING: {lifetime} years seems long for typical construction\")\n",
    "            else:\n",
    "                print(f\"    âœ… Realistic lifespan for timber construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c58e16ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STOCK ACCUMULATION ANALYSIS ===\n",
      "S_0:\n",
      "  Final stock (2045): 69.43 Mg\n",
      "  Peak stock: 555.47 Mg\n",
      "  Annual growth rate (last 10 years): -2.7%\n",
      "S_2:\n",
      "  Final stock (2045): 57.96 Mg\n",
      "  Peak stock: 673.10 Mg\n",
      "  Annual growth rate (last 10 years): 2.7%\n",
      "S_3:\n",
      "  Final stock (2045): 2554.45 Mg\n",
      "  Peak stock: 3618.65 Mg\n",
      "  Annual growth rate (last 10 years): -1.2%\n",
      "S_7:\n",
      "  Final stock (2045): 79.84 Mg\n",
      "  Peak stock: 79.84 Mg\n",
      "    âš ï¸ WARNING: Stock still growing rapidly at model end\n",
      "  Annual growth rate (last 10 years): 0.9%\n"
     ]
    }
   ],
   "source": [
    "# Analyze stock accumulation patterns\n",
    "print(\"\\n=== STOCK ACCUMULATION ANALYSIS ===\")\n",
    "for stock_name, stock_obj in mfa_system_with_results.StockDict.items():\n",
    "    if stock_name.startswith('S_') and np.any(stock_obj.Values != 0):\n",
    "        final_stock = stock_obj.Values[-1, 0]  # Final year, material element\n",
    "        max_stock = stock_obj.Values[:, 0].max()\n",
    "        \n",
    "        print(f\"{stock_name}:\")\n",
    "        print(f\"  Final stock (2045): {final_stock:.2f} Mg\")\n",
    "        print(f\"  Peak stock: {max_stock:.2f} Mg\")\n",
    "        \n",
    "        # Check for unrealistic exponential growth\n",
    "        if final_stock > max_stock * 0.9:  # Still growing at end\n",
    "            print(f\"    âš ï¸ WARNING: Stock still growing rapidly at model end\")\n",
    "        \n",
    "        # Check growth rate in last decade\n",
    "        if len(stock_obj.Values) >= 10:\n",
    "            growth_rate = (stock_obj.Values[-1, 0] / stock_obj.Values[-10, 0]) ** (1/10) - 1\n",
    "            print(f\"  Annual growth rate (last 10 years): {growth_rate*100:.1f}%\")\n",
    "            if growth_rate > 0.1:  # >10% annual growth\n",
    "                print(f\"    âš ï¸ WARNING: Very high growth rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e0b2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED STOCK DIAGNOSTIC ===\n",
      "\n",
      "--- Process 0 (Biosphere) ---\n",
      "Inflows: ['F_01_00', 'F_05_00', 'F_07_00']\n",
      "Outflows: ['F_00_01']\n",
      "Final year (2045):\n",
      "  Total inflow: 2.22 Mg\n",
      "  Total outflow: 6.40 Mg\n",
      "  Final stock: 69.43 Mg\n",
      "  Balance (In-Out): -4.18 Mg\n",
      "\n",
      "--- Process 2 (Processing) ---\n",
      "Inflows: ['F_01_02']\n",
      "Outflows: ['F_02_03', 'F_02_08']\n",
      "Final year (2045):\n",
      "  Total inflow: 4.48 Mg\n",
      "  Total outflow: 9.79 Mg\n",
      "  Final stock: 57.96 Mg\n",
      "  Balance (In-Out): -5.31 Mg\n",
      "\n",
      "--- Process 3 (Use) ---\n",
      "Inflows: ['F_02_03', 'F_04_03']\n",
      "Outflows: ['F_03_04', 'F_03_05', 'F_03_06']\n",
      "Final year (2045):\n",
      "  Total inflow: 8.26 Mg\n",
      "  Total outflow: 76.75 Mg\n",
      "  Final stock: 2554.45 Mg\n",
      "  Balance (In-Out): -68.49 Mg\n",
      "\n",
      "--- Process 7 (Atmosphere) ---\n",
      "Inflows: ['F_05_07', 'F_06_07']\n",
      "Outflows: ['F_07_00']\n",
      "Final year (2045):\n",
      "  Total inflow: 34.10 Mg\n",
      "  Total outflow: 0.26 Mg\n",
      "  Final stock: 79.84 Mg\n",
      "  Balance (In-Out): 33.84 Mg\n",
      "\n",
      "--- Process 8 (Anthroposphere) ---\n",
      "Inflows: ['F_06_08', 'F_02_08', 'F_04_08']\n",
      "Outflows: []\n",
      "Final year (2045):\n",
      "  Total inflow: 44.14 Mg\n",
      "  Total outflow: 0.00 Mg\n",
      "  Final stock: 0.00 Mg\n",
      "  Balance (In-Out): 44.14 Mg\n",
      "  âš ï¸ WARNING: Inflows but no outflows - missing flow definition?\n"
     ]
    }
   ],
   "source": [
    "# Add this diagnostic cell to understand what's happening\n",
    "\n",
    "print(\"=== DETAILED STOCK DIAGNOSTIC ===\")\n",
    "\n",
    "# Check the stock calculation logic\n",
    "for process in mfa_system_with_results.ProcessList:\n",
    "    pid = process.ID\n",
    "    \n",
    "    if f\"S_{pid}\" in mfa_system_with_results.StockDict:\n",
    "        print(f\"\\n--- Process {pid} ({process.Name}) ---\")\n",
    "        \n",
    "        # Get inflows and outflows\n",
    "        inflows = [f for f in mfa_system_with_results.FlowDict.values() if f.P_End == pid]\n",
    "        outflows = [f for f in mfa_system_with_results.FlowDict.values() if f.P_Start == pid]\n",
    "        \n",
    "        print(f\"Inflows: {[f.Name for f in inflows]}\")\n",
    "        print(f\"Outflows: {[f.Name for f in outflows]}\")\n",
    "        \n",
    "        # Calculate totals for final year (2045)\n",
    "        total_inflow = sum(f.Values[-1, 0] for f in inflows)\n",
    "        total_outflow = sum(f.Values[-1, 0] for f in outflows)\n",
    "        final_stock = mfa_system_with_results.StockDict[f\"S_{pid}\"].Values[-1, 0]\n",
    "        \n",
    "        print(f\"Final year (2045):\")\n",
    "        print(f\"  Total inflow: {total_inflow:.2f} Mg\")\n",
    "        print(f\"  Total outflow: {total_outflow:.2f} Mg\")\n",
    "        print(f\"  Final stock: {final_stock:.2f} Mg\")\n",
    "        print(f\"  Balance (In-Out): {total_inflow - total_outflow:.2f} Mg\")\n",
    "        \n",
    "        # Check for missing outflows\n",
    "        if total_inflow > 0 and total_outflow == 0:\n",
    "            print(f\"  âš ï¸ WARNING: Inflows but no outflows - missing flow definition?\")\n",
    "        \n",
    "        if final_stock < 0:\n",
    "            print(f\"  âŒ CRITICAL: Negative stock detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dde5a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DSM OUTFLOW VERIFICATION ===\n",
      "\n",
      "Process 2:\n",
      "  Cumulative inflow: 4779.74 Mg\n",
      "  Cumulative outflow: 6536.83 Mg\n",
      "  Ratio (out/in): 1.368\n",
      "  âŒ CRITICAL: Outflow exceeds total input by 36.8%!\n",
      "  DSM Configuration:\n",
      "    Lifetimes: [6] years\n",
      "    StdDevs: [2] years\n",
      "    âœ… Category 0: Parameters look reasonable\n",
      "  Recent annual flows (last 5 years):\n",
      "    2041: In=4.48, Out=8.32\n",
      "    2042: In=0.00, Out=8.50\n",
      "    2043: In=18.06, Out=8.99\n",
      "    2044: In=18.06, Out=9.54\n",
      "    2045: In=4.48, Out=9.79\n",
      "\n",
      "Process 3:\n",
      "  Cumulative inflow: 4761.56 Mg\n",
      "  Cumulative outflow: 4092.94 Mg\n",
      "  Ratio (out/in): 0.860\n",
      "  âš ï¸ Low outflow ratio - check if DSM is working correctly\n",
      "  DSM Configuration:\n",
      "    Lifetimes: [80] years\n",
      "    StdDevs: [16] years\n",
      "    âœ… Category 0: Parameters look reasonable\n",
      "  Recent annual flows (last 5 years):\n",
      "    2041: In=7.11, Out=77.19\n",
      "    2042: In=7.24, Out=77.01\n",
      "    2043: In=7.63, Out=76.87\n",
      "    2044: In=8.06, Out=76.79\n",
      "    2045: In=8.26, Out=76.75\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DSM OUTFLOW VERIFICATION ===\")\n",
    "\n",
    "for process_id in [2, 3]:  # Your DSM processes with negative stocks\n",
    "    print(f\"\\nProcess {process_id}:\")\n",
    "    \n",
    "    # Get inflow data\n",
    "    inflows = [f for f in mfa_system_with_results.FlowDict.values() if f.P_End == process_id]\n",
    "    if not inflows:\n",
    "        print(f\"  âŒ No inflows found for process {process_id}\")\n",
    "        continue\n",
    "        \n",
    "    # FIXED: Calculate total cumulative inflow correctly\n",
    "    total_cumulative_inflow = sum(f.Values[:, 0].sum() for f in inflows)\n",
    "    \n",
    "    # Get outflow data  \n",
    "    outflows = [f for f in mfa_system_with_results.FlowDict.values() if f.P_Start == process_id]\n",
    "    if not outflows:\n",
    "        print(f\"  âŒ No outflows found for process {process_id}\")\n",
    "        continue\n",
    "        \n",
    "    # FIXED: Calculate total cumulative outflow correctly\n",
    "    total_cumulative_outflow = sum(f.Values[:, 0].sum() for f in outflows)\n",
    "    \n",
    "    print(f\"  Cumulative inflow: {total_cumulative_inflow:.2f} Mg\")\n",
    "    print(f\"  Cumulative outflow: {total_cumulative_outflow:.2f} Mg\")\n",
    "    \n",
    "    # FIXED: Add safety check for division by zero\n",
    "    if total_cumulative_inflow > 0:\n",
    "        ratio = total_cumulative_outflow / total_cumulative_inflow\n",
    "        print(f\"  Ratio (out/in): {ratio:.3f}\")\n",
    "        \n",
    "        if ratio > 1.1:  # Allow small numerical errors\n",
    "            print(f\"  âŒ CRITICAL: Outflow exceeds total input by {(ratio-1)*100:.1f}%!\")\n",
    "        elif ratio > 0.95:\n",
    "            print(f\"  âœ… Good: Outflow ratio is reasonable\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ Low outflow ratio - check if DSM is working correctly\")\n",
    "    else:\n",
    "        print(f\"  âŒ Zero inflow detected!\")\n",
    "    \n",
    "    # Enhanced diagnostics\n",
    "    params = DSM_PARAMS[process_id]\n",
    "    lifetimes = params['lifetimes']['Mean']\n",
    "    std_devs = params['lifetimes']['StdDev']\n",
    "    \n",
    "    print(f\"  DSM Configuration:\")\n",
    "    print(f\"    Lifetimes: {lifetimes} years\")\n",
    "    print(f\"    StdDevs: {std_devs} years\")\n",
    "    \n",
    "    # Check for problematic lifetimes\n",
    "    for i, (lt, std) in enumerate(zip(lifetimes, std_devs)):\n",
    "        if lt < 1:\n",
    "            print(f\"    âŒ Category {i}: Lifetime {lt} < 1 year causes immediate outflows\")\n",
    "        elif std > lt:\n",
    "            print(f\"    âš ï¸ Category {i}: StdDev {std} > Mean {lt} causes unrealistic distribution\")\n",
    "        else:\n",
    "            print(f\"    âœ… Category {i}: Parameters look reasonable\")\n",
    "    \n",
    "    # Check annual flows for the last few years\n",
    "    print(f\"  Recent annual flows (last 5 years):\")\n",
    "    for year_idx in range(-5, 0):\n",
    "        year = mfa_system_with_results.IndexTable.Classification['Time'].Items[year_idx]\n",
    "        annual_inflow = sum(f.Values[year_idx, 0] for f in inflows)\n",
    "        annual_outflow = sum(f.Values[year_idx, 0] for f in outflows)\n",
    "        print(f\"    {year}: In={annual_inflow:.2f}, Out={annual_outflow:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e06da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FLOW MAGNITUDE ANALYSIS ===\n",
      "Annual timber input (2045): 6.40 Mg\n",
      "Cumulative input (1920-2045): 6828.20 Mg\n",
      "\n",
      "Reality check for Eichkamp Kiez:\n",
      "  Average per year: 54.19 Mg\n",
      "    âš ï¸ Input seems LOW for neighborhood scale\n"
     ]
    }
   ],
   "source": [
    "# Analyze flow magnitudes for geographic realism\n",
    "print(\"\\n=== FLOW MAGNITUDE ANALYSIS ===\")\n",
    "primary_flow = mfa_system_with_results.FlowDict.get('F_00_01')\n",
    "if primary_flow:\n",
    "    total_input_2045 = primary_flow.Values[-1, 0]  # 2045, material\n",
    "    cumulative_input = primary_flow.Values[:, 0].sum()\n",
    "    \n",
    "    print(f\"Annual timber input (2045): {total_input_2045:.2f} Mg\")\n",
    "    print(f\"Cumulative input (1920-2045): {cumulative_input:.2f} Mg\")\n",
    "    \n",
    "    # Reality check for neighborhood scale\n",
    "    # Eichkamp is a small Berlin neighborhood\n",
    "    print(\"\\nReality check for Eichkamp Kiez:\")\n",
    "    print(f\"  Average per year: {cumulative_input/126:.2f} Mg\")\n",
    "    \n",
    "    # Rough estimate: ~1000-2000 housing units in typical Berlin kiez\n",
    "    # Each unit might use 0.1-1 Mg timber per year for maintenance/renovation\n",
    "    estimated_range_low = 1000 * 0.1  # 100 Mg/year\n",
    "    estimated_range_high = 2000 * 1.0  # 2000 Mg/year\n",
    "    \n",
    "    if total_input_2045 < estimated_range_low:\n",
    "        print(f\"    âš ï¸ Input seems LOW for neighborhood scale\")\n",
    "    elif total_input_2045 > estimated_range_high:\n",
    "        print(f\"    âš ï¸ Input seems HIGH for neighborhood scale\")\n",
    "    else:\n",
    "        print(f\"    âœ… Input magnitude seems reasonable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60c5c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEMPORAL TRENDS ANALYSIS ===\n",
      "Early period average (1920-1945): 84.65 Mg/year\n",
      "Recent period average (2020-2045): 11.54 Mg/year\n",
      "Growth factor: 0.1x\n",
      "    âš ï¸ Declining trend - unusual for urban development\n"
     ]
    }
   ],
   "source": [
    "# Analyze temporal trends\n",
    "print(\"\\n=== TEMPORAL TRENDS ANALYSIS ===\")\n",
    "years = mfa_system_with_results.IndexTable.Classification['Time'].Items\n",
    "\n",
    "# Look at primary input trends\n",
    "primary_flow = mfa_system_with_results.FlowDict.get('F_00_01')\n",
    "if primary_flow:\n",
    "    early_avg = primary_flow.Values[:25, 0].mean()  # 1920-1945\n",
    "    recent_avg = primary_flow.Values[-25:, 0].mean()  # 2020-2045\n",
    "    \n",
    "    print(f\"Early period average (1920-1945): {early_avg:.2f} Mg/year\")\n",
    "    print(f\"Recent period average (2020-2045): {recent_avg:.2f} Mg/year\")\n",
    "    print(f\"Growth factor: {recent_avg/early_avg:.1f}x\")\n",
    "    \n",
    "    # Check for realistic urbanization/construction trends\n",
    "    if recent_avg > early_avg * 10:\n",
    "        print(\"    âš ï¸ Very high growth - check if realistic for neighborhood\")\n",
    "    elif recent_avg < early_avg:\n",
    "        print(\"    âš ï¸ Declining trend - unusual for urban development\")\n",
    "    else:\n",
    "        print(\"    âœ… Growth trend seems reasonable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01916c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DSM TIMING ANALYSIS ===\n",
      "Process 0:\n",
      "  Expected lifetime: 20 years\n",
      "  First outflows after: 0 years\n",
      "    âœ… Outflow timing consistent with lifetime\n",
      "Process 2:\n",
      "  Expected lifetime: 6 years\n",
      "  First outflows after: 5 years\n",
      "    âœ… Outflow timing consistent with lifetime\n",
      "Process 3:\n",
      "  Expected lifetime: 80 years\n",
      "  First outflows after: 57 years\n",
      "    âœ… Outflow timing consistent with lifetime\n",
      "Process 7:\n",
      "  Expected lifetime: 70 years\n",
      "  First outflows after: 100 years\n",
      "    âœ… Outflow timing consistent with lifetime\n"
     ]
    }
   ],
   "source": [
    "# Check DSM outflow timing\n",
    "print(\"\\n=== DSM TIMING ANALYSIS ===\")\n",
    "for process_id in DSM_PARAMS.keys():\n",
    "    outflows = [f for f in mfa_system_with_results.FlowDict.values() if f.P_Start == process_id]\n",
    "    if outflows:\n",
    "        outflow = outflows[0]  # Take first outflow\n",
    "        \n",
    "        # Find when significant outflows start\n",
    "        cumulative_outflow = np.cumsum(outflow.Values[:, 0])\n",
    "        first_significant = np.where(cumulative_outflow > cumulative_outflow[-1] * 0.01)[0]\n",
    "        \n",
    "        if len(first_significant) > 0:\n",
    "            delay_years = first_significant[0]\n",
    "            mean_lifetime = DSM_PARAMS[process_id]['lifetimes']['Mean'][0]\n",
    "            \n",
    "            print(f\"Process {process_id}:\")\n",
    "            print(f\"  Expected lifetime: {mean_lifetime} years\")\n",
    "            print(f\"  First outflows after: {delay_years} years\")\n",
    "            \n",
    "            if delay_years > mean_lifetime * 2:\n",
    "                print(f\"    âš ï¸ Outflows delayed too long vs. expected lifetime\")\n",
    "            else:\n",
    "                print(f\"    âœ… Outflow timing consistent with lifetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c9bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TC PARAMETER MATCHING DEBUG ===\n",
      "Available TC parameters: ['TC_07_00', 'TC_00_01', 'TC_05_00', 'TC_05_07', 'TC_06_07', 'TC_06_08', 'TC_02_03', 'TC_02_08', 'TC_01_00', 'TC_01_02', 'TC_04_03', 'TC_04_08', 'TC_03_04', 'TC_03_05', 'TC_03_06']\n",
      "Flow F_01_02 expects TC: TC_01_02 - âœ… EXISTS\n",
      "Flow F_01_00 expects TC: TC_01_00 - âœ… EXISTS\n",
      "Flow F_02_03 expects TC: TC_02_03 - âœ… EXISTS\n",
      "Flow F_03_04 expects TC: TC_03_04 - âœ… EXISTS\n",
      "Flow F_04_03 expects TC: TC_04_03 - âœ… EXISTS\n",
      "Flow F_03_05 expects TC: TC_03_05 - âœ… EXISTS\n",
      "Flow F_03_06 expects TC: TC_03_06 - âœ… EXISTS\n",
      "Flow F_05_07 expects TC: TC_05_07 - âœ… EXISTS\n",
      "Flow F_05_00 expects TC: TC_05_00 - âœ… EXISTS\n",
      "Flow F_06_07 expects TC: TC_06_07 - âœ… EXISTS\n",
      "Flow F_06_08 expects TC: TC_06_08 - âœ… EXISTS\n",
      "Flow F_02_08 expects TC: TC_02_08 - âœ… EXISTS\n",
      "Flow F_04_08 expects TC: TC_04_08 - âœ… EXISTS\n",
      "Flow F_07_00 expects TC: TC_07_00 - âœ… EXISTS\n",
      "\n",
      "ðŸ” MISSING TC ANALYSIS:\n",
      "Found 0 flows without matching TCs\n"
     ]
    }
   ],
   "source": [
    "# DEBUG cell before running MFA calculation\n",
    "print(\"=== TC PARAMETER MATCHING DEBUG ===\")\n",
    "\n",
    "# Check what TC parameters actually exist\n",
    "available_tcs = [name for name in mfa_system_with_results.ParameterDict.keys() if name.startswith('TC_')]\n",
    "print(f\"Available TC parameters: {available_tcs}\")\n",
    "\n",
    "# Check what the code expects for each flow\n",
    "expected_missing_pairs = []\n",
    "for flow_name, flow_obj in mfa_system_with_results.FlowDict.items():\n",
    "    if flow_name != 'F_00_01':  # Skip primary input\n",
    "        expected_tc = f\"TC_{'_'.join(flow_name.split('_')[1:3])}\"\n",
    "        exists = expected_tc in mfa_system_with_results.ParameterDict\n",
    "        \n",
    "        print(f\"Flow {flow_name} expects TC: {expected_tc} - {'âœ… EXISTS' if exists else 'âŒ MISSING'}\")\n",
    "        \n",
    "        if not exists:\n",
    "            expected_missing_pairs.append((flow_name, expected_tc))\n",
    "\n",
    "print(f\"\\nðŸ” MISSING TC ANALYSIS:\")\n",
    "print(f\"Found {len(expected_missing_pairs)} flows without matching TCs\")\n",
    "\n",
    "# Check your Excel TC sheet structure\n",
    "if 'all_excel_data' in globals():\n",
    "    tc_sheet = all_excel_data.get('2_5_dynamic_tcs')\n",
    "    if tc_sheet is not None:\n",
    "        print(f\"\\nTC Excel data preview:\")\n",
    "        print(tc_sheet.head())\n",
    "        print(f\"Available TC_IDs in Excel: {list(tc_sheet['TC_ID'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0497ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ðŸ—ºï¸ MFA SYSTEM ARCHITECTURE MAP\n",
      "    ===============================\n",
      "    \n",
      "    ðŸ“Š EXECUTION FLOW:\n",
      "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "    â”‚   Excel Data    â”‚â”€â”€â”€â–¶â”‚  System Setup       â”‚â”€â”€â”€â–¶â”‚ MFA Calculation â”‚\n",
      "    â”‚   (6 sheets)    â”‚    â”‚  (Processes/Flows)  â”‚    â”‚  (Enhanced)     â”‚\n",
      "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "             â”‚                        â”‚                         â”‚\n",
      "             â–¼                        â–¼                         â–¼\n",
      "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "    â”‚ Data Validation â”‚    â”‚ Dynamic Parameters   â”‚    â”‚ Results & DSM   â”‚\n",
      "    â”‚ & Processing    â”‚    â”‚ (Time Series TCs)    â”‚    â”‚ Integration     â”‚\n",
      "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "    \n",
      "    ðŸ”§ MAIN COMPONENTS:\n",
      "    â”œâ”€â”€ ðŸ“ Input Layer: Excel sheets (2_1 to 2_6)\n",
      "    â”œâ”€â”€ ðŸ—ï¸ Object Layer: 8 Processes, 15 Flows, 5 Stocks  \n",
      "    â”œâ”€â”€ ðŸ”„ Parameter Layer: 15 Dynamic TCs (126 time steps)\n",
      "    â”œâ”€â”€ ðŸ§® Calculation Layer: Enhanced MFA solver + DSM\n",
      "    â””â”€â”€ ðŸ“Š Output Layer: Flow series + Stock evolution\n",
      "    \n",
      "    â±ï¸ TIME DIMENSION: 1920-2045 (126 years)\n",
      "    ðŸ§ª ELEMENTS: CC, DM, WC (multi-element tracking)\n",
      "    ðŸ”„ DYNAMICS: Time-varying transfer coefficients\n",
      "    \n",
      "=== FUNCTION CALL TRACE ===\n",
      "1. ðŸ“‚ load_and_define_processes()\n",
      "   â”œâ”€â”€ pd.read_excel() - Load 6 Excel sheets\n",
      "   â”œâ”€â”€ Create 8 Process objects\n",
      "   â”œâ”€â”€ Create 15 Flow objects\n",
      "   â””â”€â”€ Initialize 5 Stock objects\n",
      "\n",
      "2. ðŸ”„ create_dynamic_transfer_coefficients()\n",
      "   â”œâ”€â”€ Extract TC data from Excel\n",
      "   â”œâ”€â”€ np.interp() - Interpolate 126 time steps\n",
      "   â”œâ”€â”€ Create 15 dynamic Parameter objects\n",
      "   â””â”€â”€ Normalize for mass balance\n",
      "\n",
      "3. ðŸ§® run_mfa_calculation()\n",
      "   â”œâ”€â”€ Resolve calculation dependencies\n",
      "   â”œâ”€â”€ Iterative flow calculation (3 rounds)\n",
      "   â”œâ”€â”€ DSM integration for 5 stocks\n",
      "   â””â”€â”€ Mass balance verification\n",
      "\n",
      "4. ðŸ“Š Results processing & analysis\n"
     ]
    }
   ],
   "source": [
    "# Add this to your MFA script instead of AppMap\n",
    "def visualize_mfa_system():\n",
    "    \"\"\"Visualize MFA system architecture without AppMap\"\"\"\n",
    "    print(\"\"\"\n",
    "    ðŸ—ºï¸ MFA SYSTEM ARCHITECTURE MAP\n",
    "    ===============================\n",
    "    \n",
    "    ðŸ“Š EXECUTION FLOW:\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   Excel Data    â”‚â”€â”€â”€â–¶â”‚  System Setup       â”‚â”€â”€â”€â–¶â”‚ MFA Calculation â”‚\n",
    "    â”‚   (6 sheets)    â”‚    â”‚  (Processes/Flows)  â”‚    â”‚  (Enhanced)     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             â”‚                        â”‚                         â”‚\n",
    "             â–¼                        â–¼                         â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Data Validation â”‚    â”‚ Dynamic Parameters   â”‚    â”‚ Results & DSM   â”‚\n",
    "    â”‚ & Processing    â”‚    â”‚ (Time Series TCs)    â”‚    â”‚ Integration     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    \n",
    "    ðŸ”§ MAIN COMPONENTS:\n",
    "    â”œâ”€â”€ ðŸ“ Input Layer: Excel sheets (2_1 to 2_6)\n",
    "    â”œâ”€â”€ ðŸ—ï¸ Object Layer: 8 Processes, 15 Flows, 5 Stocks  \n",
    "    â”œâ”€â”€ ðŸ”„ Parameter Layer: 15 Dynamic TCs (126 time steps)\n",
    "    â”œâ”€â”€ ðŸ§® Calculation Layer: Enhanced MFA solver + DSM\n",
    "    â””â”€â”€ ðŸ“Š Output Layer: Flow series + Stock evolution\n",
    "    \n",
    "    â±ï¸ TIME DIMENSION: 1920-2045 (126 years)\n",
    "    ðŸ§ª ELEMENTS: CC, DM, WC (multi-element tracking)\n",
    "    ðŸ”„ DYNAMICS: Time-varying transfer coefficients\n",
    "    \"\"\")\n",
    "\n",
    "def trace_function_calls():\n",
    "    \"\"\"Manual function call tracing\"\"\"\n",
    "    call_sequence = [\n",
    "        \"1. ðŸ“‚ load_and_define_processes()\",\n",
    "        \"   â”œâ”€â”€ pd.read_excel() - Load 6 Excel sheets\",\n",
    "        \"   â”œâ”€â”€ Create 8 Process objects\", \n",
    "        \"   â”œâ”€â”€ Create 15 Flow objects\",\n",
    "        \"   â””â”€â”€ Initialize 5 Stock objects\",\n",
    "        \"\",\n",
    "        \"2. ðŸ”„ create_dynamic_transfer_coefficients()\",\n",
    "        \"   â”œâ”€â”€ Extract TC data from Excel\",\n",
    "        \"   â”œâ”€â”€ np.interp() - Interpolate 126 time steps\",\n",
    "        \"   â”œâ”€â”€ Create 15 dynamic Parameter objects\",\n",
    "        \"   â””â”€â”€ Normalize for mass balance\",\n",
    "        \"\",\n",
    "        \"3. ðŸ§® run_mfa_calculation()\",\n",
    "        \"   â”œâ”€â”€ Resolve calculation dependencies\",\n",
    "        \"   â”œâ”€â”€ Iterative flow calculation (3 rounds)\",\n",
    "        \"   â”œâ”€â”€ DSM integration for 5 stocks\",\n",
    "        \"   â””â”€â”€ Mass balance verification\",\n",
    "        \"\",\n",
    "        \"4. ðŸ“Š Results processing & analysis\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=== FUNCTION CALL TRACE ===\")\n",
    "    for step in call_sequence:\n",
    "        print(step)\n",
    "\n",
    "# Use these instead of AppMap\n",
    "visualize_mfa_system()\n",
    "trace_function_calls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f057dc-9a37-4a60-89ce-604e34088e48",
   "metadata": {},
   "source": [
    "# Section 3: Main workflow (execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "402a9afa-0295-4a12-af8f-81791df1e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Model scope and classifications defined.\n",
      "--> MFA system object initialized.\n",
      "--> Excel file '250731_V11.xlsx' loaded successfully.\n",
      "\n",
      "=== PROCESSING PROCESS DEFINITIONS ===\n",
      "  Processing: Biosphere (ID: 0)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_0, S_0\n",
      "  Processing: Raw Material Extraction (ID: 1)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Processing (ID: 2)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_2, S_2\n",
      "  Processing: Use (ID: 3)\n",
      "    TC: True, Dynamic TC: True, Stock: True\n",
      "    âœ… Created stocks: dS_3, S_3\n",
      "  Processing: Refurbishment (ID: 4)\n",
      "    TC: True, Dynamic TC: True, Stock: False\n",
      "  Processing: Degredation (ID: 5)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Incineration (ID: 6)\n",
      "    TC: True, Dynamic TC: False, Stock: False\n",
      "  Processing: Atmosphere (ID: 7)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_7, S_7\n",
      "  Processing: Anthroposphere (ID: 8)\n",
      "    TC: True, Dynamic TC: False, Stock: True\n",
      "    âœ… Created stocks: dS_8, S_8\n",
      "\n",
      "--> Initializing stock values...\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING SUMMARY\n",
      "==================================================\n",
      "ðŸ“Š PROCESSES:\n",
      "  Total processes created: 9\n",
      "  Process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "\n",
      "ðŸ“ˆ TRANSFER COEFFICIENTS:\n",
      "  Static TC processes: 9\n",
      "  TC process names: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "  Dynamic TC processes: 3\n",
      "  Dynamic TC process names: ['Processing', 'Use', 'Refurbishment']\n",
      "\n",
      "ðŸ“¦ STOCKS:\n",
      "  Total stocks created: 10\n",
      "  Stock process names: ['Biosphere', 'Processing', 'Use', 'Atmosphere', 'Anthroposphere']\n",
      "  Stock names: ['dS_0', 'S_0', 'dS_2', 'S_2', 'dS_3', 'S_3', 'dS_7', 'S_7', 'dS_8', 'S_8']\n",
      "  Example stock array shape: (126, 4)\n",
      "\n",
      "==================================================\n",
      "PROCESS LOADING COMPLETE\n",
      "==================================================\n",
      "\n",
      "ðŸ” VALIDATION CHECKS:\n",
      "  âœ… Processes in system: 9\n",
      "  âœ… Stocks in system: 10\n",
      "\n",
      "--> Defined flows.\n",
      "--> Added numerical data to input flows.\n",
      "--> Processing dynamic TCs...\n",
      "--> Generating dynamic TC time series via interpolation...\n",
      "Generated 15 dynamic TC parameter(s).\n",
      "    -> Added dynamic TC: TC_07_00\n",
      "    -> Added dynamic TC: TC_00_01\n",
      "    -> Added dynamic TC: TC_05_00\n",
      "    -> Added dynamic TC: TC_05_07\n",
      "    -> Added dynamic TC: TC_06_07\n",
      "    -> Added dynamic TC: TC_06_08\n",
      "    -> Added dynamic TC: TC_02_03\n",
      "    -> Added dynamic TC: TC_02_08\n",
      "    -> Added dynamic TC: TC_01_00\n",
      "    -> Added dynamic TC: TC_01_02\n",
      "    -> Added dynamic TC: TC_04_03\n",
      "    -> Added dynamic TC: TC_04_08\n",
      "    -> Added dynamic TC: TC_03_04\n",
      "    -> Added dynamic TC: TC_03_05\n",
      "    -> Added dynamic TC: TC_03_06\n",
      "--> Created 15 dynamic TC parameters\n",
      "--> Defined 75 parameters.\n",
      "--> Calculating elemental composition for primary input flows...\n",
      "--> System setup is complete and ready for calculations!\n",
      "F_00_01: [[302.6   60.52 242.08 151.3 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [186.4   37.28 149.12  93.2 ]\n",
      " [173.6   34.72 138.88  86.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [147.8   29.56 118.24  73.9 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 96.4   19.28  77.12  48.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [199.2   39.84 159.36  99.6 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [109.2   21.84  87.36  54.6 ]\n",
      " [103.    20.6   82.4   51.5 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [128.6   25.72 102.88  64.3 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [115.8   23.16  92.64  57.9 ]\n",
      " [205.6   41.12 164.48 102.8 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 57.8   11.56  46.24  28.9 ]\n",
      " [ 77.2   15.44  61.76  38.6 ]\n",
      " [ 70.8   14.16  56.64  35.4 ]\n",
      " [141.4   28.28 113.12  70.7 ]\n",
      " [ 38.6    7.72  30.88  19.3 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 90.    18.    72.    45.  ]\n",
      " [ 64.4   12.88  51.52  32.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 51.4   10.28  41.12  25.7 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 45.     9.    36.    22.5 ]\n",
      " [ 83.6   16.72  66.88  41.8 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [ 19.2    3.84  15.36   9.6 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 12.8    2.56  10.24   6.4 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [ 32.2    6.44  25.76  16.1 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [  6.4    1.28   5.12   3.2 ]\n",
      " [  0.     0.     0.     0.  ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [ 25.8    5.16  20.64  12.9 ]\n",
      " [  6.4    1.28   5.12   3.2 ]]\n",
      "F_01_02: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_01_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_04: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_03: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_05: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_03_06: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_05_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_07: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_06_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_02_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_04_08: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "F_07_00: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "ðŸš€ STARTING ENHANCED MFA SOLVER WITH DYNAMIC TC SUPPORT\n",
      "Primary flows: ['F_00_01']\n",
      "DSM processes: {0, 2, 3, 7, 8}\n",
      "\n",
      "--- Iteration 1 ---\n",
      "  âœ… Calculating F_01_02 using TC_01_02\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=211.82, sum=11949.35\n",
      "  âœ… Calculating F_01_00 using TC_01_00\n",
      "      Input flows ready: ['F_00_01']\n",
      "      max=90.78, sum=5121.15\n",
      "  â³ F_04_03 waiting for inputs: ['F_03_04']\n",
      "  â³ F_04_08 waiting for inputs: ['F_03_04']\n",
      "  â³ F_05_07 waiting for inputs: ['F_03_05']\n",
      "  â³ F_05_00 waiting for inputs: ['F_03_05']\n",
      "  â³ F_06_07 waiting for inputs: ['F_03_06']\n",
      "  â³ F_06_08 waiting for inputs: ['F_03_06']\n",
      "  Calculated flows this iteration: ['F_01_02', 'F_01_00']\n",
      "--> ðŸ¤– Running DSM for Process 0...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 0\n",
      "      Auto-read elemental contents for F_01_00:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 0\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_00_01: max=36.62\n",
      "--> ðŸ¤– Running DSM for Process 2...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 2\n",
      "      Auto-read elemental contents for F_01_02:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 2\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_02_03: max=112.35\n",
      "--> ðŸ¤– Running DSM for Process 3...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 3\n",
      "      Auto-read elemental contents for F_02_03:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 3\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_03_04: max=44.25\n",
      "\n",
      "--- Iteration 2 ---\n",
      "  âœ… Calculating DSM output F_02_08 using TC_02_08\n",
      "      Input flows ready: DSM output from Process 2\n",
      "      max=54.15, sum=4537.64\n",
      "  âœ… Calculating DSM output F_03_05 using TC_03_05\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=1.68, sum=215.41\n",
      "  âœ… Calculating DSM output F_03_06 using TC_03_06\n",
      "      Input flows ready: DSM output from Process 3\n",
      "      max=37.29, sum=4598.64\n",
      "  âœ… Calculating F_04_03 using TC_04_03\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=0.82, sum=99.45\n",
      "  âœ… Calculating F_04_08 using TC_04_08\n",
      "      Input flows ready: ['F_03_04']\n",
      "      max=43.51, sum=5318.86\n",
      "  âœ… Calculating F_05_07 using TC_05_07\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=1.60, sum=204.64\n",
      "  âœ… Calculating F_05_00 using TC_05_00\n",
      "      Input flows ready: ['F_03_05']\n",
      "      max=0.08, sum=10.77\n",
      "  âœ… Calculating F_06_07 using TC_06_07\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=36.91, sum=4552.65\n",
      "  âœ… Calculating F_06_08 using TC_06_08\n",
      "      Input flows ready: ['F_03_06']\n",
      "      max=0.37, sum=45.99\n",
      "  Calculated flows this iteration: ['F_02_08', 'F_03_05', 'F_03_06', 'F_04_03', 'F_04_08', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08']\n",
      "--> ðŸ¤– Running DSM for Process 7...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 7\n",
      "      Auto-read elemental contents for F_05_07:\n",
      "        CC: 50.0%\n",
      "        DM: 80.0%\n",
      "        WC: 20.0%\n",
      "        WC outflow calculated with fixed content 20.0%\n",
      "        DM outflow calculated with fixed content 80.0%\n",
      "        CC outflow calculated with fixed content 50.0%\n",
      "      âœ… DSM completed for Process 7\n",
      "--> Dynamic stock calculation finished.\n",
      "      âœ… DSM Output F_07_00: max=0.26\n",
      "--> ðŸ¤– Running DSM for Process 8...\n",
      "--> Calculating dynamic stocks with automatic elemental content...\n",
      "    ... running DSM for process 8\n",
      "Warning: Missing inflow or outflow for process 8\n",
      "--> Dynamic stock calculation finished.\n",
      "\n",
      "--- Iteration 3 ---\n",
      "  Calculated flows this iteration: []\n",
      "--- âœ… System converged at iteration 3 ---\n",
      "\n",
      "--- FINAL FLOW STATUS ---\n",
      "âœ… Flows WITH data (15): ['F_00_01', 'F_01_02', 'F_01_00', 'F_02_03', 'F_03_04', 'F_04_03', 'F_03_05', 'F_03_06', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08', 'F_02_08', 'F_04_08', 'F_07_00']\n",
      "âŒ Flows WITHOUT data (0): []\n",
      "\n",
      "--- Finalizing stock balances ---\n",
      "--> Calculating final stock balances...\n",
      "  -> Skipping balance calculation for primary input process 0 (Biosphere)\n",
      "  -> Skipping balance calculation for DSM process 2 (Processing)\n",
      "  -> Skipping balance calculation for DSM process 3 (Use)\n",
      "  -> Skipping balance calculation for DSM process 7 (Atmosphere)\n",
      "  -> Skipping balance calculation for DSM process 8 (Anthroposphere)\n",
      "--> Stock balance calculation finished.\n",
      "\n",
      "ðŸŽ‰ MFA calculation finished after 3 iterations.\n",
      "\n",
      "Running MFA calculations...\n",
      "Calculation complete.\n",
      "\n",
      "Final Mass Balance Check (Sum of absolute errors per process):\n",
      "[5.20289941e+03 1.24111832e-12 4.53763524e+03 4.71460312e+03\n",
      " 2.69248516e-13 1.29515405e-14 2.68546983e-13 4.55265177e+03\n",
      " 9.90248600e+03]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa3358e44cc4f09a8f4a667e39f53ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1920, description='Year', max=2045, min=1920), Dropdown(description='Eleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797775b9676144329f2f8c9d9731cb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': [#2ca02c, #7f7f7f, #2ca02c, #2ca02c, #7f7f7f,\n",
       "                                   #7f7f7f, #7f7f7f, #d62728, #d62728]},\n",
       "              'type': 'bar',\n",
       "              'uid': '0f19fb53-24e6-4960-ac03-4f1e17f12162',\n",
       "              'x': [Biosphere, Raw Material Extraction, Processing, Use,\n",
       "                    Refurbishment, Degredation, Incineration, Atmosphere,\n",
       "                    Anthroposphere],\n",
       "              'y': [-302.5999739767458, 0.0, -0.1429677005299652,\n",
       "                    -8.811111956719131e-08, 0.0, 0.0, 0.0, 7.100116961367142e-08,\n",
       "                    0.14296777911277508]}],\n",
       "    'layout': {'shapes': [{'line': {'color': 'black', 'width': 2},\n",
       "                           'type': 'line',\n",
       "                           'x0': -0.5,\n",
       "                           'x1': 8.5,\n",
       "                           'y0': 0,\n",
       "                           'y1': 0}],\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Mass Balance Error Check for MATERIAL in 1920'},\n",
       "               'yaxis': {'title': {'text': 'Error in Mg (positive = mass created)'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… System setup is complete and ready for calculations!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# Section 3: Main Execution / Workflow (Corrected Version)\n",
    "# ====================================================================\n",
    "\n",
    "# --- 1. Define Model Scope ---\n",
    "# We call our new function and pass the parameters from the configuration block\n",
    "model_classification, index_table = define_model_scope(START_YEAR, END_YEAR, ELEMENTS)\n",
    "\n",
    "# --- 2. Initialize the MFA System Object ---\n",
    "# The output of the first function is the input for this one\n",
    "my_mfa_system = initialize_mfa_system(model_classification, index_table)\n",
    "\n",
    "#visualize_mfa_skeleton(my_mfa_system)\n",
    "\n",
    "# --- 3. Load Data and Define Processes/Stocks ---\n",
    "# The mfa_system object is passed in and gets modified by the function.\n",
    "# We also receive all excel data to use it in the next steps.\n",
    "my_mfa_system, all_excel_data = load_and_define_processes(my_mfa_system, EXCEL_FILE_PATH)\n",
    "\n",
    "# --- 4. Define Flows and Parameters ---\n",
    "# This function completes the setup of the system object.\n",
    "# This is the correct call that unpacks the tuple.\n",
    "mfa_system_with_results, _ = define_flows_and_parameters(my_mfa_system, all_excel_data, DSM_PARAMS)\n",
    "\n",
    "mfa_system_with_results, dsm_details = run_mfa_calculation(mfa_system_with_results)\n",
    "\n",
    "# --- 5. Calculation Phase ---\n",
    "print(\"\\nRunning MFA calculations...\")\n",
    "\n",
    "print(\"Calculation complete.\")\n",
    "\n",
    "# --- 6. Display final mass balance (optional) ---\n",
    "balance = mfa_system_with_results.MassBalance()\n",
    "print(\"\\nFinal Mass Balance Check (Sum of absolute errors per process):\")\n",
    "print(np.abs(balance).sum(axis=0).sum(axis=1))\n",
    "plot_mass_balance_error(mfa_system_with_results)\n",
    "\n",
    "print(\"\\nâœ… System setup is complete and ready for calculations!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4c0ea-676e-40e2-ab0b-2e4c3cd12d59",
   "metadata": {},
   "source": [
    "### ÃœberprÃ¼fung der Massenbilanz\n",
    "\n",
    "Die folgende Grafik ist das wichtigste Werkzeug zur ÃœberprÃ¼fung der Modellkonsistenz. Sie zeigt den Massenbilanzfehler fÃ¼r jeden Prozess, berechnet nach der Formel:\n",
    "\n",
    "**`Fehler = Î£ ZuflÃ¼sse - Î£ AbflÃ¼sse - LagerverÃ¤nderung (dS)`**\n",
    "\n",
    "**Wie man die Grafik liest:**\n",
    "* **Perfektes Gleichgewicht:** Ein Prozess ist perfekt bilanziert, wenn sein Balken genau auf der Nulllinie liegt.\n",
    "* **Positiver Fehler (Balken > 0):** Es wurde mehr Masse \"erschaffen\" als im System sein dÃ¼rfte. MÃ¶gliche Ursache: Ein Abfluss oder eine Lagerbildung fehlt in der Definition.\n",
    "* **Negativer Fehler (Balken < 0):** Es ist Masse \"verschwunden\". MÃ¶gliche Ursache: Ein Zufluss fehlt oder ein Abfluss wird doppelt gezÃ¤hlt.\n",
    "\n",
    "Je grÃ¶ÃŸer die Abweichung von Null, desto gravierender ist der Fehler in der Modelllogik fÃ¼r diesen Prozess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8914354d-b63b-4795-9f3f-36766003c0eb",
   "metadata": {},
   "source": [
    "# Section 4: Results and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b11f994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive_sankey(mfa_system_results):\n",
    "    import plotly.graph_objects as go\n",
    "    from ipywidgets import interact, IntSlider, Dropdown, SelectMultiple, FloatSlider\n",
    "\n",
    "    # --- NEW: Build process_id_to_name including system boundary ---\n",
    "    process_id_to_name = {p.ID: p.Name for p in mfa_system_results.ProcessList}\n",
    "    if 0 not in process_id_to_name:\n",
    "        process_id_to_name[0] = \"System\"  # or \"Outside\"\n",
    "\n",
    "    all_process_names = list(process_id_to_name.values())\n",
    "    all_flows = list(mfa_system_results.FlowDict.values())\n",
    "    time_items = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    element_items = mfa_system_results.Elements\n",
    "    max_flow_value = max(f.Values.max() for f in all_flows if f.Values is not None) if all_flows else 1\n",
    "\n",
    "    fig = go.FigureWidget(data=[go.Sankey(node=dict(label=[]), link=dict(source=[], target=[], value=[]))])\n",
    "\n",
    "    def update_sankey(year, element, processes_to_show, min_flow_value):\n",
    "        if not processes_to_show:\n",
    "            with fig.batch_update(): fig.data[0].node.label = []\n",
    "            return\n",
    "\n",
    "        # --- REPLACE THIS BLOCK WITH THE FOLLOWING ---\n",
    "        label_map = {pid: i for i, pid in enumerate(process_id_to_name.keys()) if process_id_to_name[pid] in processes_to_show}\n",
    "        filtered_labels = [name for name in processes_to_show]\n",
    "\n",
    "        year_index = time_items.index(year)\n",
    "        element_index = element_items.index(element)\n",
    "\n",
    "        candidate_flows = [f for f in all_flows if f.P_Start in label_map and f.P_End in label_map]\n",
    "        final_flows = [f for f in candidate_flows if f.Values[year_index, element_index] >= min_flow_value]\n",
    "\n",
    "        with fig.batch_update():\n",
    "            if not final_flows:\n",
    "                fig.data[0].node.label = filtered_labels\n",
    "                fig.data[0].link.source, fig.data[0].link.target, fig.data[0].link.value = [], [], []\n",
    "            else:\n",
    "                fig.data[0].node.label = filtered_labels\n",
    "                fig.data[0].node.color = \"blue\"\n",
    "                fig.data[0].link.source = [label_map[f.P_Start] for f in final_flows]\n",
    "                fig.data[0].link.target = [label_map[f.P_End] for f in final_flows]\n",
    "                fig.data[0].link.value = [f.Values[year_index, element_index] for f in final_flows]\n",
    "            fig.update_layout(title_text=f\"MFA Sankey for {element.upper()} in {year} (Flows > {min_flow_value:.2f} Mg)\",\n",
    "                              font_size=20, height=700, margin=dict(l=10, r=10, b=20, t=50))\n",
    "\n",
    "    # --- REPLACE THIS BLOCK WITH THE FOLLOWING ---\n",
    "    process_selector = SelectMultiple(options=all_process_names, value=list(all_process_names), description='Processes', rows=8)\n",
    "    year_slider = IntSlider(min=time_items[0], max=time_items[-1], step=1, value=time_items[0], description='Year')\n",
    "    element_dropdown = Dropdown(options=element_items, value=element_items[0], description='Element')\n",
    "    threshold_slider = FloatSlider(min=0, max=max_flow_value, step=max_flow_value/100, value=0,\n",
    "                                   description='Min Flow', continuous_update=False, readout_format='.2f')\n",
    "\n",
    "    interact(update_sankey, year=year_slider, element=element_dropdown, processes_to_show=process_selector, min_flow_value=threshold_slider)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3ad5e8e-8e11-4c4f-8ff7-2cf480d0282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function 4.3: Plot Inflow, Stock, and Outflow (Final Corrected Version) ---\n",
    "def plot_process_dynamics(mfa_system_results, process_definitions):\n",
    "    \"\"\"\n",
    "    Creates three side-by-side line charts showing the dynamics of \n",
    "    Inflow, Stock, and Outflow, using process type metadata for smarter titles.\n",
    "    \"\"\"\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.graph_objects as go\n",
    "    from ipywidgets import interact, Dropdown\n",
    "\n",
    "    # <<< HIER IST DIE ANPASSUNG: Der korrekte Spaltenname aus deiner Excel-Datei >>>\n",
    "    PROCESS_TYPE_COLUMN_NAME = 'Process_Type' \n",
    "\n",
    "    # Check if the column exists to avoid errors\n",
    "    has_type_column = PROCESS_TYPE_COLUMN_NAME in process_definitions.columns\n",
    "    if not has_type_column:\n",
    "        print(f\"Warning: Column '{PROCESS_TYPE_COLUMN_NAME}' not found in '2_1_Definition_Processes'. Smart titles will be disabled.\")\n",
    "\n",
    "    process_options = {p.Name: p.ID for p in mfa_system_results.ProcessList if f\"S_{p.ID}\" in mfa_system_results.StockDict}\n",
    "    if not process_options:\n",
    "        print(\"No processes with stocks found to plot.\")\n",
    "        return\n",
    "        \n",
    "    element_items = mfa_system_results.Elements\n",
    "    time_axis = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    \n",
    "    fig = go.FigureWidget(make_subplots(rows=1, cols=3, subplot_titles=(\"Inflow\", \"Stock (S)\", \"Outflow\")))\n",
    "\n",
    "    def update_plot(process_name, element):\n",
    "        pid = process_options[process_name]\n",
    "        element_index = element_items.index(element)\n",
    "\n",
    "        inflows = [f.Values[:, element_index] for f in mfa_system_results.FlowDict.values() if f.P_End == pid]\n",
    "        inflow_ts = sum(inflows) if inflows else np.zeros(len(time_axis))\n",
    "        stock_ts = mfa_system_results.StockDict[f'S_{pid}'].Values[:, element_index]\n",
    "        outflows = [f.Values[:, element_index] for f in mfa_system_results.FlowDict.values() if f.P_Start == pid]\n",
    "        outflow_ts = sum(outflows) if outflows else np.zeros(len(time_axis))\n",
    "        \n",
    "        subplot_titles = (f\"Inflow to '{process_name}'\", f\"Stock in '{process_name}'\", f\"Outflow from '{process_name}'\")\n",
    "        \n",
    "        if has_type_column:\n",
    "            process_type = process_definitions.loc[process_definitions['ID'] == pid, PROCESS_TYPE_COLUMN_NAME].iloc[0]\n",
    "            if process_type == 'Input':\n",
    "                subplot_titles = (\"Primary System Input\", f\"Stock in '{process_name}'\", f\"Outflow from '{process_name}'\")\n",
    "            elif process_type == 'Output':\n",
    "                subplot_titles = (f\"Inflow to '{process_name}'\", f\"Stock in '{process_name}'\", \"Final System Output (Sink)\")\n",
    "\n",
    "        with fig.batch_update():\n",
    "            fig.data, fig.layout.annotations = [], []\n",
    "            fig.add_trace(go.Scatter(x=time_axis, y=inflow_ts, mode='lines', name='Inflow'), row=1, col=1)\n",
    "            fig.add_trace(go.Scatter(x=time_axis, y=stock_ts, mode='lines', name='Stock'), row=1, col=2)\n",
    "            fig.add_trace(go.Scatter(x=time_axis, y=outflow_ts, mode='lines', name='Outflow'), row=1, col=3)\n",
    "            \n",
    "            fig.layout.annotations = [\n",
    "                dict(x=0.155, y=1.05, text=subplot_titles[0], showarrow=False, xref='paper', yref='paper', xanchor='center'),\n",
    "                dict(x=0.5, y=1.05, text=subplot_titles[1], showarrow=False, xref='paper', yref='paper', xanchor='center'),\n",
    "                dict(x=0.845, y=1.05, text=subplot_titles[2], showarrow=False, xref='paper', yref='paper', xanchor='center')\n",
    "            ]\n",
    "            fig.update_layout(title=f\"Dynamics for Process: '{process_name}' | Element: {element.upper()}\", height=400, showlegend=False)\n",
    "            fig.update_xaxes(title_text=\"Year\")\n",
    "            fig.update_yaxes(title_text=\"Mass in Mg\", row=1, col=1)\n",
    "\n",
    "    process_dropdown = Dropdown(options=list(process_options.keys()), description='Process:')\n",
    "    element_dropdown = Dropdown(options=element_items, value=element_items[0], description='Element:')\n",
    "    \n",
    "    interact(update_plot, process_name=process_dropdown, element=element_dropdown)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65982a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helper Function 4.4: Plot dynamic stock composition from pre-calculated results ---\n",
    "def plot_dynamic_stock_composition(dsm_details, mfa_system_results):\n",
    "    \"\"\"\n",
    "    Visualizes the pre-calculated stock composition from the dsm_details dictionary.\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from ipywidgets import interact, Dropdown, Checkbox\n",
    "\n",
    "    # Create dropdown options from the available results\n",
    "    process_options = list(dsm_details.keys())\n",
    "    if not process_options:\n",
    "        print(\"DSM calculation was not run or produced no results. Nothing to plot.\")\n",
    "        return\n",
    "        \n",
    "    element_items = mfa_system_results.Elements\n",
    "    time_axis = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    \n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    def update_plot(process_id, element, show_as_bars):\n",
    "        details = dsm_details.get(process_id, {})\n",
    "        stock_by_category = details.get('stock_by_category', [])\n",
    "        category_labels = details.get('category_names', [])\n",
    "        \n",
    "        # Find the inflow flow to get the elemental content parameter\n",
    "        inflow_flow = next((f for f in mfa_system_results.FlowDict.values() if f.P_End == process_id), None)\n",
    "        \n",
    "        # Determine the multiplication factor for the selected element\n",
    "        content_factor = 1.0\n",
    "        if element != 'material' and inflow_flow:\n",
    "            param_name = f\"{element}_{inflow_flow.Name}\"\n",
    "            if param_name in mfa_system_results.ParameterDict:\n",
    "                content_factor = mfa_system_results.ParameterDict[param_name].Values\n",
    "            else: # If no parameter is found, the elemental stock is zero\n",
    "                content_factor = 0.0\n",
    "\n",
    "        with fig.batch_update():\n",
    "            fig.data = [] # Clear previous traces\n",
    "            chart_type = go.Bar if show_as_bars else go.Scatter\n",
    "            \n",
    "            for i, material_stock_ts in enumerate(stock_by_category):\n",
    "                # Calculate the elemental stock by applying the content factor\n",
    "                element_stock_ts = material_stock_ts * content_factor\n",
    "                \n",
    "                trace_props = dict(x=time_axis, y=element_stock_ts, name=category_labels[i], hoverinfo='x+y')\n",
    "                if not show_as_bars:\n",
    "                    trace_props.update(mode='lines', line=dict(width=0.5), stackgroup='one')\n",
    "                fig.add_trace(chart_type(**trace_props))\n",
    "\n",
    "            process_name = next((p.Name for p in mfa_system_results.ProcessList if p.ID == process_id), \"\")\n",
    "            fig.update_layout(\n",
    "                barmode='stack' if show_as_bars else None,\n",
    "                title=f\"Dynamic Stock Composition for Process: '{process_name}' ({element.upper()})\",\n",
    "                xaxis_title=\"Year\", yaxis_title=f\"Stock in Mg\"\n",
    "            )\n",
    "\n",
    "    interact(update_plot, \n",
    "             process_id=Dropdown(options=process_options, description='Process:'), \n",
    "             element=Dropdown(options=element_items, value=element_items[0], description='Element:'),\n",
    "             show_as_bars=Checkbox(value=False, description='Show as Bar Chart'))\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa59de6f-b1d1-4bec-b7a4-0173812e778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Helper Function 4.5: Plot the dynamics of a FOMP process ---\n",
    "# def plot_fomp_dynamics(mfa_system_results, FOMP_PARAMS):\n",
    "#     \"\"\"\n",
    "#     Creates side-by-side line charts for Inflow, Stock, and Outflow\n",
    "#     for a process calculated with FOMP. Includes interactive widgets.\n",
    "#     \"\"\"\n",
    "#     from plotly.subplots import make_subplots\n",
    "#     import plotly.graph_objects as go\n",
    "#     from ipywidgets import interact, Dropdown\n",
    "\n",
    "#     # Create a mapping of process names to IDs for the dropdown, only for FOMP processes\n",
    "#     process_options = {\n",
    "#         p.Name: p.ID \n",
    "#         for p in mfa_system_results.ProcessList \n",
    "#         if p.ID in FOMP_PARAMS\n",
    "#     }\n",
    "#     if not process_options:\n",
    "#         print(\"No processes with FOMP parameters are defined in the configuration.\")\n",
    "#         return\n",
    "        \n",
    "#     element_items = mfa_system_results.Elements\n",
    "#     time_axis = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    \n",
    "#     fig = go.FigureWidget(make_subplots(rows=1, cols=3, subplot_titles=(\"Total Inflow\", \"Absolute Stock (S)\", \"Outflow (Mineralization)\")))\n",
    "\n",
    "#     def update_plot(process_name, element):\n",
    "#         pid = process_options[process_name]\n",
    "#         element_index = element_items.index(element)\n",
    "\n",
    "#         # Get the time series data for the selected process\n",
    "#         inflow_ts = sum(f.Values[:, element_index] for f in mfa_system_results.FlowDict.values() if f.P_End == pid)\n",
    "#         stock_ts = mfa_system_results.StockDict.get(f'S_{pid}').Values[:, element_index]\n",
    "#         outflow_ts = sum(f.Values[:, element_index] for f in mfa_system_results.FlowDict.values() if f.P_Start == pid)\n",
    "        \n",
    "#         with fig.batch_update():\n",
    "#             fig.data = [] # Clear existing data\n",
    "#             fig.add_trace(go.Scatter(x=time_axis, y=inflow_ts, mode='lines', name='Inflow'), row=1, col=1)\n",
    "#             fig.add_trace(go.Scatter(x=time_axis, y=stock_ts, mode='lines', name='Stock'), row=1, col=2)\n",
    "#             fig.add_trace(go.Scatter(x=time_axis, y=outflow_ts, mode='lines', name='Outflow'), row=1, col=3)\n",
    "            \n",
    "#             title_text = f\"FOMP Dynamics for Process: '{process_name}' | Element: {element.upper()}\"\n",
    "#             fig.update_layout(title_text=title_text, height=400, showlegend=False)\n",
    "#             fig.update_xaxes(title_text=\"Year\")\n",
    "#             fig.update_yaxes(title_text=\"Mass [Mg]\", row=1, col=1)\n",
    "\n",
    "#     # Create widgets for interaction\n",
    "#     process_dropdown = Dropdown(options=list(process_options.keys()), description='Process:')\n",
    "#     element_dropdown = Dropdown(options=element_items, value=element_items[0], description='Element:')\n",
    "    \n",
    "#     interact(update_plot, process_name=process_dropdown, element=element_dropdown)\n",
    "#     display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35373367-22fe-4362-beef-1ae49d71338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function 4.6: Plot the dynamics of selected flows over time ---\n",
    "def plot_flow_dynamics(mfa_system_results):\n",
    "    \"\"\"\n",
    "    Creates an interactive line/bar chart to show the development of selected\n",
    "    flows over time for a chosen element.\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from ipywidgets import interact, Dropdown, SelectMultiple, Checkbox\n",
    "\n",
    "    # Create options for the widgets\n",
    "    flow_options = sorted(list(mfa_system_results.FlowDict.keys()))\n",
    "    if not flow_options:\n",
    "        print(\"No flows found in the system to plot.\")\n",
    "        return\n",
    "        \n",
    "    element_items = mfa_system_results.Elements\n",
    "    time_axis = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    \n",
    "    \n",
    "    # Use FigureWidget for efficient updates\n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    def update_plot(flows_to_show, element, show_as_bars):\n",
    "        # Use batch_update for smooth interaction\n",
    "        with fig.batch_update():\n",
    "            fig.data = [] # Clear previous traces\n",
    "            if not flows_to_show:\n",
    "                fig.update_layout(title_text=\"Please select one or more flows to display.\")\n",
    "                return\n",
    "\n",
    "            element_index = element_items.index(element)\n",
    "            chart_type = go.Bar if show_as_bars else go.Scatter\n",
    "\n",
    "            # Add a trace for each selected flow\n",
    "            for flow_id in flows_to_show:\n",
    "                flow_obj = mfa_system_results.FlowDict.get(flow_id)\n",
    "                if flow_obj:\n",
    "                    trace_props = dict(x=time_axis, y=flow_obj.Values[:, element_index], name=flow_id)\n",
    "                    if not show_as_bars:\n",
    "                        trace_props.update(mode='lines')\n",
    "                    fig.add_trace(chart_type(**trace_props))\n",
    "            \n",
    "            # Update layout and title\n",
    "            fig.update_layout(\n",
    "                barmode='stack' if show_as_bars else 'overlay',\n",
    "                title=f\"Time Series for Selected Flows ({element.upper()})\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Mass in Mg\",\n",
    "                hovermode=\"x unified\"\n",
    "            )\n",
    "\n",
    "    # Create widgets\n",
    "    flow_selector = SelectMultiple(options=flow_options, value=[flow_options[0]] if flow_options else [], description='Flows:', rows=10)\n",
    "    element_dropdown = Dropdown(options=element_items, value=element_items[0], description='Element:')\n",
    "    chart_type_checkbox = Checkbox(value=False, description='Show as Bar Chart')\n",
    "\n",
    "    interact(update_plot, flows_to_show=flow_selector, element=element_dropdown, show_as_bars=chart_type_checkbox)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dea1aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows: ['F_00_01', 'F_01_02', 'F_01_00', 'F_02_03', 'F_03_04', 'F_04_03', 'F_03_05', 'F_03_06', 'F_05_07', 'F_05_00', 'F_06_07', 'F_06_08', 'F_02_08', 'F_04_08', 'F_07_00']\n",
      "Processes: ['Biosphere', 'Raw Material Extraction', 'Processing', 'Use', 'Refurbishment', 'Degredation', 'Incineration', 'Atmosphere', 'Anthroposphere']\n",
      "Processes loaded:\n",
      "ID: 0, Name: Biosphere\n",
      "ID: 1, Name: Raw Material Extraction\n",
      "ID: 2, Name: Processing\n",
      "ID: 3, Name: Use\n",
      "ID: 4, Name: Refurbishment\n",
      "ID: 5, Name: Degredation\n",
      "ID: 6, Name: Incineration\n",
      "ID: 7, Name: Atmosphere\n",
      "ID: 8, Name: Anthroposphere\n",
      "\n",
      "Flows loaded:\n",
      "F_00_01: 0 -> 1\n",
      "F_01_02: 1 -> 2\n",
      "F_01_00: 1 -> 0\n",
      "F_02_03: 2 -> 3\n",
      "F_03_04: 3 -> 4\n",
      "F_04_03: 4 -> 3\n",
      "F_03_05: 3 -> 5\n",
      "F_03_06: 3 -> 6\n",
      "F_05_07: 5 -> 7\n",
      "F_05_00: 5 -> 0\n",
      "F_06_07: 6 -> 7\n",
      "F_06_08: 6 -> 8\n",
      "F_02_08: 2 -> 8\n",
      "F_04_08: 4 -> 8\n",
      "F_07_00: 7 -> 0\n",
      "Flow data: F_00_01: 0 -> 1, max=302.6, sum=17070.5\n",
      "Flow data: F_01_02: 1 -> 2, max=211.82, sum=11949.349999999999\n",
      "Flow data: F_01_00: 1 -> 0, max=90.78, sum=5121.15\n",
      "Flow data: F_02_03: 2 -> 3, max=112.35203336221545, sum=11804.443086719617\n",
      "Flow data: F_03_04: 3 -> 4, max=44.24659757055904, sum=5418.31187422035\n",
      "Flow data: F_04_03: 4 -> 3, max=0.8243685436391266, sum=99.44749686493508\n",
      "Flow data: F_03_05: 3 -> 5, max=1.6831771150372432, sum=215.41245930363297\n",
      "Flow data: F_03_06: 3 -> 6, max=37.28675541342502, sum=4598.638154810935\n",
      "Flow data: F_05_07: 5 -> 7, max=1.599018259285381, sum=204.6418363384513\n",
      "Flow data: F_05_00: 5 -> 0, max=0.08415885575186216, sum=10.77062296518165\n",
      "Flow data: F_06_07: 6 -> 7, max=36.91388785929077, sum=4552.6517732628245\n",
      "Flow data: F_06_08: 6 -> 8, max=0.3728675541342502, sum=45.98638154810934\n",
      "Flow data: F_02_08: 2 -> 8, max=54.15368008058785, sum=4537.635241639155\n",
      "Flow data: F_04_08: 4 -> 8, max=43.50679445917929, sum=5318.864377355415\n",
      "Flow data: F_07_00: 7 -> 0, max=0.2597770421124852, sum=5.038727657464994\n"
     ]
    }
   ],
   "source": [
    "print(\"Flows:\", list(mfa_system_with_results.FlowDict.keys()))\n",
    "print(\"Processes:\", [p.Name for p in mfa_system_with_results.ProcessList])\n",
    "\n",
    "print(\"Processes loaded:\")\n",
    "for p in mfa_system_with_results.ProcessList:\n",
    "    print(f\"ID: {p.ID}, Name: {p.Name}\")\n",
    "\n",
    "print(\"\\nFlows loaded:\")\n",
    "for f in mfa_system_with_results.FlowDict.values():\n",
    "    print(f\"{f.Name}: {f.P_Start} -> {f.P_End}\")\n",
    "\n",
    "for f in mfa_system_with_results.FlowDict.values():\n",
    "    print(f\"Flow data: {f.Name}: {f.P_Start} -> {f.P_End}, max={f.Values.max()}, sum={f.Values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0686aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mark all processes widget\n",
    "\n",
    "# all_process_names = [p.Name for p in mfa_system_with_results.ProcessList]\n",
    "\n",
    "# process_selector = SelectMultiple(\n",
    "#     options=all_process_names,\n",
    "#     value=list(all_process_names),  # <-- ensures all are selected by default\n",
    "#     description='Processes',\n",
    "#     rows=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4b3d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with flow 0\n",
    "process_id_to_name = {p.ID: p.Name for p in mfa_system_with_results.ProcessList}\n",
    "if 0 not in process_id_to_name:\n",
    "    process_id_to_name[0] = \"System\"\n",
    "\n",
    "all_process_names = list(process_id_to_name.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4caf5880-03b7-4a1f-a30a-739bd95cce96",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying interactive Sankey diagram:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34432f306ac0427a983311e7c940f732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1920, description='Year', max=2045, min=1920), Dropdown(description='Eleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de18f3519ab4606a42372ce217bf98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'link': {'source': [0, 1, 1, 2, 3, 4, 3, 3, 5, 5, 6, 6, 2, 4, 7],\n",
       "                       'target': [1, 2, 0, 3, 4, 3, 5, 6, 7, 0, 7, 8, 8, 8, 0],\n",
       "                       'value': [302.6, 211.82, 90.78, 0.285935401059902,\n",
       "                                 8.196383216585446e-08, 4.098191608292723e-09,\n",
       "                                 2.0490958041463614e-08, 7.171835314512265e-08,\n",
       "                                 1.9466410139390434e-08, 1.0245479020731807e-09,\n",
       "                                 7.100116961367142e-08, 7.171835314512265e-10,\n",
       "                                 0.142967700529951, 7.786564055756174e-08, 0.0]},\n",
       "              'node': {'color': 'blue',\n",
       "                       'label': [Biosphere, Raw Material Extraction, Processing,\n",
       "                                 Use, Refurbishment, Degredation, Incineration,\n",
       "                                 Atmosphere, Anthroposphere]},\n",
       "              'type': 'sankey',\n",
       "              'uid': '181cd5e6-3799-4dc1-9079-35f72847ae8b'}],\n",
       "    'layout': {'font': {'size': 20},\n",
       "               'height': 700,\n",
       "               'margin': {'b': 20, 'l': 10, 'r': 10, 't': 50},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'MFA Sankey for MATERIAL in 1920 (Flows > 0.00 Mg)'}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying Inflow-Stock-Outflow Dynamics:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95feb3f45b472f8cd6596fd43613af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Process:', options=('Biosphere', 'Processing', 'Use', 'Atmosphere'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642e7450b6d84b44a576cfc8e15c5042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'Inflow',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b03afbe8-d445-462e-a054-8beed6ac6e43',\n",
       "              'x': [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929,\n",
       "                    1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
       "                    1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
       "                    1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959,\n",
       "                    1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
       "                    1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979,\n",
       "                    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "                    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "                    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "                    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "                    2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029,\n",
       "                    2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "                    2040, 2041, 2042, 2043, 2044, 2045],\n",
       "              'xaxis': 'x',\n",
       "              'y': {'bdata': ('8tEfheuxVkB9w61wPQpKQBHugI/C9U' ... 'aJ3Nb1H0DpzcCzngcgQI46zOnBxgFA'),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y'},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'Stock',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9feb18fe-7bf1-4892-924a-5fec5733eca9',\n",
       "              'x': [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929,\n",
       "                    1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
       "                    1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
       "                    1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959,\n",
       "                    1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
       "                    1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979,\n",
       "                    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "                    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "                    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "                    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "                    2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029,\n",
       "                    2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "                    2040, 2041, 2042, 2043, 2044, 2045],\n",
       "              'xaxis': 'x2',\n",
       "              'y': {'bdata': ('SZD5F+uxVkCKvsc9hNthQCrLAqvy2G' ... 'YCR3YzUUDe4oLoQPVRQG5f3FOXW1FA'),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y2'},\n",
       "             {'mode': 'lines',\n",
       "              'name': 'Outflow',\n",
       "              'type': 'scatter',\n",
       "              'uid': '099ee895-b5fb-4b7d-8916-debd51e6e70d',\n",
       "              'x': [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929,\n",
       "                    1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
       "                    1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
       "                    1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959,\n",
       "                    1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
       "                    1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979,\n",
       "                    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "                    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "                    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "                    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "                    2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029,\n",
       "                    2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "                    2040, 2041, 2042, 2043, 2044, 2045],\n",
       "              'xaxis': 'x3',\n",
       "              'y': {'bdata': ('mpmZmZnpckAzMzMzM7NlQM3MzMzMTG' ... 'zMzMzMOUDNzMzMzMw5QJqZmZmZmRlA'),\n",
       "                    'dtype': 'f8'},\n",
       "              'yaxis': 'y3'}],\n",
       "    'layout': {'annotations': [{'showarrow': False,\n",
       "                                'text': \"Inflow to 'Biosphere'\",\n",
       "                                'x': 0.155,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 1.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'showarrow': False,\n",
       "                                'text': \"Stock in 'Biosphere'\",\n",
       "                                'x': 0.5,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 1.05,\n",
       "                                'yref': 'paper'},\n",
       "                               {'showarrow': False,\n",
       "                                'text': \"Outflow from 'Biosphere'\",\n",
       "                                'x': 0.845,\n",
       "                                'xanchor': 'center',\n",
       "                                'xref': 'paper',\n",
       "                                'y': 1.05,\n",
       "                                'yref': 'paper'}],\n",
       "               'height': 400,\n",
       "               'showlegend': False,\n",
       "               'template': '...',\n",
       "               'title': {'text': \"Dynamics for Process: 'Biosphere' | Element: MATERIAL\"},\n",
       "               'xaxis': {'anchor': 'y', 'domain': [0.0, 0.2888888888888889], 'title': {'text': 'Year'}},\n",
       "               'xaxis2': {'anchor': 'y2', 'domain': [0.35555555555555557, 0.6444444444444445], 'title': {'text': 'Year'}},\n",
       "               'xaxis3': {'anchor': 'y3', 'domain': [0.7111111111111111, 1.0], 'title': {'text': 'Year'}},\n",
       "               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Mass in Mg'}},\n",
       "               'yaxis2': {'anchor': 'x2', 'domain': [0.0, 1.0]},\n",
       "               'yaxis3': {'anchor': 'x3', 'domain': [0.0, 1.0]}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying Dynamic Stock Composition:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcf56bb7b574ef2999af3a0055963a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Process:', options=(0, 2, 3, 7, 8), value=0), Dropdown(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9f37169d454db1a875b6a9f54d169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hoverinfo': 'x+y',\n",
       "              'line': {'width': 0.5},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Average Exchange (20 yrs)',\n",
       "              'stackgroup': 'one',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c5488889-a053-4031-a8ac-861c82a8de1e',\n",
       "              'x': [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929,\n",
       "                    1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
       "                    1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
       "                    1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959,\n",
       "                    1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
       "                    1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979,\n",
       "                    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "                    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "                    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "                    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "                    2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029,\n",
       "                    2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "                    2040, 2041, 2042, 2043, 2044, 2045],\n",
       "              'y': {'bdata': ('SZD5F+uxVkCKvsc9hNthQCrLAqvy2G' ... 'YCR3YzUUDe4oLoQPVRQG5f3FOXW1FA'),\n",
       "                    'dtype': 'f8'}}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': \"Dynamic Stock Composition for Process: 'Biosphere' (MATERIAL)\"},\n",
       "               'xaxis': {'title': {'text': 'Year'}},\n",
       "               'yaxis': {'title': {'text': 'Stock in Mg'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying Flow Dynamics:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5088a76fed664fb491f03e52abe4fab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Flows:', index=(0,), options=('F_00_01', 'F_01_00', 'F_01_02â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08219305059e420ab27e2d613ba8511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'F_00_01',\n",
       "              'type': 'scatter',\n",
       "              'uid': '7fc7149f-7a3e-4fac-970a-930d9a5ddb0d',\n",
       "              'x': [1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929,\n",
       "                    1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939,\n",
       "                    1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
       "                    1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959,\n",
       "                    1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969,\n",
       "                    1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979,\n",
       "                    1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n",
       "                    1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n",
       "                    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "                    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
       "                    2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029,\n",
       "                    2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "                    2040, 2041, 2042, 2043, 2044, 2045],\n",
       "              'y': {'bdata': ('mpmZmZnpckAzMzMzM7NlQM3MzMzMTG' ... 'zMzMzMOUDNzMzMzMw5QJqZmZmZmRlA'),\n",
       "                    'dtype': 'f8'}}],\n",
       "    'layout': {'barmode': 'overlay',\n",
       "               'hovermode': 'x unified',\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Time Series for Selected Flows (MATERIAL)'},\n",
       "               'xaxis': {'title': {'text': 'Year'}},\n",
       "               'yaxis': {'title': {'text': 'Mass in Mg'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# Section 4: Results & Visualization (Final Version)\n",
    "# ====================================================================\n",
    "\n",
    "# --- 4.1 Interactive Sankey Diagram ---\n",
    "print(\"Displaying interactive Sankey diagram:\")\n",
    "plot_interactive_sankey(mfa_system_with_results)\n",
    "\n",
    "\n",
    "# --- 4.2 Process Dynamics Plot (Inflow-Stock-Outflow) ---\n",
    "print(\"\\nDisplaying Inflow-Stock-Outflow Dynamics:\")\n",
    "plot_process_dynamics(mfa_system_with_results, all_excel_data['2_1_Definition_Processes'])\n",
    "\n",
    "# --- 4.3 Dynamic Stock Composition Plot ---\n",
    "print(\"\\nDisplaying Dynamic Stock Composition:\")\n",
    "if dsm_details:\n",
    "    plot_dynamic_stock_composition(dsm_details, mfa_system_with_results)\n",
    "else:\n",
    "    print(\"--> DSM calculation was not run or no DSM processes are defined. Nothing to display.\")\n",
    "\n",
    "# # --- 4.4 FOMP Dynamics Plot ---\n",
    "# print(\"\\nDisplaying FOMP Dynamics:\")\n",
    "# if FOMP_PARAMS and any(f in mfa_system_with_results.StockDict for f in [f\"S_{pid}\" for pid in FOMP_PARAMS]):\n",
    "#     plot_fomp_dynamics(mfa_system_with_results, FOMP_PARAMS)\n",
    "# else:\n",
    "#     print(\"--> No FOMP parameters defined or no FOMP stocks present. Nothing to display.\")\n",
    "\n",
    "# --- 4.5 Flow Dynamics Plot ---\n",
    "print(\"\\nDisplaying Flow Dynamics:\")\n",
    "plot_flow_dynamics(mfa_system_with_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b41e1-a5be-4578-a65e-6611fe24a645",
   "metadata": {},
   "source": [
    "# Section 5: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3ccd660-0b65-4178-af5e-82ec55aa8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Section 5: Export Results\n",
    "# ====================================================================\n",
    "\n",
    "def export_results_to_excel(mfa_system_results, output_filename=\"mfa_results.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exports all calculated flows and stocks into a single Excel file with multiple sheets.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--> Exporting results to '{output_filename}'...\")\n",
    "    \n",
    "    time_index = mfa_system_results.IndexTable.Classification['Time'].Items\n",
    "    elements = mfa_system_results.Elements\n",
    "    \n",
    "    with pd.ExcelWriter(output_filename) as writer:\n",
    "        # --- Export Flows ---\n",
    "        flow_data_rows = []\n",
    "        for name, flow_obj in mfa_system_results.FlowDict.items():\n",
    "            for i, year in enumerate(time_index):\n",
    "                row = {'Flow_ID': name, 'Year': year}\n",
    "                for j, element in enumerate(elements):\n",
    "                    row[element] = flow_obj.Values[i, j]\n",
    "                flow_data_rows.append(row)\n",
    "        df_flows = pd.DataFrame(flow_data_rows)\n",
    "        df_flows.to_excel(writer, sheet_name='Flows_ts', index=False)\n",
    "        \n",
    "        # --- Export Stocks ---\n",
    "        stock_data_rows = []\n",
    "        for name, stock_obj in mfa_system_results.StockDict.items():\n",
    "            for i, year in enumerate(time_index):\n",
    "                row = {'Stock_ID': name, 'Year': year}\n",
    "                for j, element in enumerate(elements):\n",
    "                    row[element] = stock_obj.Values[i, j]\n",
    "                stock_data_rows.append(row)\n",
    "        df_stocks = pd.DataFrame(stock_data_rows)\n",
    "        df_stocks.to_excel(writer, sheet_name='Stocks_ts', index=False)\n",
    "        \n",
    "    print(\"--> Export complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "226be3f9-3859-44d5-a9e6-ac3a8d625831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Exporting results to 'timber_thruss_results.xlsx'...\n",
      "--> Export complete.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# Section 5: Export Results\n",
    "# ====================================================================\n",
    "\n",
    "# Call the export function\n",
    "export_results_to_excel(mfa_system_with_results, output_filename=\"timber_thruss_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a10829-939a-46b6-a821-e16186b2b0db",
   "metadata": {},
   "source": [
    "<img src=\"system_flow_diagram.svg\" alt=\"system_flow_diagram\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf599485",
   "metadata": {},
   "source": [
    "## 0 Load packages\n",
    "\n",
    "This cell imports all necessary packages. It also loads the ODYM framework and the bioDYM_addon, both are included as files in the project (see folder /framework). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec308ac",
   "metadata": {},
   "source": [
    "## 3 MFA Calculations\n",
    "\n",
    "Now, the solution of the MFA is calculated. Since most flows have either input data or TCs and substance contents are given, they can be easily calculated. However, this system includes a dynamic stock modeling (dsm) and a first order model process (FOMP) for the mineralization of carbon in soil. The idea is that first, all flows are calculated with TCs that are independent of dsm or FOMP. Then, dsm is performed and subsequently, all flows up to the FOMP are calculated. After that, the bioDYM_addon functions are used to calculate the mineralization. Finally, all following flows and stocks are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d676a6",
   "metadata": {},
   "source": [
    "### 3.1 Solution MFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cabdf6-d262-47d3-bc4b-246a14049a64",
   "metadata": {},
   "source": [
    "### 3.1.1 Solution MFA pt. I (until MBC dynamic stock modelling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2047f8-ee16-4022-8f8b-bbd3a209bb06",
   "metadata": {},
   "source": [
    "### 3.1.4 Solution MFA pt. IV (FOMP mineralization process)\n",
    "\n",
    "The carbon mineralization process in the soil is calculated with a first order decay model according to (Cayuela et al., 2010) based on (Robertson & Paul, 2000): \n",
    "\n",
    "$$ C_{remaining} (t)=f \\cdot expâ¡(-k_{1} \\cdot t)+(100\\%-f) \\cdot expâ¡(-k_{2} \\cdot t) $$\n",
    "\n",
    "To keep calculations simple, it is assumed that this is the only equation that leads to outflows of the process, the remaining fractions of the material accumulate as stock without any emissions. (Cayuela et al., 2010) give parameter values for green waste biochar, they are used here.\n",
    "\n",
    "\\\n",
    "\\\n",
    "Literature\n",
    "\n",
    "Cayuela, M. L., Oenema, O., Kuikman, P. J., Bakker, R. R., & Van GROENIGEN, J. W. (2010). Bioenergy by-products as soil amendments? Implications for carbon sequestration and greenhouse gas emissions: C AND N DYNAMICS FROM BIOENERGY BY-PRODUCTS IN SOIL. GCB Bioenergy, no-no. https://doi.org/10.1111/j.1757-1707.2010.01055.x\n",
    "\n",
    "Robertson, G. P., & Paul, E. (2000). Decomposition and Soil Organic Matter Dynamics. Decomposition and Soil Organic Matter Dynamics., 104â€“116. https://doi.org/10.1007/978-1-4612-1224-9_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b1ef8-3ecd-48a2-8861-3a764c2573c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6218a16-fe58-414d-88d2-eb0489bdfa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e7d99-44a3-47cb-915c-9aab50df33e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498b8d8-d4eb-4e49-a696-7c699eb2568b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25c89d-af35-4f61-a8e3-771bc7d5201e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bd289-c690-4c1a-b4ec-950bfb17bbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafe9a0-2b69-4af6-b599-64ffbcd0bf71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioDYM_anaconda_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
